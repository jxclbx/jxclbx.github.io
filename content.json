{"meta":{"title":"jxclbx的小站","subtitle":"","description":"诶嘿","author":"Jxclbx","url":"http://jxclbx.github.io","root":"/"},"pages":[{"title":"","date":"2023-05-08T05:44:55.926Z","updated":"2023-04-28T05:47:48.000Z","comments":true,"path":"404.html","permalink":"http://jxclbx.github.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"所有分类","date":"2023-05-08T05:44:55.943Z","updated":"2023-04-28T05:53:46.000Z","comments":true,"path":"categories/index.html","permalink":"http://jxclbx.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2023-05-08T05:44:55.935Z","updated":"2023-04-28T05:53:42.000Z","comments":true,"path":"about/index.html","permalink":"http://jxclbx.github.io/about/index.html","excerpt":"","text":"下面写关于自己的内容"},{"title":"我的朋友们","date":"2023-05-08T05:44:56.031Z","updated":"2023-04-28T05:53:58.000Z","comments":true,"path":"friends/index.html","permalink":"http://jxclbx.github.io/friends/index.html","excerpt":"友情链接没有友链是万万不行滴！ 虽然博客是我自己写的，但是感谢他们对我一路的资瓷~","text":"友情链接没有友链是万万不行滴！ 虽然博客是我自己写的，但是感谢他们对我一路的资瓷~"}],"posts":[{"title":"20231015凌晨","slug":"20231015凌晨","date":"2023-10-14T17:31:48.000Z","updated":"2023-10-14T17:32:15.100Z","comments":true,"path":"2023/10/15/20231015凌晨/","link":"","permalink":"http://jxclbx.github.io/2023/10/15/20231015%E5%87%8C%E6%99%A8/","excerpt":"","text":"首先来说的话呢 王者真上瘾 下面来回忆一下上周都干啥了 嗯十月七号给自己多放了一天假，好吧，写雅思题，应该是错了一堆 八号去张晶的课了，也没点名是吧，然后也是看雅思课。 礼拜一孙宁，在课上复习了，效率很低，晚上给姥爷过了生日，yes！ 礼拜二早晨whp点名我点上了，然后吃了昨天剩下的饭饭，晚上杨奇干啥了没去，哦对，是张瀚，好喜欢他的方向 礼拜三好像没啥，自检起晚了，傻逼智工控在这耽误我的时间，然后晚上孙海东点名了吓了我一跳 礼拜四大舔没去，晚上去了美国外交，背了单词，从周一开始每天都有背单词 礼拜五也就是昨天，张晶没点名，然后就没什么了，周三到周五写深度学习吧！ 今天把张瀚搞差不多了。明天看两篇论文GAT GCNConv就可以愉快结束这一周了，明天也要去拍一组照片，希望效果好！ 其实这么记日记挺没意思的，我觉得有时候就算文字记下来了也真的想不起来当天发生过什么，也许图片会更好一些吧。。但是真没心情带相机出去，也真的不想考卡。。 就这样吧 一些图纪念一下","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"GCLMTP","slug":"GCLMTP","date":"2023-10-14T14:20:52.000Z","updated":"2023-10-14T17:32:15.107Z","comments":true,"path":"2023/10/14/GCLMTP/","link":"","permalink":"http://jxclbx.github.io/2023/10/14/GCLMTP/","excerpt":"","text":"矩阵操作 123456789101112131415161718192021222324252627282930313233def read_file1(): # 加载 lncRNA 和 miRNA 之间的关联数据 lnc_mi = np.loadtxt(&quot;data/yuguoxian_lnc_mi.txt&quot;) # 将 lncRNA 和 miRNA 之间的关联数据转置，表示 miRNA 和 lncRNA 之间的关联数据 mi_lnc = lnc_mi.T # 加载 lncRNA 与疾病之间的关联数据 lnc_dis = np.loadtxt(&quot;data/lnc_dis_association.txt&quot;) # 加载 miRNA 与疾病之间的关联数据 mi_dis = np.loadtxt(&quot;data/mi_dis.txt&quot;) # 加载疾病之间的相似性数据 dis_sim = np.loadtxt(&quot;data/dis_fusion_sim.txt&quot;) # 加载 lncRNA 之间的相似性数据 lnc_sim = np.loadtxt(&quot;data/lnc_fusion_sim.txt&quot;) # 加载 miRNA 之间的相似性数据 mi_sim = np.loadtxt(&quot;data/mi_fusion_sim.txt&quot;) # 加载 lncRNA 与疾病关联数据的测试标识符 lnc_dis_test_id = np.loadtxt(&quot;data/lnc_dis_test_id1.txt&quot;) # 加载 miRNA 与疾病关联数据的测试标识符 mi_dis_test_id = np.loadtxt(&quot;data/mi_dis_test_id1.txt&quot;) # 加载 miRNA 和 lncRNA 之间关联数据的测试标识符 mi_lnc_test_id = np.loadtxt(&quot;data/mi_lnc_test_id1.txt&quot;) # 返回加载的数据作为函数的输出 return mi_lnc, lnc_dis, mi_dis, dis_sim, lnc_sim, mi_sim, lnc_dis_test_id, mi_dis_test_id, mi_lnc_test_id 以上代码形状为 (495, 240) (240, 405) (495, 405) (405, 405) (240, 240) (495, 495) (95051, 2) (189628, 2) (117999, 2)，test为在矩阵中为即将在copyA中置零的矩阵 12345def Preproces_Data(A, test_id): copy_A = A / 1 for i in range(test_id.shape[0]): copy_A[int(test_id[i][0])][int(test_id[i][1])] = 0 return copy_A 程序中对lnc疾病、mi疾病、lncmi做了如上处理，后续 matrix_A = construct_graph(lnc_dis, mi_dis, mi_lnc, lnc_sim, mi_sim, dis_sim)，把上面三个矩阵构造进去，同时也把三个变量自己之间相关性也包含在内。 然后依照这个先做hstack，再做vstack。我发现处理数据时，lncRNA与miRNA顺序是反过来的，所以我修改了代码。将其先做转置，再更改 12345678910def construct_graph(lncRNA_disease, miRNA_disease, lncRNA_miRNA, lncRNA_sim, miRNA_sim, disease_sim): lnc_dis_sim = np.hstack((lncRNA_sim, lncRNA_disease, lncRNA_miRNA)) print(lnc_dis_sim.shape) dis_lnc_sim = np.hstack((lncRNA_disease.T, disease_sim, miRNA_disease.T)) print(dis_lnc_sim.shape) mi_lnc_dis = np.hstack((lncRNA_miRNA.T, miRNA_disease, miRNA_sim)) print(mi_lnc_dis.shape) matrix_A = np.vstack((lnc_dis_sim, dis_lnc_sim, mi_lnc_dis)) return matrix_A 拉普拉斯归一化 12345678910111213def lalacians_norm(adj): # adj += np.eye(adj.shape[0]) degree = np.array(adj.sum(1)) D = [] for i in range(len(degree)): if degree[i] != 0: de = np.power(degree[i], -0.5) D.append(de) else: D.append(0) degree = np.diag(np.array(D)) norm_A = degree.dot(adj).dot(degree) return norm_A GCNConv GCNConv 是一个自定义的 PyTorch 模块类，继承了 nn.Module。这表示它是一个可训练的神经网络层，可以包含可学习的参数。 在初始化方法 __init__ 中，定义了 GCNConv 层的参数： in_size 表示输入特征的维度大小，即节点特征的数量。 out_size 表示输出特征的维度大小，即经过该层后节点特征的维度。 在 __init__ 中，创建了一个可训练的权重矩阵 self.weight 作为 GCNConv 层的参数。这个权重矩阵的大小是 (in_size, out_size)，初始化使用 Xavier 初始化方法，以确保参数的初始值是合适的，有助于网络的训练。 在 forward 方法中，定义了 GCNConv 层的前向传播操作： adj 是图的邻接矩阵（Adjacency Matrix），表示节点之间的连接关系。 features 是节点的特征矩阵，表示每个节点的特征向量。 在前向传播中，首先执行 torch.mm(adj, features) 操作，将邻接矩阵 adj 与特征矩阵 features 相乘。这个操作相当于对每个节点的特征与其邻居节点的特征进行聚合，得到了节点聚合后的特征表示。 然后，执行 torch.mm(out, self.weight) 操作，将上一步得到的聚合特征矩阵与 GCNConv 层的权重矩阵 self.weight 相乘。这个操作实现了将聚合后的特征进一步映射到输出特征空间，得到了最终的输出特征表示。 最后，将计算得到的输出特征 out 返回作为这个 GCNConv 层的输出。 图为encoder的一种结构 Encoder 123456789101112131415161718192021222324## input_dim是输入的维度，hidden_dim是隐藏层的维度，n_calss是输出的维度class Encoder(nn.Module): def __init__(self, input_dim, hidden_dim, n_calss): super(Encoder, self).__init__() self.gcn1 = GCNConv(input_dim, hidden_dim) self.prelu1 = nn.PReLU(hidden_dim) self.gcn2 = GCNConv(hidden_dim, n_calss) self.prelu2 = nn.PReLU(n_calss) self.last_linear = torch.nn.Linear(hidden_dim + n_calss, n_calss) def forward(self, x, adj, corrupt=True): if corrupt: perm = torch.randperm(x.shape[0]) x = x[perm] x1 = self.gcn1(adj, x) x1 = self.prelu1(x1) x2 = self.gcn2(adj, x1) x2 = self.prelu2(x2) return x2 不再赘述 模型本身 GCLMTP是一个基于图的模型，它利用编码器从输入数据生成正样本和负样本，然后使用判别器进行处理，并根据判别器的输出计算损失。这个模型的目的似乎是在图结构的数据上进行未监督的学习，可能是用于图嵌入或者相似的任务。 Corrupt 12345678910111213141516171819202122232425262728293031323334353637383940## hidden_dim是隐藏层的维度# discriminator是一个全连接层，输入是hidden_dim，输出是hidden_dimclass Discriminator(nn.Module): def __init__(self, hidden_dim): super(Discriminator, self).__init__() self.weight = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim)) nn.init.xavier_uniform_(self.weight.data, gain=1.414) def forward(self, x, summary): x = torch.matmul(x, torch.matmul(self.weight, summary)) return x&#x27;&#x27;&#x27;Model&#x27;&#x27;&#x27;class GCLMTP(nn.Module): def __init__(self, input_dim, hidden_dim, output_dim): super(GCLMTP, self).__init__() self.encoder = Encoder(input_dim, hidden_dim, output_dim) self.discriminator = Discriminator(output_dim) self.loss = nn.BCEWithLogitsLoss() def forward(self, edge_index, x): positive = self.encoder(x, edge_index, corrupt=False) negative = self.encoder(x, edge_index, corrupt=True) summary = torch.sigmoid(positive.mean(dim=0)) # print(&quot;summary: &quot;,summary.shape) positive_D = self.discriminator(positive, summary) negative_D = self.discriminator(negative, summary) l1 = self.loss(positive_D, torch.ones_like(positive_D)) l2 = self.loss(negative_D, torch.zeros_like(negative_D)) L = l1 + l2 return L, positive 代码的核心在于 positive = self.encoder(x, edge_index, corrupt=False),corrupt代表是否生成错误特征，这也是对比学习的一个特点。 positive是通过编码器处理输入数据得到的“正”样本的输出，其形状应该是 [N, output_dim]，接下来的 positive.mean(dim=0)计算了 positive沿第0维度（即沿样本数方向）的平均值。这会得到一个长度为 output_dim的向量，其每个元素表示所有样本在该特定维度上的平均值。torch.sigmoid函数被应用于这个平均值向量。sigmoid函数将任何输入压缩到0和1之间。这意味着 summary是一个介于0和1之间的值的向量，表示所有正样本的平均特征。 Discriminator Discriminator接受两个输入：x和 summary。x是从编码器得到的输出，是正样本或负样本的表示，而 summary是前面提到的正样本的平均特征。torch.matmul(self.weight, summary)是一个矩阵与向量的乘法操作，它实际上是在为每个特征维度提供一个权重，这些权重来自 self.weight。然后得到的结果与输入 x再次进行矩阵乘法。这是将 x的每个样本与通过 summary加权的权重进行相乘。 我认为判别器实际上是在使用 summary 来影响或加权它如何处理输入的样本。 1234summary = torch.sigmoid(positive.mean(dim=0))&gt;&gt;&gt; positive: torch.Size([1140, 256])summary: torch.Size([256]) 可以看出，dim进行了降维度。 这样，判别器实际上是在使用 summary（即正样本的平均特征）来影响或加权它如何处理输入的样本。 从高级角度看，Discriminator的目的是判断一个给定的样本表示（x）与整体“正”样本分布（由 summary表示）有多接近。如果 x表示的样本接近于正样本分布，那么判别器的输出会更接近1（正类），否则它会更接近0（负类）。 训练 1234567891011121314151617181920212223242526def train(la_A, Epoch, in_features, N_HID, out_features, LR): G = GCLMTP(input_dim=in_features, hidden_dim=N_HID, output_dim=out_features) G_optimizer = torch.optim.Adam(G.parameters(), lr=LR) A_laplacians = torch.from_numpy(la_A).float() X = torch.from_numpy(la_A).float() # print(A_laplacians.shape,X.shape) ################################GPU############################# if torch.cuda.is_available(): G = G.cuda() A_laplacians = A_laplacians.cuda() X = X.cuda() ###########################model train########################### for epoch in range(Epoch): G_loss, embedding = G(A_laplacians, X) G_optimizer.zero_grad() G_loss.backward() G_optimizer.step() print(&#x27;Epoch: &#x27;, epoch, &#x27;| train G_loss: %.10f&#x27; % G_loss.item()) np.savetxt(&quot;dataset1_result/low_A_256.txt&quot;, embedding.detach().cpu().numpy()) 训练过程比较常规，无需单独记录 疑问 1234 A_laplacians = A_laplacians.cuda() X = X.cuda()G_loss, embedding = G(A_laplacians, X) 代码中 X矩阵即为经过拉普拉斯正则化的 matrix_A ，但我们发现作为 edge_index的矩阵仍是 matrix_A 我推测是因为这个矩阵中包含了足够多的特征","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"深度学习","slug":"深度学习","permalink":"http://jxclbx.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"GNNs","slug":"GNNs","permalink":"http://jxclbx.github.io/tags/GNNs/"},{"name":"课题组","slug":"课题组","permalink":"http://jxclbx.github.io/tags/%E8%AF%BE%E9%A2%98%E7%BB%84/"}]},{"title":"图学习之GCN","slug":"图学习之GCN","date":"2023-10-11T04:22:10.000Z","updated":"2023-10-14T17:32:15.129Z","comments":true,"path":"2023/10/11/图学习之GCN/","link":"","permalink":"http://jxclbx.github.io/2023/10/11/%E5%9B%BE%E5%AD%A6%E4%B9%A0%E4%B9%8BGCN/","excerpt":"","text":"其中： xi(k)x_i^{(k)}xi(k)​ 代表节点i在第k层的特征。 N(i)N(i)N(i) 是节点i的邻居集合。 deg(i)\\text{deg}(i)deg(i) 是节点i的度（或邻居的数量）。 WWW 是可学习的权重矩阵。 bbb 是偏置向量。 数学公式的含义 加入自循环：通过在求和符号中包含 j∈N(i)∪{i}j \\in N(i) \\cup \\{i\\}j∈N(i)∪{i}，我们考虑了每个节点自己的特征，即添加了自循环。 归一化系数：系数 1deg(i)⋅deg(j)\\frac{1}{\\sqrt{\\text{deg}(i) \\cdot \\text{deg}(j)}}deg(i)⋅deg(j)​1​ 是为了对节点的度进行归一化，这有助于模型的稳定性和训练效果。 线性特征转换：通过乘以权重矩阵 WTW^TWT 并添加偏置 bbb，每个节点的特征进行了线性变换。 特征聚合：通过对所有邻居的转换后的特征进行求和，我们实际上在每个节点上聚合了其所有邻居的信息。 使用“add”聚合 这是一个将所有邻接节点与自己特征先归一化再加和成为新节点的过程 添加自循环 123456789Examples: &gt;&gt;&gt; edge_index = torch.tensor([[0, 1, 0], ... [1, 0, 0]]) &gt;&gt;&gt; edge_weight = torch.tensor([0.5, 0.5, 0.5]) &gt;&gt;&gt; add_self_loops(edge_index) (tensor([[0, 1, 0, 0, 1], [1, 0, 0, 0, 1]]), None) 节点的度 在您之前提到的GCN的公式中，i 和 j 分别代表两个节点，其中节点 i 是中心节点，而节点 j 是它的一个邻居或它自己（当考虑自循环时）。 自循环产生的边缘特征如何计算 在图神经网络（GNN）中，自循环指的是节点到自身的边。当我们在图中添加自循环时，通常是为了确保节点在消息传递时可以考虑自己的特征。但这通常涉及到节点特征，而不是边的特征。 当涉及到具有边特征的图时，处理自循环的方式可能会有所不同： 没有边特征 ：在这种情况下，添加自循环只会影响节点特征的聚合，并不涉及边的特征。 有边特征 ：当图中存在边特征时，为自循环添加特定的边特征会更加复杂。在这种情况下，您有几种选择： 零向量 ：为自循环边分配一个零向量作为其特征。 特殊值 ：为自循环边分配一个固定的特殊值或标志。 节点特征衍生 ：从相关节点的特征衍生出自循环边的特征。 学习 ：如果网络结构允许，可以设计一个机制来学习自循环边的特征。需要注意的是，不是所有的GNN都会使用或需要边特征。在某些情况下，特别是当使 用基本的GNN架构如GCN时，只考虑节点特征可能就足够了。 计算 lin进行W矩阵的全连接，norm求出了所有ij节点的归一化系数 propagate包含了message方法 norm.view(-1, 1) * x_j讲norm转置，再与节点特征相乘 然后加上b求出了新xi 实现边缘卷积 边缘卷积相对于标准的GCN（Graph Convolutional Network）层更多地实现了以下方面的功能和考虑： 边缘卷积利用了&quot;max&quot;聚合方式，这意味着它在考虑一个节点的所有邻居节点时，会选择MLP计算后的最大值作为该节点的新特征。 具体来说： 对于节点i的每一个邻居j，计算特征差值 将这个差值通过MLP得到新的特征。 对于节点i的所有邻居，选择这些新特征中的最大值作为节点i的新特征。 因此，当我们说选择的是&quot;最大值&quot;时，我们是指对于节点i，我们选择其所有邻居经过MLP处理后的最大特征值来表示节点i的新特征。这种选择方式捕获了节点与其邻居之间的最显著差异，这可能在某些任务中是很有用的。 练习题 对于 GCNConv： row 和 col 分别保存了什么信息？ edge_index的形状是 [2, E]，其中E是边的数量。row和 col是 edge_index的两个维度。在这种情况下，col表示边的起始节点，而 row表示边的目标节点。 degree()函数的作用是什么？ degree()函数计算图中每个节点的度。在图论中，一个节点的度是指与它相连的边的数量。 为什么使用 degree(col, …) 而不是 degree(row, …)? 在GCN中，通常使用 degree(col, ...)来计算每个节点的出度，这与信息传播的方向有关。 deg_inv_sqrt[col] 和 deg_inv_sqrt[row] 的作用是什么？ 这两者都是GCN归一化步骤中用到的因子。使用节点的度的平方根的倒数作为归一化因子，这有助于训练的稳定性和模型的性能。 在 message() 函数中 x_j 保存了哪些信息？如果 self.lin 表示恒等函数，x_j 的确切内容是什么？ x_j保存了源节点的特征。如果 self.lin是恒等函数，那么 x_j就是原始的、未经修改的节点 j的特征。 为 GCNConv 添加一个 update() 函数，该函数将转换后的中心节点特征添加到聚合输出中。 12def update(self, aggr_out, x): return aggr_out + self.lin(x) 对于 EdgeConv： x_i 和 x_j - x_i 分别是什么？ x_i是目标节点的特征，而 x_j - x_i表示的是源节点与目标节点特征之间的差异。 torch.cat([x_i, x_j - x_i], dim=1) 的作用是什么？为什么选择 dim = 1？ torch.cat([x_i, x_j - x_i], dim=1)的作用是将 x_i和 x_j - x_i沿着特征维度进行拼接。选择 dim=1是因为我们希望在特征维度上进行拼接，这样每个节点的新特征长度会是原来的两倍。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"深度学习","slug":"深度学习","permalink":"http://jxclbx.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"GNNs","slug":"GNNs","permalink":"http://jxclbx.github.io/tags/GNNs/"},{"name":"课题组","slug":"课题组","permalink":"http://jxclbx.github.io/tags/%E8%AF%BE%E9%A2%98%E7%BB%84/"}]},{"title":"Hello，图学习","slug":"Hello，图学习","date":"2023-10-10T17:17:19.000Z","updated":"2023-10-10T17:22:33.237Z","comments":true,"path":"2023/10/11/Hello，图学习/","link":"","permalink":"http://jxclbx.github.io/2023/10/11/Hello%EF%BC%8C%E5%9B%BE%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"data封装了一个类似图的数据结构 123456789import torchfrom torch_geometric.data import Dataedge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)x = torch.tensor([[-1], [0], [1]], dtype=torch.float)data = Data(x=x, edge_index=edge_index)&gt;&gt;&gt; Data(edge_index=[2, 4], x=[3, 1]) 1234567dataset = TUDataset(root=&#x27;/tmp/ENZYMES&#x27;, name=&#x27;ENZYMES&#x27;)print(&quot;打印数据集的图表数量，类别数量，节点特征数量&quot;)print(len(dataset), dataset.num_classes, dataset.num_node_features)data = dataset[0] # Get the first graph object.print(data.num_nodes)&gt;&gt;&gt; 600 6 3&gt;&gt;&gt; 37 加入dataloader 123456dataset = TUDataset(root=&#x27;/tmp/ENZYMES&#x27;, name=&#x27;ENZYMES&#x27;, use_node_attr=True)loader = DataLoader(dataset, batch_size=32, shuffle=True)# 每个batch 32个图表for batch in loader: print(batch) 代表这个节点在哪张图里 12345678910for data in loader: data &gt;&gt;&gt; DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32]) data.num_graphs &gt;&gt;&gt; 32 x = scatter(data.x, data.batch, dim=0, reduce=&#x27;mean&#x27;) x.size() &gt;&gt;&gt; torch.Size([32, 21]) 分析scatter函数的汇总过程 输入数据: data.x: 这是节点特征矩阵，其形状为[1082, 21]。这意味着在这个批处理中，总共有1082个节点，每个节点有21个特征。 data.batch: 这是一个批次向量，其长度为1082（与 data.x中的节点数相同）。它指定了每个节点属于哪个图。 data.num_graphs: 这表示在批处理中有32个图。 使用scatter进行汇总: 你使用 scatter函数并指定 reduce='mean'，这意味着你想要计算每个图中的节点特征的平均值。 所以，对于每个图，它会考虑所有属于该图的节点（基于 data.batch），然后计算这些节点特征的平均值。结果是每个图都有一个平均的特征向量。 输出: x: 经过 scatter函数处理后，你得到一个新的张量 x，其形状为[32, 21]。这意味着现在你有32个平均特征向量，每个向量有21个特征（与输入 data.x中的特征数相同）。 每个平均特征向量对应于批处理中的一个图。这样，你从批处理中的1082个节点减少到了32个平均特征向量，每个都代表一个图。 结论: scatter的汇总工作是将这批处理中的每个图中的所有节点特征取平均，从而为每个图得到一个代表性的特征向量。这对于那些需要从整个图中提取特征的任务（例如，整图分类）非常有用。 数据转换 12345678import torch_geometric.transforms as Tfrom torch_geometric.datasets import ShapeNetdataset = ShapeNet(root=&#x27;/tmp/ShapeNet&#x27;, categories=[&#x27;Airplane&#x27;], pre_transform=T.KNNGraph(k=6))dataset[0]&gt;&gt;&gt; Data(edge_index=[2, 15108], pos=[2518, 3], y=[2518]) 该代码把点云图，找到每个点最邻近的6个点，加上边连接，所以15108 = 2518 * 6，数据集专注于飞机类别。而y属性中的值将表示飞机的各个部分（如机翼、尾翼、机身等） pre_transform vs transform pre_transform: 定义: pre_transform 是在保存数据集到磁盘之前应用的变换。 应用时机: 它只会执行一次，即在第一次下载和处理原始数据时。之后，即使你多次加载数据集，这个变换也不会再被应用。 示例解释: 在你的例子中，pre_transform=T.KNNGraph(k=6) 的意思是在数据被保存之前，对每个图形数据计算其k-最近邻图。具体来说，它会为每个点找到其6个最近的邻居，并创建一个边连接索引，表示这些近邻关系。 transform: 定义: transform 是每次从数据集中获取数据时都会应用的变换。 应用时机: 它是动态的，意味着每次你从数据集中提取一个数据项时，都会实时地应用这个变换。 示例解释: 在你的例子中，transform=T.RandomJitter(0.01) 的意思是每次提取数据时，都会对每个点的位置随机添加一个在 [-0.01, 0.01]范围内的扰动。这种随机扰动有助于数据增强，使模型更加鲁棒。 结论: pre_transform 是一个预处理步骤，只应用一次，而 transform 是一个每次都会应用的数据增强步骤。 图的学习方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from torch_geometric.datasets import Planetoiddataset = Planetoid(root=&#x27;/tmp/Cora&#x27;, name=&#x27;Cora&#x27;)print(&quot;打印数据集的图表数量，类别数量，节点特征数量&quot;)print(len(dataset), dataset.num_classes, dataset.num_node_features)print(&quot;打印节点标签&quot;)print(dataset[0].keys)data = dataset[0] # Get the first graph object.print(data.num_nodes)import torchimport torch.nn.functional as Ffrom torch_geometric.nn import GCNConvclass GCN(torch.nn.Module): def __init__(self): super().__init__() self.conv1 = GCNConv(dataset.num_node_features, 16) self.conv2 = GCNConv(16, dataset.num_classes) def forward(self, data): x, edge_index = data.x, data.edge_index x = self.conv1(x, edge_index) x = F.relu(x) x = F.dropout(x, training=self.training) x = self.conv2(x, edge_index) return F.log_softmax(x, dim=1)device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)model = GCN().to(device)data = dataset[0].to(device)optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)model.train()for epoch in range(200): optimizer.zero_grad() out = model(data) loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask]) loss.backward() optimizer.step()model.eval()pred = model(data)print(pred.shape)pred = pred.argmax(dim=1)print (pred)correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()acc = int(correct) / int(data.test_mask.sum())print(f&#x27;Accuracy: &#123;acc:.4f&#125;&#x27;) 可以看到，图学习方法将边的信息融合了进去 现在让我们注意dim参数，dim的意思是，在某个维度上处理数据，argmax在7的概率分布中选择最大的那个 我们可以观察输出 12345678打印数据集的图表数量，类别数量，节点特征数量1 7 1433打印节点标签[&#x27;y&#x27;, &#x27;x&#x27;, &#x27;train_mask&#x27;, &#x27;val_mask&#x27;, &#x27;test_mask&#x27;, &#x27;edge_index&#x27;]2708torch.Size([2708, 7])tensor([3, 4, 4, ..., 5, 3, 3], device=&#x27;cuda:0&#x27;)Accuracy: 0.7880 关于这个mask是什么 1tensor([ True, True, True, ..., False, False, False]) 可以看出，就是为了区别是否加入训练 Exercises What does edge_index.t().contiguous() do? Load the &quot;IMDB-BINARY&quot; dataset from the TUDataset benchmark suite and randomly split it into 80%/10%/10% training, validation and test graphs. What does each number of the following output mean? 12print(batch)&gt;&gt;&gt; DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32]) edge_index.t().contiguous() 将 edge_index 张量转置并确保其在内存中连续存储。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"深度学习","slug":"深度学习","permalink":"http://jxclbx.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"GNNs","slug":"GNNs","permalink":"http://jxclbx.github.io/tags/GNNs/"},{"name":"课题组","slug":"课题组","permalink":"http://jxclbx.github.io/tags/%E8%AF%BE%E9%A2%98%E7%BB%84/"}]},{"title":"20231007","slug":"20231007","date":"2023-10-07T03:22:10.000Z","updated":"2023-10-10T17:26:55.713Z","comments":true,"path":"2023/10/07/20231007/","link":"","permalink":"http://jxclbx.github.io/2023/10/07/20231007/","excerpt":"","text":"是啊，国庆结束了。 哦原来9月27号去谈留学了啊 28团泊接鱼吧算是，堵死在路上，差点没拍到晚霞笑死，晚上还蹦出来死了一个。。 29号回家塘沽吃饭，开车听雅思听力 30号跟光吹车展，开心！ 谁家雅思课十一上啊 十月一号直接请假，跑模型，！必胜客好吃 十月二号北京开跑，台球（） 3号开始回看雅思，写a星吧大概，晚上修丽娜 4号感起来了，给小刘送镜头，不知道该吃啥的纠结日，最后吃了红烧肉 5号学了一天，吃个疯狂星期四把自己逼到吴悦去，晚上看镜头 6号就是写完了自检然后摆了吧，我发觉我晚上就真的几乎没干啥，看了看张翰的论文 睡吧，烂着了 Written with StackEdit中文版.","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"20230925_VSCode没了马","slug":"20230925_VSCode没了马","date":"2023-09-25T15:22:10.000Z","updated":"2023-10-10T17:26:55.712Z","comments":true,"path":"2023/09/25/20230925_VSCode没了马/","link":"","permalink":"http://jxclbx.github.io/2023/09/25/20230925_VSCode%E6%B2%A1%E4%BA%86%E9%A9%AC/","excerpt":"","text":"司马 你瞎几把更新什么呢 到最后powershell都崩坏了 然后de了一堆，最后无奈给vsc降级 我发现我写的9月19号实际上能管到21号 我的拖延治不好了 22号 吃了个啥 吃了个寿喜锅 晚上台球 丹丹好爱我(≧∇≦)ﾉ 23号 运动会跟小刘见一面~~ 早晨看了雅思网课 下午装了鱼缸加了水 晚上是抽象的晚霞，甚至一下都没烧，乐 uv偏色 24号 也就是前天，被雅思课创飞 晚上回去光速大舔 孙宁的神奇演讲 25号，孙宁提前讲完了给自己准备了一场即兴演讲 于是下午智工控上的跟脑残一样 晚上翻墙出去海底捞 真的不是很好吃啊哎 Written with StackEdit中文版.","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"20230919还是应该多写写","slug":"20230919还是应该多写写","date":"2023-09-19T17:22:10.000Z","updated":"2023-10-10T17:26:55.707Z","comments":true,"path":"2023/09/20/20230919还是应该多写写/","link":"","permalink":"http://jxclbx.github.io/2023/09/20/20230919%E8%BF%98%E6%98%AF%E5%BA%94%E8%AF%A5%E5%A4%9A%E5%86%99%E5%86%99/","excerpt":"","text":"因为忘记的太快了 所以还是写的频繁点😓 我叼，13号全忘了！ 哦，去你妈个达美乐了，难吃服务还差，出口成脏的习惯要改，因为会让自己处于下风 然后吐槽了一下哈哈，佳佳的代码，也告诉我：try except要写，事件要搞明白，少用sleep阻塞，尽量搞多线程。。。Qt好难 十四号啊 丹的科三过了，真的超级开心！！ 啊对，是那个礼拜四……八里台那边负责人一股子臭屎胡搅蛮缠，真是搞不懂他们脑子里长没长纹路……我最后说自己在路上，也没出现在八里台哈哈，都是谎言罢了，到了晚上去吃了个木屋烧烤 呵呵，预制菜。。。没见过辣味的木屋烧烤，大无语 晚上回到津南，蟹笼捕到了虾坚强 礼拜五 游泳游泳！！ 这是第一天陈万语被我拉到大群里，他立马就开始跳了，然后后续加上了阿依古丽……结果嘛，其实就是架空别人，呵呵！ 上礼拜六干啥了，又忘了哎。。想起来了，上礼拜六给大舔写论文呢，再次呵呵！哦 计网他们保研交材料，我去找我的各种证书，好吧，我找许的事儿，还拖着呢啊~以后证书千万别乱丢啦！ 礼拜日早晨写啥忘了，下午上了个雅思课，哈哈我又想起来了，早晨cwy想自己搞订饭的事情，把我们所有人都搞迷糊了。。。。。。不说这个贱人了。这天晚上去吃铁锅炖，东北菜菜单写的不好，也不知道肉多肉少，最后吃了一顿碳水大餐~还行吧 又是新的一周 现控：孙宁PUA大师；智能实践：谁都玩不明白，小茹U盘也没还我哈哈，大家都忘，晚上开车回市里了，吃了八里台的那个馆子，不好吃~预制菜~测了个血压回家了，鬼知道那晚上干啥了。。迷迷瞪瞪又一天 礼拜二whp不上课好啊好，中午面试遇到双非考证王！原来全中国的视传都这么烂！下午实验没去，哦又忘了屎学通论*-*，周恩来与南开又停课，驮着丹丹骑了一圈儿啊啊啊，流动小摊咖啡不好喝 礼拜三上了一整天课，要死了，因为深度学习实验忙活了一天！智工控sb！！B聪也是啥也不会！！！这天写到三点，服了 礼拜四也就是刚过来的这天，大舔舔了个痛快，去山姆买了1000的东西也是痛快，明天放假我在这写下这些，记录我的感受 总结与展望 就是他妈的以后别在每次都迟到五分钟了！！！然后也别再拖了，别再乱丢证书！！！好好拍照，别打嘴炮！！！对人名字要小心马虎！！！over。","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"20230913苹果发布会","slug":"20230913苹果发布会","date":"2023-09-12T17:43:25.000Z","updated":"2023-09-12T17:43:48.567Z","comments":true,"path":"2023/09/13/20230913苹果发布会/","link":"","permalink":"http://jxclbx.github.io/2023/09/13/20230913%E8%8B%B9%E6%9E%9C%E5%8F%91%E5%B8%83%E4%BC%9A/","excerpt":"","text":"于是回到周六下午 去纳新现场晃了一脚然后折腾一下午纸（乐） 周日呢，早晨起来写了自检作业，回去跟老田聊了聊，看了看姥姥姥爷 中环花鸟鱼虫送了个缸，一场痛苦的台球，晚上回到津南。。 建模 有一种感觉，我是不是应该试着做一些数学建模，自己真掌握不了这些内容吗？吹牛我还不会吗哈哈哈 周一 现控没上课 下午sb智能专业实践 实践个屁，19年还叫自动化专业实践 晚上去游泳嘻嘻 周二 满课，但是不累 学了一些现控内容吧算是，然后就继续玩玩玩 印完了照片 这儿副厂的纸还算不错，没来得及锻炼的一天，晚上五点就骑了半个多小时自行车 明天值得期待哈哈哈 像不像AIh","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"20230909向摆烂致敬","slug":"20230909向摆烂致敬","date":"2023-09-09T07:45:10.000Z","updated":"2023-09-09T07:46:09.293Z","comments":true,"path":"2023/09/09/20230909向摆烂致敬/","link":"","permalink":"http://jxclbx.github.io/2023/09/09/20230909%E5%90%91%E6%91%86%E7%83%82%E8%87%B4%E6%95%AC/","excerpt":"","text":"致敬我摆烂的四天 大抵都是在水课吧，其实也没什么特别好纪念的，因为我也忘了哈哈哈。。 礼拜二晚上万恶的杨奇老师把我们鸽了 礼拜三深度学习实验在教室后盯着还有解放军战史（ 礼拜四当然是跟丹丹过了一周年，我们一年了嘿 吃了巨难吃的同发号，真实天津菜的耻辱 礼拜五也就是昨天摆烂一整天，真的是躺了一天的那种 礼拜六摆烂了一上午（ 丹丹没得幽门螺杆菌诶，庆祝🎉 来点儿图 哦对了 这东西买一送一送的可不是一模一样的哦 🙈退货了 Written with StackEdit中文版.","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"20230905","slug":"20230905","date":"2023-09-05T03:25:52.000Z","updated":"2023-09-05T03:26:11.173Z","comments":true,"path":"2023/09/05/20230905/","link":"","permalink":"http://jxclbx.github.io/2023/09/05/20230905/","excerpt":"","text":"看似是9月5日，其实是9月4日 让我用流水账速记一下这几天发生的事情，9月2号呢好像是玩了一天吧，新宿舍落成吃了个达美乐，准备了一天根本没必要的面试，次日和卡梅老头聊天颇有意思，然后又晃荡了一下午。。 呵呵，自己浪费了时间，也没照顾到别人尤其是亲人的情绪，真的没什么必要，速改 想不到吧，就这样就周一了，早晨上了个现控，料理好相机什么的事，下午吃了个牛筋面因为热量不足昏睡到下午五点半…… 还好今天把要料理的事儿料理完了。晚上打了会儿台球回来修图哈哈 分享自己喜欢的几张(≧∇≦)ﾉ 对了，有机会我一定要试试用md改变图片占据的行宽 然后就是现控自检模电哦捏盖伊","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"20230901","slug":"20230901","date":"2023-09-01T17:29:33.000Z","updated":"2023-09-01T17:31:25.459Z","comments":true,"path":"2023/09/02/20230901/","link":"","permalink":"http://jxclbx.github.io/2023/09/02/20230901/","excerpt":"","text":"九月奇迹 九月从又碰见ubuntu虚拟机开始，真的又卡又难用。 没有车的我在津南真的像没有腿一样，在犹豫今天要不要回家，用我的老机器进行Ubuntu双系统的可行性验证…… 晚上 没回家，张晶怎么也开始点名了，真佛了 自己印的照片儿送给别人被喜欢了，嘿嘿 傻逼 不跟傻逼置气，但是傻逼会反咬你，然后就更需要置气，这时候真的觉得自己的阅读量不够，无法泰然处置这种情况。于是开始对线，到最后伤了和气，浪费了时间，怎么办呢？ 最难剪的BDF，可怜的小刘 Written with StackEdit中文版.","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"Ubuntu系统中如何快速安装和配置Clash代理","slug":"Ubuntu系统中如何快速安装和配置Clash代理","date":"2023-08-31T16:06:55.000Z","updated":"2023-09-01T03:13:31.361Z","comments":true,"path":"2023/09/01/Ubuntu系统中如何快速安装和配置Clash代理/","link":"","permalink":"http://jxclbx.github.io/2023/09/01/Ubuntu%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AEClash%E4%BB%A3%E7%90%86/","excerpt":"","text":"前言 Clash 是一款免费的代理软件，可以帮助我们实现科学上网。在 Ubuntu 系统中安装和配置 Clash 代理非常简单，只需要按照以下步骤操作即可。 首先解决虚拟机剪切板问题 然而不行 然而还不行，提示安装增强功能时提示 未能加载虚拟光盘到虚拟电脑 删除这个光盘盘片 有了，然后在终端中打开盘片，再输入 ./autorun.sh 搞定 下载clash 打开 github，搜索 clash for Windows 1wget https://github.com/Fndroid/clash_for_windows_pkg/releases/download/0.20.32/Clash.for.Windows-0.20.32-x64-linux.tar.gz mkdir ~/.app mkdir 是 “make directory” 的缩写，用于创建新的目录。 ~/.app 指的是在用户主目录下创建一个名为 .app 的隐藏目录（因为它以 .开始）。 tar -zxvf Clash.for.Windows-0.19.12-x64-linux.tar.gz -C ~/.app tar 是一个用于归档文件的工具。 -zxvf 是选项的集合：-z 表示解压缩，-x 表示提取文件，-v 表示详细模式，-f 后面是要操作的文件。 Clash.for.Windows-0.19.12-x64-linux.tar.gz 是你要解压的文件。 -C ~/.app 表示解压后的文件将放置在 ~/.app 目录下。 cd ~/.app cd 是 “change directory” 的缩写，用于改变当前工作目录。 ~/.app 是你要切换到的目录。 mv Clash\\ for\\ Windows-0.19.12-x64-linux/ clash mv 是 “move” 的缩写，用于移动或重命名文件和目录。 Clash\\ for\\ Windows-0.19.12-x64-linux/ 是原始目录名，因为目录名包含空格，所以用反斜杠 \\ 进行转义。 clash 是新的目录名。 cd clash 同第3条命令，这条命令将你的当前工作目录切换到 clash。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"http://jxclbx.github.io/tags/ubuntu/"},{"name":"linux","slug":"linux","permalink":"http://jxclbx.github.io/tags/linux/"},{"name":"clash","slug":"clash","permalink":"http://jxclbx.github.io/tags/clash/"},{"name":"科学上网","slug":"科学上网","permalink":"http://jxclbx.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"}]},{"title":"20230831","slug":"20230831","date":"2023-08-31T03:00:15.000Z","updated":"2023-08-31T12:50:20.682Z","comments":true,"path":"2023/08/31/20230831/","link":"","permalink":"http://jxclbx.github.io/2023/08/31/20230831/","excerpt":"","text":"痛 摔跤的疼痛肯定是无法这么快就缓解的……尤其是不破皮不流血 今日维护脚本 来po一些觉得很有意思的聊天记录be like “原来”“我是按照一天一更新图片”“写的”“然后现在我突然想起来”“我有时候可能回不了学校”“就想着用一个dataframe存日期，来把每个日期产生的文件写进去，已经写入过的日期置1” “昂” “然后他妈的”“我发现dataframe要写的代码太多了”“然后我就想”“要不要直接就把所有遍历到的文件全扔进去吧”“虽然慢但是可行”“然后读了读昨天写的代码，全他妈要重构” “现在我想出了个折中的方法”“在接口外边迭代日期”“从2022年1月1号执行到今天” 屎山就这么起来了 1234while current_date &lt;= end_date: gp.git_pics_by_date(current_date.strftime(&#x27;%Y-%m-%d&#x27;), posts_path, img_dest_folder, img_repo_path) current_date += datetime.timedelta(days=1) print(current_date) 人机界面交互方向是什么 个性化和推荐系统 用户建模 : 通过机器学习算法，可以更准确地理解用户的需求和行为，从而提供更个性化的服务或产品。 内容推荐 : 在各种应用（如新闻、电商、社交媒体等）中，机器学习算法可以用于推荐最相关或最有趣的内容给用户。 自然语言处理和语音交互 聊天机器人 : 机器学习和自然语言处理（NLP）技术可以用于创建更自然、更智能的聊天机器人。 语音助手 : 通过机器学习，可以提高语音识别和自然语言理解的准确性，从而改善用户与语音助手的交互体验。 智能界面和自适应系统 预测性输入和自动完成 : 机器学习算法可以用于预测用户可能的下一步操作，从而提供更快捷的界面响应。 自适应界面 : 通过学习用户的行为和偏好，界面可以自动调整以适应不同用户的需求。 增强现实和虚拟现实 手势识别 : 通过机器学习算法，可以更准确地识别用户的手势，从而提供更自然的交互方式。 场景理解 : 在增强现实（AR）应用中，机器学习可以用于理解和解释现实世界的场景，以便更准确地叠加虚拟对象。 用户研究和数据分析 情感分析 : 通过分析用户的文本或语音输入，可以了解用户的情感状态，从而提供更符合情境的响应。 用户行为分析 : 机器学习算法可以用于分析大量的用户交互数据，以发现使用模式、痛点或者其他有用的信息。 辅助技术 无障碍设计 : 机器学习可以用于提高无障碍技术的准确性和可用性，例如通过视觉识别来辅助视障人士。 由于你有机器学习和算法的背景，你将能够在HCI领域中应用这些高级技术来解决复杂问题，提供更高质量的用户体验。同时，你也可以从用户研究和设计思维中获得全面的视角，这将使你在解决实际问题时更加全面和深入。 可爱捏 还是想专门开topic记录一下打印照片这可爱的介质，真的赋予了照片生命以及长久保存的意义…… 研究所项目 现在是20：40分，我要去验证舌苔项目的可行性了","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"20230830写一句","slug":"20230830写一句","date":"2023-08-30T12:22:41.000Z","updated":"2023-08-31T10:15:20.684Z","comments":true,"path":"2023/08/30/20230830写一句/","link":"","permalink":"http://jxclbx.github.io/2023/08/30/20230830%E5%86%99%E4%B8%80%E5%8F%A5/","excerpt":"","text":"部署完成 😍😍 手机里的图看来是也可以同步上来了，欧耶！ 骑回学校 均速提升至23 收到85 事实证明，有灰心里还是膈应，纠结一下要不要送修吧，送修估计是卖不得了，先用几次看看 骑车摔了一跤 好疼哈哈 总结 我觉得花一些时间让每天做过的事情留下一些痕迹总是好的……有迹可循，而不是_空空荡荡，嗡嗡作响_😂😂😂 Written with StackEdit中文版.","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"借助stackedit撰写远程日记","slug":"借助stackedit撰写远程日记","date":"2023-08-30T11:26:13.000Z","updated":"2023-08-31T04:15:25.538Z","comments":true,"path":"2023/08/30/借助stackedit撰写远程日记/","link":"","permalink":"http://jxclbx.github.io/2023/08/30/%E5%80%9F%E5%8A%A9stackedit%E6%92%B0%E5%86%99%E8%BF%9C%E7%A8%8B%E6%97%A5%E8%AE%B0/","excerpt":"","text":"欢迎来到 StackEdit 中文版！ 你好！我是你在 StackEdit中文版 中的第一个 Markdown 文件。如果你想了解 StackEdit中文版，可以阅读此文章。如果你想玩 Markdown，你也可以编辑此文章。另外，您可以通过打开导航栏左边的文件资源管理器来创建新文件。 文件 StackEdit中文版 将您的文件存储在您的浏览器中，这意味着您的所有文件都会自动保存在本地并且可以离线访问！ 创建文件和文件夹 使用导航栏左边的文件夹图标可以访问文件资源管理器。您可以通过单击文件资源管理器中的 创建文件 图标来创建新文件。您还可以通过单击 创建文件夹 图标来创建文件夹。 切换到另一个文件 您的所有文件和文件夹在文件资源管理器中都显示为树。您可以通过单击树中的文件从一个文件切换到另一个文件。 重命名文件 您可以通过单击导航栏中的文件名或单击文件资源管理器中的重命名图标来重命名当前文件。 搜索文件 您可以通过单击文件资源管理器中的搜索文件图标来通过关键字在整个文档空间中搜索文件。 删除一个文件 您可以通过单击文件资源管理器中的 删除 图标来删除当前文件。该文件将被移至 回收站 文件夹并在 7 天不活动后自动删除。 导出文件 您可以通过单击菜单中的 导入/导出 来导出当前文件。您可以选择将文件导出为纯 Markdown、使用 Handlebars 模板的 HTML 或 PDF。 同步 同步是 StackEdit中文版 的最大特点之一。它使您可以将文档空间中的任何文件与存储在Gitee 和 GitHub 账号中的其他文件同步。这使您可以继续在其他设备上写作，与您共享文件的人协作，轻松集成到您的工作流程中…同步机制在后台每分钟触发一次，下载、合并和上传文件修改。 有两种类型的同步，它们可以相互补充： 文档空间同步将自动同步您的所有文件、文件夹和设置。这将允许您在任何其他设备上获取您的文档空间。 要开始同步您的文档空间，只需在菜单中使用 Gitee 登录。 文件同步将保持文档空间的一个文件与Gitee或GitHub中的一个或多个文件同步。 在开始同步文件之前，您必须在同步子菜单中链接一个账号。 打开一个文件 您可以通过打开 同步 子菜单并单击 从…打开 从Gitee 或 GitHub 打开文件。在文档空间中打开后，文件中的任何修改都将自动同步。 保存文件 您可以通过打开 同步 子菜单并单击 在…保存 将文档空间的任何文件保存到Gitee 或 GitHub。即使文档空间中的文件已经同步，您也可以将其保存到另一个位置。 StackEdit中文版 可以将一个文件与多个位置和账号同步。 同步文件 一旦您的文件链接到同步位置，StackEdit中文版 将通过下载/上传任何修改来定期同步它。如有必要，将执行合并并解决冲突。 如果您刚刚修改了文件并且想要强制同步，请单击导航栏中的 立即同步 按钮。 注意： 如果您没有要同步的文件，立即同步按钮将被禁用。 管理文件同步 由于一个文件可以与多个位置同步，您可以通过单击同步子菜单中的文件同步列出和管理同步位置。这允许您列出和删除链接到您的文件的同步位置。 发布 在 StackEdit中文版 中发布使您可以轻松地在线发布文件。对文件感到满意后，您可以将其发布到不同的托管平台，例如 Blogger、Gitee、Gist、GitHub、WordPress 和 Zendesk。使用 Handlebars 模板，您可以完全控制导出的内容。 在开始发布之前，您必须在发布子菜单中链接一个账号。 发布文件 您可以通过打开 发布 子菜单并单击 发布到 来发布您的文件。对于某些位置，您可以选择以下格式： Markdown：在可以解释的网站上发布 Markdown 文本（例如GitHub）， HTML：通过 Handlebars 模板发布转换为 HTML 的文件（例如在博客上）。 更新发布 发布后，StackEdit中文版 会将您的文件链接到该发布，这使您可以轻松地重新发布它。一旦您修改了文件并想要更新您的发布，请单击导航栏中的立即发布按钮。 注意： 如果您没有要同步的文件，立即同步按钮将被禁用。 管理文件同步 由于一个文件可以与多个位置同步，您可以通过单击同步子菜单中的文件同步列出和管理同步位置。这允许您列出和删除链接到您的文件的同步位置。 Markdown扩展 StackEdit中文版 通过添加额外的 Markdown扩展 扩展了标准 Markdown 语法，为您提供了一些不错的功能。 提示： 您可以在 文件属性 对话框中禁用任何 Markdown 扩展名。 SmartyPants SmartyPants 将 ASCII 标点字符转换为“智能”印刷标点 HTML 实体。例如： ASCII HTML 单反引号 '这不好玩吗？' ‘这不好玩吗？’ 引用 “这不好玩吗？” “这不好玩吗？” 破折号 -- 是破折号，--- 是破折号 – 是破折号，— 是破折号 KaTeX 您可以使用 KaTeX 渲染 LaTeX 数学表达式： 满足 Γ(n)=(n−1)!∀n∈N\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb NΓ(n)=(n−1)!∀n∈N 的 Gamma 函数 是通过欧拉积分 Γ(z)=∫0∞tz−1e−tdt .\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\,. Γ(z)=∫0∞​tz−1e−tdt. 您可以在 这里 找到有关 LaTeX 数学表达式的更多信息。 UML 图 您可以使用 Mermaid 渲染 UML 图。例如，这将产生一个序列图： 123456789sequenceDiagram爱丽丝 -&gt;&gt; 鲍勃: 你好鲍勃，你好吗？鲍勃--&gt;&gt;约翰: 约翰，你呢？鲍勃--x 爱丽丝: 我很好，谢谢！鲍勃-x 约翰: 我很好，谢谢！Note right of 约翰: 鲍勃想了很长&lt;br/&gt;很长的时间，太长了&lt;br/&gt;文本确实&lt;br/&gt;不能放在一行中。鲍勃--&gt;爱丽丝: 正在和 John 核对...爱丽丝-&gt;约翰: 是的……约翰，你好吗？ 这将产生一个流程图： 12345graph LRA[长方形] -- 链接文本 --&gt; B((圆形))A --&gt; C(圆角矩形)B --&gt; D&#123;菱形&#125;C --&gt; D 图片 （将昨天功能改为把所有image以及新仓库里边的图片都复制到图床git里）将仓库克隆到本地，然后首先将其中所有图片移动到图床文件夹；将post中目前不存在的md文件复制进去，打开当前正在复制进去的文件，添加hexo的参数段；再遍历所有文件","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"测试自动图床","slug":"测试自动图床","date":"2023-08-27T17:40:04.000Z","updated":"2023-08-31T04:15:25.540Z","comments":true,"path":"2023/08/28/测试自动图床/","link":"","permalink":"http://jxclbx.github.io/2023/08/28/%E6%B5%8B%E8%AF%95%E8%87%AA%E5%8A%A8%E5%9B%BE%E5%BA%8A/","excerpt":"","text":"操，怎么就失败了呢，再试试 我好像要成功了","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"}]},{"title":"我回来了","slug":"我回来了","date":"2023-08-27T16:22:19.000Z","updated":"2023-08-31T04:15:25.540Z","comments":true,"path":"2023/08/28/我回来了/","link":"","permalink":"http://jxclbx.github.io/2023/08/28/%E6%88%91%E5%9B%9E%E6%9D%A5%E4%BA%86/","excerpt":"","text":"是的没错，很久没有更新之后，是时候来审视这个网站的作用。首先它部署在云端，让我回忆起来往昔更加容易一些……其实也并不容易，没有配图的文字确实是十分干燥，五月的事情没有配图，确实已经忘记的一干二净。其次呢，框架式的布局省去了一些排版上的麻烦，这是废话。为了把这些特性发扬出去，就需要一个提交网站的脚本……实现起来有一些技术难度，但我相信是可以攻克的，这样每时每刻想写的内容就可以及时地被记录下来，上传到图床。 明天开学，下学期能不能做的好一点呢？","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"使用Katex公式","slug":"使用Katex公式","date":"2023-06-05T03:27:41.000Z","updated":"2023-08-31T04:18:30.949Z","comments":true,"path":"2023/06/05/使用Katex公式/","link":"","permalink":"http://jxclbx.github.io/2023/06/05/%E4%BD%BF%E7%94%A8Katex%E5%85%AC%E5%BC%8F/","excerpt":"","text":"首先切换渲染器,在hexo目录下控制台执行以下代码 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-markdown-it-plus --save front-matter中写入 1katex volantis自己的_config中 1234katex: js: https://unpkg.com/katex@0.16.4/dist/katex.min.js # https://unpkg.com/katex@0.15.2/dist/katex.min.js css: https://unpkg.com/katex@0.16.4/dist/katex.min.css # https://unpkg.com/katex@0.15.2/dist/katex.min.css render: https://unpkg.com/katex@0.16.4/dist/contrib/auto-render.min.js # https://unpkg.com/katex@0.15.2/dist/contrib/auto-render.min.js","categories":[],"tags":[]},{"title":"Pytorch的奇妙体验","slug":"pytorch的奇妙体验","date":"2023-05-09T13:11:25.000Z","updated":"2023-08-31T04:18:30.949Z","comments":true,"path":"2023/05/09/pytorch的奇妙体验/","link":"","permalink":"http://jxclbx.github.io/2023/05/09/pytorch%E7%9A%84%E5%A5%87%E5%A6%99%E4%BD%93%E9%AA%8C/","excerpt":"","text":"Dataset PyTorch中的Dataset类是一个抽象基类，用于表示数据集。它定义了两个必须实现的方法：__len__() 和 __getitem__()。这个基类是通用的，但它本身无法处理特定类型的数据。因此，当您需要处理特定类型的数据（例如图像、文本等）时，您需要创建一个继承自Dataset类的自定义类，并实现这两个方法，以便根据您的数据加载和处理需求来处理数据。 在您提供的代码示例中，您创建了一个名为ImageDataset的自定义数据集类，它继承自PyTorch的Dataset类。这个类实现了 __len__() 和 __getitem__() 方法，用于处理存储为NumPy格式的图像数据。通过这种方式，您可以使用自定义的数据集类来适应您的特定数据类型和数据处理需求。 总结一下，原因在于PyTorch的Dataset类是一个通用的抽象基类，无法直接处理特n定类型的数据。因此，需要创建自定义数据集类来实现针对特定数据类型的加载和处理。 网络1 12345678910111213141516class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 32, 5, stride=1) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(32, 64, 5, stride=1) self.fc1 = nn.Linear(64 * 29 * 29, 128) self.fc2 = nn.Linear(128, 7) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 64 * 29 * 29) x = F.relu(self.fc1(x)) x = self.fc2(x) return x 效果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Epoch 1 loss: 1.622, train acc: 0.522, test acc: 0.522Epoch 2 loss: 1.012, train acc: 0.740, test acc: 0.736Epoch 3 loss: 0.707, train acc: 0.811, test acc: 0.814Epoch 4 loss: 0.581, train acc: 0.852, test acc: 0.854Epoch 5 loss: 0.501, train acc: 0.840, test acc: 0.845Epoch 6 loss: 0.416, train acc: 0.886, test acc: 0.884Epoch 7 loss: 0.385, train acc: 0.863, test acc: 0.852Epoch 8 loss: 0.334, train acc: 0.902, test acc: 0.884Epoch 9 loss: 0.315, train acc: 0.922, test acc: 0.902Epoch 10 loss: 0.255, train acc: 0.907, test acc: 0.868Epoch 11 loss: 0.247, train acc: 0.937, test acc: 0.916Epoch 12 loss: 0.193, train acc: 0.956, test acc: 0.924Epoch 13 loss: 0.158, train acc: 0.959, test acc: 0.921Epoch 14 loss: 0.149, train acc: 0.967, test acc: 0.931Epoch 15 loss: 0.132, train acc: 0.961, test acc: 0.914Epoch 16 loss: 0.117, train acc: 0.976, test acc: 0.935Epoch 17 loss: 0.091, train acc: 0.968, test acc: 0.927Epoch 18 loss: 0.084, train acc: 0.980, test acc: 0.933Epoch 19 loss: 0.073, train acc: 0.975, test acc: 0.925Epoch 20 loss: 0.060, train acc: 0.990, test acc: 0.938Epoch 21 loss: 0.060, train acc: 0.978, test acc: 0.922Epoch 22 loss: 0.063, train acc: 0.989, test acc: 0.938Epoch 23 loss: 0.048, train acc: 0.991, test acc: 0.938Epoch 24 loss: 0.042, train acc: 0.990, test acc: 0.935Epoch 25 loss: 0.035, train acc: 0.994, test acc: 0.941Epoch 26 loss: 0.036, train acc: 0.991, test acc: 0.941Epoch 27 loss: 0.029, train acc: 0.993, test acc: 0.938Epoch 28 loss: 0.033, train acc: 0.998, test acc: 0.943Epoch 29 loss: 0.038, train acc: 0.993, test acc: 0.942Epoch 30 loss: 0.026, train acc: 0.998, test acc: 0.945Epoch 31 loss: 0.017, train acc: 0.997, test acc: 0.944Epoch 34 loss: 0.021, train acc: 0.996, test acc: 0.939Epoch 35 loss: 0.017, train acc: 0.990, test acc: 0.936Epoch 36 loss: 0.020, train acc: 0.997, test acc: 0.950Epoch 37 loss: 0.014, train acc: 0.997, test acc: 0.951Epoch 38 loss: 0.011, train acc: 0.998, test acc: 0.945Epoch 39 loss: 0.007, train acc: 1.000, test acc: 0.938Epoch 40 loss: 0.011, train acc: 1.000, test acc: 0.944Epoch 41 loss: 0.007, train acc: 0.995, test acc: 0.940Epoch 42 loss: 0.012, train acc: 1.000, test acc: 0.940Epoch 43 loss: 0.008, train acc: 0.999, test acc: 0.945Epoch 44 loss: 0.009, train acc: 1.000, test acc: 0.946Epoch 45 loss: 0.007, train acc: 0.997, test acc: 0.943Epoch 46 loss: 0.007, train acc: 0.999, test acc: 0.948Epoch 49 loss: 0.009, train acc: 1.000, test acc: 0.948Epoch 50 loss: 0.004, train acc: 1.000, test acc: 0.948Finished Training 这种比较简单的网络结构可能存在一些缺陷： 模型表达能力有限：该网络的深度相对较浅，层数较少，可能无法充分提取输入数据的特征，从而导致模型表达能力不足。 容易出现过拟合：该网络没有使用正则化技术，如dropout等，容易在训练过程中出现过拟合问题，导致模型在测试集上表现不佳。 卷积核尺寸较大：该网络使用的卷积核尺寸为5，可能会导致卷积后的特征图失去一些细节信息，从而降低模型性能。 没有使用预训练模型：该网络是从头开始训练的，没有使用任何预训练模型，可能会导致训练时间较长，模型性能不佳。 以上是该网络可能存在的一些缺陷，可以通过调整网络结构、添加正则化技术、使用更小的卷积核等方式来提高模型性能。 简单提升CNN网络性能 增加了更多卷积层，批量标准化层和 Dropout 层来提高性能： 123456789101112131415161718192021222324252627282930313233343536373839class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 32, 3, padding=1) self.bn1 = nn.BatchNorm2d(32) self.conv2 = nn.Conv2d(32, 64, 3, padding=1) self.bn2 = nn.BatchNorm2d(64) self.pool = nn.MaxPool2d(2, 2) self.conv3 = nn.Conv2d(64, 128, 3, padding=1) self.bn3 = nn.BatchNorm2d(128) self.conv4 = nn.Conv2d(128, 128, 3, padding=1) self.bn4 = nn.BatchNorm2d(128) self.conv5 = nn.Conv2d(128, 256, 3, padding=1) self.bn5 = nn.BatchNorm2d(256) self.conv6 = nn.Conv2d(256, 256, 3, padding=1) self.bn6 = nn.BatchNorm2d(256) self.fc1 = nn.Linear(256 * 8 * 8, 512) self.fc2 = nn.Linear(512, 256) self.fc3 = nn.Linear(256, 7) self.dropout = nn.Dropout(p=0.5) def forward(self, x): x = self.pool(F.relu(self.bn1(self.conv1(x)))) x = self.pool(F.relu(self.bn2(self.conv2(x)))) x = F.relu(self.bn3(self.conv3(x))) x = self.pool(F.relu(self.bn4(self.conv4(x)))) x = F.relu(self.bn5(self.conv5(x))) x = self.pool(F.relu(self.bn6(self.conv6(x)))) x = x.view(-1, 256 * 8 * 8) x = self.dropout(F.relu(self.fc1(x))) x = self.dropout(F.relu(self.fc2(x))) x = self.fc3(x) return x 效果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041Epoch 1 loss: 1.625, train acc: 0.466, test acc: 0.465Epoch 2 loss: 1.146, train acc: 0.707, test acc: 0.712Epoch 3 loss: 0.603, train acc: 0.895, test acc: 0.883Epoch 4 loss: 0.313, train acc: 0.938, test acc: 0.937Epoch 5 loss: 0.175, train acc: 0.963, test acc: 0.951Epoch 6 loss: 0.135, train acc: 0.970, test acc: 0.956Epoch 7 loss: 0.092, train acc: 0.982, test acc: 0.967Epoch 8 loss: 0.071, train acc: 0.986, test acc: 0.968Epoch 9 loss: 0.055, train acc: 0.988, test acc: 0.971Epoch 10 loss: 0.043, train acc: 0.990, test acc: 0.971Epoch 11 loss: 0.036, train acc: 0.995, test acc: 0.968Epoch 12 loss: 0.028, train acc: 0.994, test acc: 0.979Epoch 13 loss: 0.024, train acc: 0.996, test acc: 0.977Epoch 14 loss: 0.016, train acc: 0.998, test acc: 0.977Epoch 15 loss: 0.017, train acc: 0.997, test acc: 0.978Epoch 16 loss: 0.017, train acc: 0.997, test acc: 0.978Epoch 17 loss: 0.015, train acc: 0.998, test acc: 0.981Epoch 18 loss: 0.013, train acc: 0.998, test acc: 0.979Epoch 19 loss: 0.010, train acc: 0.998, test acc: 0.976Epoch 20 loss: 0.008, train acc: 0.999, test acc: 0.978Epoch 21 loss: 0.008, train acc: 0.999, test acc: 0.980Epoch 22 loss: 0.007, train acc: 0.998, test acc: 0.980Epoch 23 loss: 0.006, train acc: 1.000, test acc: 0.979Epoch 24 loss: 0.005, train acc: 0.999, test acc: 0.978Epoch 25 loss: 0.006, train acc: 0.999, test acc: 0.977Epoch 26 loss: 0.005, train acc: 1.000, test acc: 0.979Epoch 27 loss: 0.005, train acc: 1.000, test acc: 0.977Epoch 28 loss: 0.004, train acc: 0.999, test acc: 0.978Epoch 29 loss: 0.005, train acc: 0.999, test acc: 0.976Epoch 30 loss: 0.004, train acc: 0.999, test acc: 0.982Epoch 31 loss: 0.004, train acc: 1.000, test acc: 0.977Epoch 32 loss: 0.006, train acc: 0.999, test acc: 0.979Epoch 33 loss: 0.005, train acc: 1.000, test acc: 0.978Epoch 34 loss: 0.004, train acc: 0.999, test acc: 0.976Epoch 35 loss: 0.003, train acc: 1.000, test acc: 0.982Epoch 36 loss: 0.003, train acc: 1.000, test acc: 0.977Epoch 37 loss: 0.003, train acc: 1.000, test acc: 0.979Epoch 38 loss: 0.003, train acc: 1.000, test acc: 0.976Epoch 39 loss: 0.003, train acc: 1.000, test acc: 0.979Epoch 40 loss: 0.002, train acc: 1.000, test acc: 0.982Epoch 41 loss: 0.002, train acc: 1.000, test acc: 0.980 网络2（Resnet） 拟合速度更快，准确率更高的网络是残差网络（ResNet）。 ResNet是由微软提出的深度残差网络，其主要思想是通过引入残差连接来解决网络退化问题，从而允许网络更深更广，并提高了模型准确率和泛化能力。ResNet常用的版本包括ResNet-18、ResNet-34、ResNet-50、ResNet-101和ResNet-152等。 相比于其他深度神经网络，ResNet的优点有： 更快的训练速度：ResNet通过残差连接解决了梯度消失问题，使得网络可以更深更宽，从而能够更好地拟合数据，提高了训练速度。 更好的泛化能力：残差连接允许网络跨层直接传递信息，避免了信息的损失，使得网络可以更好地学习到数据的特征，提高了模型的泛化能力。 更高的准确率：ResNet通过引入残差连接，使得网络可以更深更宽，提高了模型的表达能力，从而能够更好地拟合数据，提高了模型的准确率。 但是，相比于其他深度神经网络，ResNet占用更多的显存，需要更多的计算资源来训练。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class BasicBlock(nn.Module): def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(BasicBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channels) self.relu = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample: residual = self.downsample(x) out += residual out = self.relu(out) return outclass ResNet(nn.Module): def __init__(self, block, layers, num_classes=7): super(ResNet, self).__init__() self.in_channels = 64 self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(64) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self.make_layer(block, 64, layers[0]) self.layer2 = self.make_layer(block, 128, layers[1], 2) self.layer3 = self.make_layer(block, 256, layers[2], 2) self.layer4 = self.make_layer(block, 512, layers[3], 2) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512, num_classes) def make_layer(self, block, out_channels, blocks, stride=1): downsample = None if stride != 1 or self.in_channels != out_channels: downsample = nn.Sequential( nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(out_channels) ) layers = [] layers.append(block(self.in_channels, out_channels, stride, downsample)) self.in_channels = out_channels for _ in range(1, blocks): layers.append(block(out_channels, out_channels)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = x.view(x.size(0), -1) x = self.fc(x) return x Resnet存在着如下几个问题 网络的深度限制：尽管ResNet的提出解决了深度神经网络的梯度消失问题，但是当网络的深度增加时，ResNet仍然会出现梯度消失和梯度爆炸的问题。这限制了ResNet的深度。 特征重复利用不充分：在ResNet中，残差块中的特征并没有充分地被重复利用。相对于DenseNet，ResNet的特征传递方式是逐级传递，即特征只在当前和下一个块之间传递，而不是在所有块之间传递。 训练时间较长：由于ResNet是一个非常深的网络，所以它的训练时间会比较长，特别是当训练数据集很大时。 1234567891011121314151617181920212223242526272829Epoch 1 loss: 1.333, train acc: 0.757, test acc: 0.734Epoch 2 loss: 0.492, train acc: 0.938, test acc: 0.904Epoch 3 loss: 0.171, train acc: 0.982, test acc: 0.951Epoch 4 loss: 0.061, train acc: 0.996, test acc: 0.956Epoch 5 loss: 0.026, train acc: 0.999, test acc: 0.960Epoch 6 loss: 0.012, train acc: 1.000, test acc: 0.960Epoch 7 loss: 0.006, train acc: 1.000, test acc: 0.962Epoch 8 loss: 0.005, train acc: 1.000, test acc: 0.964Epoch 9 loss: 0.004, train acc: 1.000, test acc: 0.963Epoch 10 loss: 0.003, train acc: 1.000, test acc: 0.964Epoch 11 loss: 0.003, train acc: 1.000, test acc: 0.964Epoch 12 loss: 0.002, train acc: 1.000, test acc: 0.964Epoch 13 loss: 0.002, train acc: 1.000, test acc: 0.964Epoch 14 loss: 0.002, train acc: 1.000, test acc: 0.963Epoch 15 loss: 0.002, train acc: 1.000, test acc: 0.964Epoch 16 loss: 0.002, train acc: 1.000, test acc: 0.963Epoch 17 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 18 loss: 0.001, train acc: 1.000, test acc: 0.962Epoch 19 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 20 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 21 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 22 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 23 loss: 0.001, train acc: 1.000, test acc: 0.964Epoch 24 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 25 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 26 loss: 0.001, train acc: 1.000, test acc: 0.964Epoch 27 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 28 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 29 loss: 0.001, train acc: 1.000, test acc: 0.963 网络3（DenseNet） 在DenseNet中，每个层的输出都会被连接到后续所有层的输入中，这使得每个层都可以直接获取到之前所有层的特征图，从而增加了特征重用的程度，避免了特征的浪费。在DenseNet中，特征图之间的连接可以使用张量拼接（concatenate）来实现。 具体地，DenseNet可以由多个密集块（Dense Block）和一个全局池化层（Global Pooling Layer）组成。每个密集块由多个卷积层和一个批量归一化层（Batch Normalization Layer）组成，卷积层的输出将被拼接到后续所有卷积层的输入中。全局池化层的输出将被送入一个全连接层和一个Softmax层中进行分类。 DenseNet的优点包括： 特征重用程度高：在DenseNet中，每个层都可以直接获取到之前所有层的特征图，从而增加了特征重用的程度，避免了特征的浪费。 模型参数较少：在DenseNet中，由于特征图之间的连接可以使用张量拼接来实现，所以模型参数较少。 准确率高：DenseNet在图像分类等任务上表现出色，达到了当时最好的性能。 然而，DenseNet也有一些缺点，如模型计算量较大、模型结构复杂等。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182class DenseLayer(nn.Module): def __init__(self, in_channels, growth_rate): super(DenseLayer, self).__init__() self.bn1 = nn.BatchNorm2d(in_channels) self.conv1 = nn.Conv2d(in_channels, growth_rate * 4, kernel_size=1, stride=1, bias=False) self.bn2 = nn.BatchNorm2d(growth_rate * 4) self.conv2 = nn.Conv2d(growth_rate * 4, growth_rate, kernel_size=3, stride=1, padding=1, bias=False) def forward(self, x): out = self.bn1(x) out = F.relu(out) out = self.conv1(out) out = self.bn2(out) out = F.relu(out) out = self.conv2(out) out = torch.cat((x, out), 1) return outclass DenseBlock(nn.Module): def __init__(self, in_channels, growth_rate, num_layers): super(DenseBlock, self).__init__() self.layers = nn.ModuleList([DenseLayer(in_channels + i * growth_rate, growth_rate) for i in range(num_layers)]) def forward(self, x): for layer in self.layers: x = layer(x) return xclass TransitionLayer(nn.Module): def __init__(self, in_channels, out_channels): super(TransitionLayer, self).__init__() self.bn = nn.BatchNorm2d(in_channels) self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False) def forward(self, x): out = self.bn(x) out = F.relu(out) out = self.conv(out) out = F.avg_pool2d(out, 2) return outclass DenseNet(nn.Module): def __init__(self, growth_rate, block_config, num_classes=7): super(DenseNet, self).__init__() self.conv1 = nn.Conv2d(3, growth_rate * 2, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(growth_rate * 2) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) in_channels = growth_rate * 2 self.dense_blocks = nn.ModuleList() self.transition_layers = nn.ModuleList() for i, num_layers in enumerate(block_config): dense_block = DenseBlock(in_channels, growth_rate, num_layers) self.dense_blocks.append(dense_block) in_channels += num_layers * growth_rate if i != len(block_config) - 1: transition_layer = TransitionLayer(in_channels, in_channels // 2) self.transition_layers.append(transition_layer) in_channels = in_channels // 2 self.bn2 = nn.BatchNorm2d(in_channels) self.fc = nn.Linear(in_channels, num_classes) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) for i, dense_block in enumerate(self.dense_blocks): x = dense_block(x) if i != len(self.dense_blocks) - 1: x = self.transition_layers[i](x) x = self.bn2(x) x = F.relu(x) x = F.adaptive_avg_pool2 效果如下； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748Epoch 1 loss: 1.401, train acc: 0.684, test acc: 0.669Epoch 2 loss: 0.556, train acc: 0.945, test acc: 0.921Epoch 3 loss: 0.188, train acc: 0.984, test acc: 0.951Epoch 4 loss: 0.074, train acc: 0.997, test acc: 0.956Epoch 5 loss: 0.024, train acc: 1.000, test acc: 0.965Epoch 6 loss: 0.012, train acc: 1.000, test acc: 0.966Epoch 7 loss: 0.007, train acc: 1.000, test acc: 0.964Epoch 8 loss: 0.005, train acc: 1.000, test acc: 0.965Epoch 9 loss: 0.004, train acc: 1.000, test acc: 0.967Epoch 10 loss: 0.003, train acc: 1.000, test acc: 0.966Epoch 11 loss: 0.003, train acc: 1.000, test acc: 0.965Epoch 12 loss: 0.003, train acc: 1.000, test acc: 0.966Epoch 13 loss: 0.002, train acc: 1.000, test acc: 0.967Epoch 14 loss: 0.002, train acc: 1.000, test acc: 0.967Epoch 15 loss: 0.002, train acc: 1.000, test acc: 0.966Epoch 16 loss: 0.002, train acc: 1.000, test acc: 0.967Epoch 17 loss: 0.002, train acc: 1.000, test acc: 0.966Epoch 18 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 19 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 20 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 21 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 22 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 23 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 24 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 25 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 26 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 27 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 28 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 29 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 30 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 31 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 34 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 36 loss: 0.001, train acc: 1.000, test acc: 0.968Epoch 37 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 38 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 39 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 40 loss: 0.001, train acc: 1.000, test acc: 0.968Epoch 41 loss: 0.001, train acc: 1.000, test acc: 0.968Epoch 42 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 43 loss: 0.000, train acc: 1.000, test acc: 0.967Epoch 44 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 45 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 46 loss: 0.000, train acc: 1.000, test acc: 0.967Epoch 47 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 48 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 49 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 50 loss: 0.000, train acc: 1.000, test acc: 0.968Finished Training 提高准确度方法： 调整超参数：尝试不同的学习率、批量大小、优化器和权重衰减。可以使用网格搜索或随机搜索找到最佳超参数组合。同时，可以考虑使用学习率调度器逐渐降低学习率。 更深或更宽的模型：尝试使用更复杂的模型，如更深或更宽的 ResNet、DenseNet 或其他现代架构。通常，更复杂的模型具有更大的表示能力，可以提高性能。 数据增强：使用数据增强技术，如随机旋转、翻转、缩放、剪裁和亮度调整等，可以扩展训练数据集并提高模型泛化能力。 正则化：使用正则化技术，如 L1 或 L2 正则化、Dropout 或 Batch Normalization，可以减轻过拟合并提高模型泛化能力。 更多数据：如果可能，尝试收集更多的训练数据。更多的数据有助于模型学习更多的特征，从而提高准确性。 早停法：在验证集上监控模型性能，当性能不再提高时，提前停止训练。这有助于防止过拟合。 预训练模型：使用预训练的模型作为初始模型，然后在您的数据集上进行微调。这样可以利用在大型数据集上学到的特征，加速收敛并提高性能。 集成方法：训练多个模型并将它们的输出结合起来。这可以是简单的平均，或者可以使用更复杂的技术，如投票或模型堆叠。这有助于提高模型的稳定性和准确性。 数据增强 与上文不同，我在加入高斯噪声的基础上加入了图像旋转变换来提高模型的泛化能力 损失函数 要改善模型的训练效果，您可以尝试使用其他损失函数。这里我使用Label Smoothing Cross Entropy损失。可以提高模型的泛化能力，因为它在训练过程中为模型提供了额外的正则化。 12345678910111213141516class LabelSmoothingCrossEntropy(nn.Module): def __init__(self, eps=0.1, reduction=&#x27;mean&#x27;): super(LabelSmoothingCrossEntropy, self).__init__() self.eps = eps self.reduction = reduction def forward(self, output, target): c = output.size(1) log_preds = F.log_softmax(output, dim=1) loss = F.nll_loss(log_preds, target, reduction=self.reduction) smooth_loss = -log_preds.mean(dim=1) if self.reduction == &#x27;mean&#x27;: smooth_loss = smooth_loss.mean() elif self.reduction == &#x27;sum&#x27;: smooth_loss = smooth_loss.sum() return loss * (1 - self.eps) + smooth_loss * self.eps BATCH_SIZE Batch size的选择对模型的训练效果和收敛速度有很大影响。然而，并没有一个固定的答案来确定最佳的batch size。 训练稳定性和收敛速度 ：较大的batch size可以让梯度下降过程更稳定，因为每个batch的平均梯度对噪声更不敏感。然而，大的batch size可能会导致训练过程收敛速度变慢，因为每次迭代更新权重的次数减少了。相反，较小的batch size可以提高训练速度，因为每个epoch内权重更新的次数增加，但可能会导致训练过程不稳定，这是由于小batch size中噪声较多。 泛化能力 ：有研究表明，较小的batch size可能有助于提高模型的泛化能力。这可能是因为较小的batch size在训练过程中引入了随机性和正则化，从而防止模型过拟合。 训练时间 ：较大的batch size可以减少每个epoch所需的迭代次数，从而减少同步和数据传输的开销，提高计算资源的利用率。但是，如果batch size过大，可能会导致GPU内存不足，进而影响训练速度。","categories":[{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/categories/CV/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/tags/CV/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://jxclbx.github.io/tags/Pytorch/"}]},{"title":"网页设计与制作作业2","slug":"网页设计与制作作业2","date":"2023-05-09T05:55:09.000Z","updated":"2023-08-31T10:15:20.546Z","comments":true,"path":"2023/05/09/网页设计与制作作业2/","link":"","permalink":"http://jxclbx.github.io/2023/05/09/%E7%BD%91%E9%A1%B5%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%B6%E4%BD%9C%E4%BD%9C%E4%B8%9A2/","excerpt":"","text":"阐述 CSS 盒模型原理 CSS盒模型是CSS中最基础的概念之一，它描述了一个元素在网页中的呈现方式。盒模型将一个元素看做是一个矩形盒子，由四个部分组成：内容区域（content）、内边距区域（padding）、边框区域（border）和外边距区域（margin）。 内容区域，也就是元素内部实际显示内容的区域。比如div元素，它的内容区域就是它所包含的文字、图片、列表等内容。 内边距区域，它是在内容区域和边框之间的空白区域，它为元素的内容提供空间。可以设置背景颜色、背景图片等样式属性。可以通过设置padding属性来调整内边距的大小。 边框区域，它包围着内边距和内容区域，并为元素提供了可见的边界。可以通过设置border属性来调整边框的大小、样式和颜色。 外边距区域，它是元素边框与相邻元素边框之间的空白区域。可以通过设置margin属性来调整外边距的大小。 举例阐述 CSS 中几种常用的选择器 通配符选择器（Wildcard Selector）：使用 * 选择器可以匹配页面上的所有元素。 标签选择器（Tag Selector）：使用标签名称作为选择器，例如 div、p、h1，可以选择指定类型的元素。 ID 选择器（ID Selector）：使用 # 加上元素的唯一标识符，例如 #myId，可以选择具有指定 ID 的元素。ID 应在页面中是唯一的。 类选择器（Class Selector）：使用 . 加上类名，例如 .myClass，可以选择具有指定类名的元素。多个元素可以共享相同的类。 伪类选择器（Pseudo-Class Selector）：使用 : 加上伪类名，例如 :hover、:first-child，可以选择特定状态或位置的元素。伪类可以根据用户交互或元素的位置进行选择。 具体效果剪文件夹内代码 举例阐述 CSS 几种定位方式 绝对定位（Absolute Positioning）：使用 position: absolute; 将元素的位置相对于其最近的已定位祖先元素进行定位，如果没有已定位的祖先元素，则相对于文档的窗口进行定位。通过使用 top、bottom、left 和 right 属性，可以精确控制元素在页面上的位置。 相对定位（Relative Positioning）：使用 position: relative; 将元素相对于其正常位置进行定位。相对定位不会改变其他元素的布局，仍会占据原来的空间。通过使用 top、bottom、left 和 right 属性，可以相对于元素的正常位置调整其位置。 固定定位（Fixed Positioning）：使用 position: fixed; 将元素的位置相对于视口（浏览器窗口）进行定位，无论页面滚动与否，元素都会保持在固定的位置。通过使用 top、bottom、left 和 right 属性，可以确定元素在视口中的具体位置。 浮动定位（Float Positioning）：使用 float 属性将元素从正常的文档流中浮动到指定的位置。浮动元素可以向左或向右浮动，并使其周围的元素环绕在其周围。浮动通常用于创建多列布局。 做一个 CSS 3动画 使用了 CSS 的样式和关键帧动画来实现了一个动画效果，通过定义样式和应用动画属性创建了一个渐变放大和旋转的圆形元素，并在动画结束后以渐变放大的方式显示了一段文字。 linear-gradient()：渐变函数用于创建线性渐变背景。在 .circle 类的样式中，使用了 linear-gradient(45deg, #ff8a00, #e52e71, #4c4c4c) 来创建一个从斜角 45 度开始的线性渐变背景。 border-radius：用于设置元素的边框圆角。在 .circle 类的样式中，使用了 border-radius: 50% 来将元素设置为一个圆形。 transform：用于对元素进行变换，例如旋转、缩放、平移等。在 .circle 和 .text 类的样式中，使用了 transform: translate(-50%, -50%) scale(0) 来设置元素的初始位置和大小。 animation 和 @keyframes：这是 CSS3 中用于创建动画的特性。在 .circle 和 .text 类的样式中，使用了 animation 属性来指定动画名称、持续时间、缓动函数和循环次数等。而 @keyframes 则定义了关键帧动画的不同阶段和样式","categories":[{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/categories/HTML/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"},{"name":"网页","slug":"网页","permalink":"http://jxclbx.github.io/tags/%E7%BD%91%E9%A1%B5/"}]},{"title":"快速使用VSCode编写HTML文件","slug":"快速使用VSCode编写HTML文件","date":"2023-05-09T05:33:11.000Z","updated":"2023-09-01T03:12:03.659Z","comments":true,"path":"2023/05/09/快速使用VSCode编写HTML文件/","link":"","permalink":"http://jxclbx.github.io/2023/05/09/%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8VSCode%E7%BC%96%E5%86%99HTML%E6%96%87%E4%BB%B6/","excerpt":"","text":"安装 安装相关插件——搜索html,安装如下插件 再次打开插件商店，搜索open in browser 回到你的html文件，ctrl+s保存文件，然后shift+alt+b，在弹出的窗口中输入open in ,选择open in Other Browsers,如图(或者右键文件空白处，如图二红箭头所指向的两个，一个是用默认浏览器，一个是用其他浏览器。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"http://jxclbx.github.io/tags/vscode/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"}]},{"title":"Hexo博客自定义页面跳过渲染","slug":"Hexo博客自定义页面跳过渲染","date":"2023-05-08T07:39:01.000Z","updated":"2023-08-31T04:18:30.947Z","comments":true,"path":"2023/05/08/Hexo博客自定义页面跳过渲染/","link":"","permalink":"http://jxclbx.github.io/2023/05/08/Hexo%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2%E8%B7%B3%E8%BF%87%E6%B8%B2%E6%9F%93/","excerpt":"","text":"Hexo自定义原理 Hexo 系列的博客中的文章都是经Hexo的主题渲染的静态网页。所以Hexo博客大部分都呈现出一种高度的统一化与规范化。不过 Hexo 提供了跳过渲染功能，使得我们可以直接在博客中放入自定义网页。 比如在博客中放入图片、自定义404.html、自定义About页面、简历等 创建自定义网页 网页可以是自己编写的，也可以是别人现成的源码（下载喜欢的页面）。 网页编写完成后，在Hexo\\source目录下创建一个文件夹（文件夹名称任意，比如我创建的是about这个文件夹，部署完成后，访问http://mrlsm.github.io/about即可看到效果，依此类推） 将 html 文件放置于此文件夹，并重命名为 index.html 。 跳过渲染 跳过渲染有下述两种方法： 在自定义页面的开头添加如下： 123---layout: false--- 添加该指令后，执行 hexo g命令时便会跳过该 index.html文件，使得index.html不受当前 hexo 主题影响，完全是一个独立的网页，如果网页引用了 css 或 js，css 和 js 需使用外链或者将css js 文件放入index.html同目录下引用。 引用图片亦是如此 在_config.yml文件中设置skip_render 使用编辑器打开 Hexo 目录下的_config.yml文件，找到skip_render skip_render一般有以下四种常用参数： 跳过source目录下的 test.html: skip_render: test.html 跳过source目录下 test 文件夹内所有文件：skip_render: test/* 跳过source目录下 test 文件夹内所有文件包括子文件夹以及子文件夹内的文件：skip_render: test/** 跳过多个路径： 123skip_render:- curriculumVitae/**- DecrypeMusic/** 最后执行 1hexo g -d","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://jxclbx.github.io/tags/hexo/"},{"name":"音乐","slug":"音乐","permalink":"http://jxclbx.github.io/tags/%E9%9F%B3%E4%B9%90/"}]},{"title":"算法设计实验题目","slug":"算法设计实验题目","date":"2023-05-06T08:37:01.000Z","updated":"2023-08-31T04:15:25.541Z","comments":true,"path":"2023/05/06/算法设计实验题目/","link":"","permalink":"http://jxclbx.github.io/2023/05/06/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E5%AE%9E%E9%AA%8C%E9%A2%98%E7%9B%AE/","excerpt":"","text":"GS算法匹配小狗狗 忘了 BFS DFS树的层序遍历（3月29日） 4.5没上课","categories":[{"name":"算法设计课程","slug":"算法设计课程","permalink":"http://jxclbx.github.io/categories/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"算法","slug":"算法","permalink":"http://jxclbx.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Anaconda配置PyTorch环境","slug":"Anaconda配置PyTorch环境","date":"2023-05-05T14:36:39.000Z","updated":"2023-08-31T04:15:25.533Z","comments":true,"path":"2023/05/05/Anaconda配置PyTorch环境/","link":"","permalink":"http://jxclbx.github.io/2023/05/05/Anaconda%E9%85%8D%E7%BD%AEPyTorch%E7%8E%AF%E5%A2%83/","excerpt":"","text":"在Anaconda下安装Pytorch 安装pytorch，有两种办法，一是pip，二是conda。不管什么样的方法，首先，都要安装最新的anaconda。 安装Anaconda Anaconda指的是一个开源的Python发行版本，其包含了conda、Python等180多个科学包及其依赖项。里面所包含的Jupyter Notebook是数据挖掘领域中最热门的工具。(例如Kaggle网站) 没安装Anaconda的小伙伴可以参考以下安装链接： https://blog.csdn.net/qq_4521807/article/details/112442577 安装Pytorch 打开Anaconda Prompt 在命令行格式下，输入代码，完成调用清华镜像、建立pytorch环境、安装pytorch、测试pytorch过程 调用清华镜像 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ 1conda config --set show_channel_urls yes 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ 这个配置好以后，以后再安装其他的软件如果要用到清华镜像源网站就不用了重新配置了。 注意！如果切换镜像后当出现下载不了的情况，就先切换默认源，然后再修改另一个可以使用的conda源（一定要先恢复默认，再换另一个！！！） 切回默认源： 1conda config --remove-key channels 创建Pytorch环境 说真的，别在命令行里费那劲了，给你个GUI为嘛不用呢 1conda create -n pytorch python=3.7 查看环境是否安装成功 1conda info --envs 下载Pytorch 根据自己的安装版本，在Pytorch官网寻找安装命令代码：Pytorch官网：https://pytorch.org/ 查看CUDA版本 nvidia-smi solve environment需要比较长的时间，换了清华源之后就基本不需要挂梯子了 等待安装完成出现done 此时在vscode中可以在python解释器选择里看到pytorch环境的解释器： 按下F1键选择解释器，结束。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"anaconda","slug":"anaconda","permalink":"http://jxclbx.github.io/tags/anaconda/"},{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"}]},{"title":"Anaconda常用操作","slug":"Anaconda常用配置","date":"2023-05-04T09:30:21.000Z","updated":"2023-08-31T04:18:30.946Z","comments":true,"path":"2023/05/04/Anaconda常用配置/","link":"","permalink":"http://jxclbx.github.io/2023/05/04/Anaconda%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/","excerpt":"","text":"在使用 python anaconda时，经常会用到很多常用操作，记录下来，方便以后更好地使用： Conda Conda既是一个包管理器又是一个环境管理器。你肯定知道包管理器，它可以帮你发现和查看包。但是如果当我们想要安装一个包，但是这个包只支持跟我们目前使用的python不同的版本时。你只需要几行命令，就可以搭建起一个可以运行另外python版本的环境。这就是conda环境管理器的强大功能。 Conda常用命令 1conda update conda # 升级conda 12conda create -n pytorch1 python=3 Astroid Babel#创建基于python3 ，包含Astroid 和 Babel 包，称为pytorch1的新环境，在/envs/bunnies文件夹里 123# 查看当前可用环境conda env list conda info --envs 123# 切换工作环境conda activate baseconda deactivate 123456# 复制一个环境conda create -n flowers --clone snowflakes # 重新命名：先 clone 一份 new name 的环境；删除 old name 的环境；conda create -n tf --clone rcnn # 克隆conda remove -n rcnn --all # 删除conda info -e # 重新查看环境 123# 删除一个环境conda remove -n flowers --allconda info -e # 查看是否环境已经成功被移除 12345678# 管理Python环境# 检查python版本conda search --full --name python conda search python # 使用模糊匹配 # 安装一个新的版本 conda create -n snakes python=3# 查看已经安装的环境 conda info -e 123456789101112# 管理包# 查看当前环境中包含的包和其版本列表 conda list # 查找一个包conda search beautifulsoup4 # 安装一个包conda install --name bunnies beautifulsoup4 # 你必须告诉conda你要安装环境的名字（-n bunies）否则它将会被安装到当前环境中 # 使用 pip 安装一个包，并可使用 conda list 进行查看；pip install see conda list 123# 删除整个anaconda rm -rf ~/miniconda OR rm -rf ~/anaconda # 直接删除整个文件夹，并去除.bashrc 中的配置文件即可，对环境影响较少；","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"anaconda","slug":"anaconda","permalink":"http://jxclbx.github.io/tags/anaconda/"},{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"}]},{"title":"站内搜索","slug":"站内搜索","date":"2023-05-03T05:46:39.000Z","updated":"2023-08-31T04:18:30.951Z","comments":true,"path":"2023/05/03/站内搜索/","link":"","permalink":"http://jxclbx.github.io/2023/05/03/%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2/","excerpt":"","text":"站内搜索 配置代码 1234567891011121314# To use hexo search, you need to install the following plugins:# npm i hexo-generator-json-contentsearch: enable: true service: hexo # hexo, algolia, meilisearch algolia: searchAsYouType: true # If false, triggers the search only on submit. hitsPerPage: 5 # Set the number of hits per page. placeholder: &#x27;Search...&#x27; # The placeholder text of the input. meilisearch: placeholder: &#x27;Search...&#x27; searchKey: &#x27;&#x27; indexName: &#x27;&#x27; hostUrl: &#x27;&#x27; 显然这段没啥用，因为我们不需要使用algolia搜索等等 你需要安装 hexo-generator-json-content，并根据它的文档去做相应配置。 修改 主题配置文件 。 123search: enable: true service: hexo","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://jxclbx.github.io/tags/hexo/"},{"name":"站内搜索","slug":"站内搜索","permalink":"http://jxclbx.github.io/tags/%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2/"}]},{"title":"Github+jsDelivr搭建个人图床","slug":"Github-jsDelivr搭建个人图床","date":"2023-05-02T16:13:51.000Z","updated":"2023-08-31T04:15:25.534Z","comments":true,"path":"2023/05/03/Github-jsDelivr搭建个人图床/","link":"","permalink":"http://jxclbx.github.io/2023/05/03/Github-jsDelivr%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%9B%BE%E5%BA%8A/","excerpt":"","text":"Github+jsDelivr图床 经常写博文的朋友对床图肯定不陌生。使用markdown撰写博客，将图片放在床图网站生成外链统一管理，这样一份博文就可以发布在不同的平台，也避免了不同网页对同一张图片引用的。不过免费的床图网站有时不稳定，付费价格又都不便宜。 最近了解到了Github+jsDelivr的方式搭建个人床图，稳定快速免费。 搭建方法也比较简单，本文默认已经： 有Github账号 通过SSH与本地Git绑定 掌握基本的Git操作 那么，搭建床图仅需三步。 在GIthub建立一个仓库 在创建GitHub仓库并与本地Git绑定中已经完成 将本地图片push到仓库 先将建好的仓库clone到本地 将需要上传的图片添加到对应文件夹 git push 图片就是保存在github仓库，每个仓库有1个G的容量限制。1个G？不叫事，那能存很多图片。如果你图片存满，那再建个新仓库就是了。 Github的资源在国内加载速度比较慢，所以需要用到CDN技术来加速。 CDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。 jsDelivr(https://cdn.jsdelivr.net)就是一种免费且快速的CDN，通过jsDelivr引用资源GIthub图片资源，即可实现图片加速。所以接下来的第三步，改写一下链接就搞定了。主题内部也是用了这种方法。 通过jsDelivr引用资源 使用方法： 1https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@发布的版本号/文件路径 此处 1https://cdn.jsdelivr.net/gh/jxclbx/blogImages/文件路径 例如访问https://cdn.jsdelivr.net/gh/jxclbx/blogImages/imageSource/bg.jpg 得到如下效果： 图床接入 markdown的图片URL可以填入网络地址，并且paste image插件所输出的格式就是标准的markdown格式，而不是hexo的引用图片格式，我们只需在写完一篇blog后，多加入一步上传图片到github的步骤即可。 在merge后，直接将md文件中的url做替换，加入 1https://cdn.jsdelivr.net/gh/jxclbx/blogImages/imagePost/ 即可完成。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"图床","slug":"图床","permalink":"http://jxclbx.github.io/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"jsDelivr","slug":"jsDelivr","permalink":"http://jxclbx.github.io/tags/jsDelivr/"},{"name":"git","slug":"git","permalink":"http://jxclbx.github.io/tags/git/"}]},{"title":"创建GitHub仓库并与本地Git绑定","slug":"创建GitHub仓库并与本地Git绑定","date":"2023-05-02T13:40:34.000Z","updated":"2023-08-31T04:15:25.539Z","comments":true,"path":"2023/05/02/创建GitHub仓库并与本地Git绑定/","link":"","permalink":"http://jxclbx.github.io/2023/05/02/%E5%88%9B%E5%BB%BAGitHub%E4%BB%93%E5%BA%93%E5%B9%B6%E4%B8%8E%E6%9C%AC%E5%9C%B0Git%E7%BB%91%E5%AE%9A/","excerpt":"","text":"为了创建一个图床 有Github账号 通过SSH与本地Git绑定 掌握基本的Git操作 这三步是缺一不可的，现在先来将SSH绑定git 创建一个新的仓库 我们点击“New repository”创建一个新的仓库： 得到SSH地址 绑定SSH 双击git-bash.exe，在本地创建ssh key： 1ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot; 然后成功后会在User文件夹对应的用户下创建.ssh文件夹，其中有一个id_rsa.pub文件，我们复制其中的key: 之后返回github，进入 Account Settings（账户配置），左边选择SSH and GPG Keys选项 其中的title随便填，下面的粘贴在你电脑上生成的key。点击添加之后，则添加成功： 验证是否绑定本地成功，在git-bash中验证，输入指令： 1ssh -T git@github.com 如果第一次执行该指令，则会提示是否continue继续，如果我们输入yes就会看到成功信息： 1ssh -T git@github.com github不支持shell这个可以忽略。 1Hi jxclbx! You&#x27;ve successfully authenticated, but GitHub does not provide shell access. Git操作 由于GitHub每次执行commit操作时，都会记录username和email，所以要设置它们： 12git config --global user.name &quot;jxclbx&quot;git config --global user.email &quot;13001392777@163.com&quot; Clone到本地 1git clone git@github.com:jxclbx/blogImages.git 此时在目录下会到一个隐藏的.git文件夹，该文件夹是Git用来跟踪管理版本库的，然后将所有文件添加到仓库，并提交文件： 1git add . 1git commit -m &quot; &quot; Add &amp; Commit git commit 是 Git 版本控制系统中用于保存本地仓库更改的命令。当你在本地 Git 仓库中更改文件时，可以使用 git commit 创建一个新的快照并将其添加到 Git 历史记录中。这有助于跟踪你随着时间推移所做的更改并与其他人共同开发同一项目。 要使用 git commit，你首先需要使用 git add 将要提交的更改加入到暂存区中。这告诉 Git 你想要包含在提交中的更改内容。一旦你将更改加入到暂存区中，就可以使用以下命令将其提交： -m 标志用于添加提交信息，描述你所做的更改。编写清晰和描述性的提交信息非常重要，这样其他开发人员可以轻松地理解你所做的更改。 如果你想在提交中包含工作目录中的所有更改，可以使用以下命令： 1git commit -a -m &quot;提交信息&quot; -a 标志告诉 Git 自动将仓库中所有已修改或已删除的更改加入到暂存区中。 提交完成后，可以将其推送到远程仓库以与他人共享更改或保留更改的备份。 暂存区 暂存区是 Git 版本控制系统中的一个概念，它是介于工作目录和 Git 仓库之间的一个中间状态，也被称为 Git 的“索引”（index）。它是用于临时存储已修改或已删除文件的地方，以便在下一次提交时包含这些更改。 暂存区在本地 Git 仓库的 .git 目录中的 index 文件中。每次使用 git add 命令将文件添加到暂存区时，Git 会将这些更改写入 index 文件中。在执行 git commit 命令之前，你可以使用 git status 命令来查看哪些文件已经被添加到暂存区，哪些文件还未被添加。 需要注意的是，暂存区只是一个中间状态，只有执行 git commit 命令将暂存区中的更改提交到 Git 仓库后，这些更改才会被永久保存下来。如果你在暂存区中添加了一个文件，但之后又对该文件进行了修改，那么只有重新使用 git add 命令将该文件添加到暂存区，之后再使用 git commit 命令才能将最新的更改提交到 Git 仓库中。 关于远程仓库：remote 在 Git 中，remote 表示远程仓库的别名或名称。当你从远程仓库中获取代码或将代码推送到远程仓库时，需要使用远程仓库的名称。为了方便起见，Git 允许为每个远程仓库分配一个别名，这个别名就是 remote。 在 git remote add 命令中，remote 参数指定了新远程仓库的名称或别名，origin 就是一个常用的远程仓库别名。在这个命令中，origin 将被用作指向远程仓库的别名，而 git@github.com:jxclbx/blogImages.git 则是该远程仓库的 URL。这个命令将把远程仓库 git@github.com:jxclbx/blogImages.git 添加到本地 Git 仓库中，并将其命名为 origin。 在添加远程仓库后，你可以使用 git remote -v 命令查看所有已添加的远程仓库，包括它们的别名和 URL。 这个错误意味着在尝试将本地 Git 仓库连接到远程仓库时，Git 发现已经存在一个名为 origin 的远程仓库。这通常发生在你尝试在已经存在 origin 的情况下再次运行 git remote add origin 命令，或者在克隆仓库时指定了一个与 origin 名称相同的远程仓库。 要解决这个错误，可以尝试以下方法： 1git remote rm origin 本地仓库建立完成 此时我们的本地仓库就建立好了。 然后我们的本地仓库要关联GitHub的仓库，直接将本地仓库关联远程GitHub仓库地址即可 1git remote add origin git@github.com:jxclbx/blogImages.git 上传本地代码至GitHub 下面要上传本地代码至GitHub，但是前提是远程仓库不能使空的，所以我们在远程仓库中创建一个README.md的文件： 本地仓库也创建一个一模一样的README.md文件即可，然后使用git pull origin master远程更新一下。 然后我们在原来的git bash中提交本地仓库中的web工程源代码： 1git push -u origin master error: src refspec master does not match any 确认本地 Git 仓库中是否存在名为 master 的分支。使用以下命令查看本地分支： 1git branch 如果 master 分支不存在，则可以使用以下命令创建该分支： 1git checkout -b master Pull request 出现 There isn’t anything to compare. 请移步另一篇文章。至此，已经绑定以及创建仓库。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"git","slug":"git","permalink":"http://jxclbx.github.io/tags/git/"},{"name":"ssh","slug":"ssh","permalink":"http://jxclbx.github.io/tags/ssh/"}]},{"title":"你好，五月！","slug":"你好，五月！","date":"2023-04-28T06:11:48.000Z","updated":"2023-08-31T10:15:20.521Z","comments":true,"path":"2023/04/28/你好，五月！/","link":"","permalink":"http://jxclbx.github.io/2023/04/28/%E4%BD%A0%E5%A5%BD%EF%BC%8C%E4%BA%94%E6%9C%88%EF%BC%81/","excerpt":"","text":"五月 一个寻常的五月，往往以一个寻常的错误开篇。 寻常的不能再寻常 寻常到……front-matter的Headimg千万不要忘了打后缀名，本地路径打上了后缀名也会因为外部链接没法引用这个路径下的image而无法显示。。最后投奔了图床…… 开始 真正的五月在北京开启，爬展花花卡丁车 好在五月是这样的一个轻松充实的基调 （富士真好玩.jpg 让我们和四月说一声再见吧，希望五月的风带来我想见的你，愿你想要的明天，都会如约而至。","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"VS_Code配置Python解释器","slug":"VS-Code配置Python解释器","date":"2023-04-26T13:21:53.000Z","updated":"2023-08-31T04:15:25.536Z","comments":true,"path":"2023/04/26/VS-Code配置Python解释器/","link":"","permalink":"http://jxclbx.github.io/2023/04/26/VS-Code%E9%85%8D%E7%BD%AEPython%E8%A7%A3%E9%87%8A%E5%99%A8/","excerpt":"","text":"我们熟悉的老朋友VS Code今天cv2莫名其妙报错，经过一番排查，得到是Python自身出了问题，故记录一下VSC与anaconda配置其的过程 VSCode 首先，我们需要在环境变量中添加 12C:\\Users\\13001\\AppData\\Local\\Programs\\Python\\Python37C:\\Users\\13001\\AppData\\Local\\Programs\\Python\\Python37\\Scripts 再在VSCode中，Ctrl+Shift+P 或者 View &gt; Command Palette，打开命令面板 输入 Python: Select Interpreter 选择Python的安装路径 可以使用上方的刷新符号来更新已经卸载的python版本的状态使其消失 选择好解释器后，就可以愉快的开始使用了","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"},{"name":"垃圾py","slug":"垃圾py","permalink":"http://jxclbx.github.io/tags/%E5%9E%83%E5%9C%BEpy/"},{"name":"vscode","slug":"vscode","permalink":"http://jxclbx.github.io/tags/vscode/"}]},{"title":"公开前：配置主题","slug":"公开前：配置主题","date":"2023-04-23T15:35:32.000Z","updated":"2023-08-31T04:15:25.538Z","comments":true,"path":"2023/04/23/公开前：配置主题/","link":"","permalink":"http://jxclbx.github.io/2023/04/23/%E5%85%AC%E5%BC%80%E5%89%8D%EF%BC%9A%E9%85%8D%E7%BD%AE%E4%B8%BB%E9%A2%98/","excerpt":"","text":"首先，非常激动，非常开心，我打开了撰写blog的大门。 配置主题 首先是更改主题 1npm i hexo-theme-volantis 这步是为了将主题安置到 blog\\node_modules\\hexo-theme-volantis 关于背景图片的替换 将图片放置在 node_modules\\hexo-theme-volantis\\source\\images 中，再将 12345678cover: height_scheme: full # full, half layout_scheme: dock # blank (留白), search (搜索), dock (坞), featured (精选), focus (焦点) display: home: true archive: true others: false # can be written in front-matter &#x27;cover: true&#x27; background: /images/bg.jpg # background image 的background字段更改为相对路径即可 关于引用图片 hexo-renderer-marked 3.1.0 引入了一个新的选项，其允许你无需使用 asset_img 标签插件就可以在 markdown 中嵌入图片 然后再在 _config.yml中更改代码块 1234post_asset_folder: truemarked: prependRoot: true postAsset: true 后在 _posts 文件夹中新建与post名相同的文件夹即可","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"自言自语","slug":"自言自语","permalink":"http://jxclbx.github.io/tags/%E8%87%AA%E8%A8%80%E8%87%AA%E8%AF%AD/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-04-22T15:54:53.000Z","updated":"2023-05-02T15:55:08.000Z","comments":true,"path":"2023/04/22/hello-world/","link":"","permalink":"http://jxclbx.github.io/2023/04/22/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"},{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/categories/CV/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/categories/HTML/"},{"name":"算法设计课程","slug":"算法设计课程","permalink":"http://jxclbx.github.io/categories/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"},{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"深度学习","slug":"深度学习","permalink":"http://jxclbx.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"GNNs","slug":"GNNs","permalink":"http://jxclbx.github.io/tags/GNNs/"},{"name":"课题组","slug":"课题组","permalink":"http://jxclbx.github.io/tags/%E8%AF%BE%E9%A2%98%E7%BB%84/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://jxclbx.github.io/tags/ubuntu/"},{"name":"linux","slug":"linux","permalink":"http://jxclbx.github.io/tags/linux/"},{"name":"clash","slug":"clash","permalink":"http://jxclbx.github.io/tags/clash/"},{"name":"科学上网","slug":"科学上网","permalink":"http://jxclbx.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"},{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"},{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/tags/CV/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://jxclbx.github.io/tags/Pytorch/"},{"name":"网页","slug":"网页","permalink":"http://jxclbx.github.io/tags/%E7%BD%91%E9%A1%B5/"},{"name":"vscode","slug":"vscode","permalink":"http://jxclbx.github.io/tags/vscode/"},{"name":"hexo","slug":"hexo","permalink":"http://jxclbx.github.io/tags/hexo/"},{"name":"音乐","slug":"音乐","permalink":"http://jxclbx.github.io/tags/%E9%9F%B3%E4%B9%90/"},{"name":"算法","slug":"算法","permalink":"http://jxclbx.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"anaconda","slug":"anaconda","permalink":"http://jxclbx.github.io/tags/anaconda/"},{"name":"站内搜索","slug":"站内搜索","permalink":"http://jxclbx.github.io/tags/%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2/"},{"name":"图床","slug":"图床","permalink":"http://jxclbx.github.io/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"jsDelivr","slug":"jsDelivr","permalink":"http://jxclbx.github.io/tags/jsDelivr/"},{"name":"git","slug":"git","permalink":"http://jxclbx.github.io/tags/git/"},{"name":"ssh","slug":"ssh","permalink":"http://jxclbx.github.io/tags/ssh/"},{"name":"垃圾py","slug":"垃圾py","permalink":"http://jxclbx.github.io/tags/%E5%9E%83%E5%9C%BEpy/"},{"name":"自言自语","slug":"自言自语","permalink":"http://jxclbx.github.io/tags/%E8%87%AA%E8%A8%80%E8%87%AA%E8%AF%AD/"}]}