{"meta":{"title":"jxclbx的小站","subtitle":"","description":"诶嘿","author":"Jxclbx","url":"http://jxclbx.github.io","root":"/"},"pages":[{"title":"","date":"2023-05-08T05:44:55.926Z","updated":"2023-04-28T05:47:48.000Z","comments":true,"path":"404.html","permalink":"http://jxclbx.github.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"所有分类","date":"2023-05-08T05:44:55.943Z","updated":"2023-04-28T05:53:46.000Z","comments":true,"path":"categories/index.html","permalink":"http://jxclbx.github.io/categories/index.html","excerpt":"","text":""},{"title":"","date":"2023-05-08T05:44:55.935Z","updated":"2023-04-28T05:53:42.000Z","comments":true,"path":"about/index.html","permalink":"http://jxclbx.github.io/about/index.html","excerpt":"","text":"下面写关于自己的内容"},{"title":"我的朋友们","date":"2023-05-08T05:44:56.031Z","updated":"2023-04-28T05:53:58.000Z","comments":true,"path":"friends/index.html","permalink":"http://jxclbx.github.io/friends/index.html","excerpt":"友情链接没有友链是万万不行滴！ 虽然博客是我自己写的，但是感谢他们对我一路的资瓷~","text":"友情链接没有友链是万万不行滴！ 虽然博客是我自己写的，但是感谢他们对我一路的资瓷~"}],"posts":[{"title":"高阶网络的链接预测算法和应用","slug":"高阶网络的链接预测算法和应用","date":"2024-01-27T08:43:39.000Z","updated":"2024-02-02T15:16:01.322Z","comments":true,"path":"2024/01/27/高阶网络的链接预测算法和应用/","link":"","permalink":"http://jxclbx.github.io/2024/01/27/%E9%AB%98%E9%98%B6%E7%BD%91%E7%BB%9C%E7%9A%84%E9%93%BE%E6%8E%A5%E9%A2%84%E6%B5%8B%E7%AE%97%E6%B3%95%E5%92%8C%E5%BA%94%E7%94%A8/","excerpt":"","text":"高阶网络的链接预测算法和应用 Hypergraph Neural Networks 定义了超图的关联矩阵 H，其中 h(u,e) 是关联矩阵中的元素，它表示顶点 u 和超边 e 是否相关联。 是节点（顶点）分类问题在超图上的正则化框架，这里 Ω(f) 是正则化项，Remp(f) 是经验损失项。 定义了正则化项Ω(f) 的具体形式，它是基于超图结构的一个正则化项，用于评估顶点之间的相似性。 描述了正则化项Ω(f) 的标准化形式，其中 Δ 是度矩阵 Dv 和 De 的逆矩阵乘以关联矩阵 H 和权重矩阵 W 的乘积再乘以关联矩阵的转置，这里 f^TΔ 实际上是拉普拉斯正则化项的一种形式。 超图卷积过程 顶点特征矩阵 XXX: 初始维度: ∣V∣×F|V| \\times F∣V∣×F 描述: 包含图中每个顶点的特征向量。 顶点-超边关联矩阵 HHH: 维度: ∣V∣×∣E∣|V| \\times |E|∣V∣×∣E∣ 描述: 表明顶点和超边之间的关系。如果顶点 viv_ivi​ 属于超边 eje_jej​，则 Hij=1H_{ij} = 1Hij​=1，否则为 0。 超边权重矩阵 WWW: 维度: ∣E∣×∣E∣|E| \\times |E|∣E∣×∣E∣ 描述: 对角矩阵，其中对角线上的元素表示每个超边的权重。 超边度矩阵 DeD_eDe​: 维度: ∣E∣×∣E∣|E| \\times |E|∣E∣×∣E∣ 描述: 对角矩阵，其对角线上的元素表示每个超边连接的顶点数量。 顶点度矩阵 DvD_vDv​: 维度: ∣V∣×∣V∣|V| \\times |V|∣V∣×∣V∣ 描述: 对角矩阵，其对角线上的元素表示与每个顶点相关联的所有超边的权重之和。 超边规范化: 计算: H×WH \\times WH×W 结果维度: ∣V∣×∣E∣|V| \\times |E|∣V∣×∣E∣ 超边规范化与超边度矩阵的逆平方根相乘: 计算: HW×De−1/2HW \\times D_e^{-1/2}HW×De−1/2​ 结果维度: ∣V∣×∣E∣|V| \\times |E|∣V∣×∣E∣ 顶点特征与规范化超边关联矩阵相乘: 计算: (HW×De−1/2)×X(HW \\times D_e^{-1/2}) \\times X(HW×De−1/2​)×X 结果维度: ∣V∣×F|V| \\times F∣V∣×F 顶点度矩阵的逆平方根与上一步结果相乘: 计算: Dv−1/2×((HW×De−1/2)×X)D_v^{-1/2} \\times ((HW \\times D_e^{-1/2}) \\times X)Dv−1/2​×((HW×De−1/2​)×X) 结果维度: ∣V∣×F|V| \\times F∣V∣×F 参数矩阵 Θ\\ThetaΘ: 维度: F×F′F \\times F&#x27;F×F′ 描述: 包含卷积层中的可学习参数。 应用参数矩阵: 计算: (Dv−1/2×((HW×De−1/2)×X))×Θ(D_v^{-1/2} \\times ((HW \\times D_e^{-1/2}) \\times X)) \\times \\Theta(Dv−1/2​×((HW×De−1/2​)×X))×Θ 结果维度: ∣V∣×F′|V| \\times F&#x27;∣V∣×F′ 应用非线性激活函数 σ\\sigmaσ: 计算: σ((Dv−1/2×((HW×De−1/2)×X))×Θ)\\sigma((D_v^{-1/2} \\times ((HW \\times D_e^{-1/2}) \\times X)) \\times \\Theta)σ((Dv−1/2​×((HW×De−1/2​)×X))×Θ) 结果维度: ∣V∣×F′|V| \\times F&#x27;∣V∣×F′ 描述: X′X&#x27;X′ 是卷积操作的输出，包含了更新后的顶点特征向量。 是高阶图卷积网络中的卷积操作的简化表达式，使用节点度矩阵和超边度矩阵。 定义了超图信号 X 的超边卷积，其中 Y 是卷积后的输出，W 是学习参数。 描述了超图神经网络中卷积层的更新规则 What Are Higher-OrderNetworks? 这篇综述文章讨论了复杂系统和数据的网络化建模，这在不同领域中已成为一个重要话题。 超图的定义 这部分文本定义了一个抽象的单纯复形），它是一种高阶网络结构，用于表示超图中的多元关系。 Simplicial closure and higher-order link prediction 这篇文章探讨了网络中的高阶交互（higher-order interactions）组织原则和时间演化。通过分析19个数据集，揭示了不同系统类型中高阶结构的一致模式。文章发现，联系强度（tie strength）和边缘密度（edge density）是高阶组织的正向指标。提出了高阶链接预测（higher-order link prediction）作为基准问题，评估预测高阶结构的模型和算法，发现与成对链接预测相比，本地信息在预测新交互时比远程信息（深层信息）更为重要。 是一个指示随机变量，表示节点 u, v, 和 w 形成一个开放三角形的情况。、 模型可以用来生成具有特定三角形分布特性的网络数据集，进而用于研究和模拟真实世界网络的结构和动态。 Link prediction in complex networks based on Significance of Higher-Order Path Index (SHOPI) 这篇文章提出了一个新的相似性指数SHOPI，用于链接预测，通过惩罚共同邻居来限制信息泄露，并利用高阶路径（Higher-Order Paths）作为区分特征。SHOPI在12个真实网络数据集上的实验结果显示，它优于基线方法，与现有的Katz指数和本地路径指数（Local Path Index, LP）相比更为稳健。这与高阶网络的研究相关，因为它考虑了高阶路径作为连接预测的特征。 初始化阶段 ： prev和 score两个矩阵被初始化为零矩阵。 对于图中的每一对节点 (i, j)，计算二阶路径（两步可达）的得分。 z 是节点对 (i, j) 的共同邻居。 score[i, j] 被设置为 1/kz，其中 kz 是节点 z 的度数，即与 z 相连的边数。 prev[i, j] 用来存储上一次迭代的得分。 计算阶段 ： l 表示路径长度，lmax 是最大考虑的路径长度。 temp 矩阵被初始化，用来临时存储计算结果。 对于每一对节点 (i, j)，对于节点 i 的每个邻居 Ni，计算由节点 i 到 Ni 的路径得分 f1，以及 Ni 到 j 的上一次迭代得分 f2。 temp[i, j] 通过 f1 * f2 * ψ^(l-2) 更新，其中 ψ 是惩罚参数，用于减少通过共同邻居泄漏的信息量。 更新阶段 ： 更新 score 矩阵，将 temp 矩阵中计算的得分加到 score[i, j] 上。 将 prev 矩阵更新为 temp 矩阵的内容，为下一次迭代做准备。 最终，算法返回 score 矩阵，包含所有节点对的相似度得分。 在这篇文章中，“高阶”指的是考虑节点对之间通过多个中间节点连接的路径，而不仅仅是直接的连接或共同邻居。 Link Prediction via Higher-Order Motif Features 这篇文章提出了一种基于高阶拓扑分析的链接预测方法，超越了依赖共同邻居的传统方式。将链接预测视为监督分类问题，并引入依赖于节点对出现的模式或动机（motifs）的特征集，特别是k = 3、4、5的模式。此外，文章还提出了两种优化构建分类数据集的方法：一是向图中添加负例，二是控制采样节点对形成负例时的最短路径距离。实验表明，使用所提动机特征可显著提高分类准确率，与高阶（higher-order）关系在于使用了图中更复杂的结构模式来提高预测性能。 对于分类数据集中的每个边示例（无论是正例还是负例），算法会枚举该边参与的所有k-motif 计算每种不同motif的出现次数。这些计数结果构成了用于训练分类器的特征向量。 分类器学习这些特征与边存在与否之间的关系，从而用于预测未知边。 通过这种方法，分类器能够利用复杂的拓扑特征来提高预测的准确性。 Graph embedding-based novel protein interaction prediction via higher-order graph convolutional network 这篇文章提出了一种新的节点（蛋白质）嵌入方法，结合图卷积网络GCN和PageRank，用于蛋白质-蛋白质互作（PPI）网络中新链接的预测。通过开发高阶GCN变分自编码器（HO-VGAE）架构，实现了基于更高阶局部和全局PPI网络拓扑的节点表示学习，无需额外的生物学特征。这与高阶（higher-order）关系紧密，因为它扩展并探索了节点的高阶邻域拓扑信息。 模型由两部分组成：编码器和解码器。编码器使用高阶GCN生成潜在节点嵌入，这些嵌入遵循高斯分布。解码器部分使用这些潜在嵌入来重建输入的网络结构，目的是重构PPI网络并发现新的蛋白质相互作用。模型通过最小化重建误差和Kullback-Leibler（KL）散度来训练，以学习低维且稳定的节点表示，从而预测新的相互作用。 公式 (1): 这是节点嵌入的非线性激活函数，使用ReLU作为激活函数，它作用于每个卷积层的传播结果。 $ Z^{l+1} = \\text{ReLU}(H{l}W{l}) $ 公式 (2): 表示了每个卷积层中用于随机游走或传播的幂迭代计算。这里结合了图传播效应和PageRank的概念。 $ H^{l}{k+1} = (1 - \\alpha)A{\\text{norm}}H^{l}_{k} + \\alpha Z^{l} $ 公式 (3): 初始化幂迭代过程中 $ H^{l} $ 的值。 $ H^{l}_{0} = Z^{l} $ 公式 (4): 当 $ k $ 趋向于无穷大时，幂迭代会收敛，这时 $ H^{l}{k+1} $ 可以用 $ H^{l}{\\infty} $ 来近似表示，进而得到收敛的公式。 $ H^{l}{\\infty} = \\alpha(I_n - (1 - \\alpha)A{\\text{norm}}){-1}Z{l} $ 公式 (5): 高阶GCN中节点嵌入的非线性激活函数，这是使用了得分矩阵 $ S 。。 。 Z^{l+1} = \\text{ReLU}(SZ{l}W{l}) $ 公式 (6): 高阶GCN模型的最终输出，代表了通过 $ L $ 层卷积计算后得到的节点嵌入。 $ \\text{GCN}(X, A) = Z^{L} $ Higher-Order Relations Skew Link Prediction in Graphs 这篇文章探讨了在存在高阶关系的情况下，链接预测问题的表现。研究发现，常见邻居启发式方法在高阶关系中表现得非常好。然而，文章证明了这是因为CN在高阶关系中过高估计了其预测能力。通过考虑高阶关系的理论模型，并显示CN的AUC分数高于模型所能达到的水平，来证明这一点。文章还扩展了对其他类似链接预测算法（如Adamic Adar）的观察，并提出了一个调整因子以更好地估计泛化分数，关于高阶（higher-order）的关系在于它调查了CN启发式方法在考虑高阶关系时的表现和理论基础。 文章通过计算AUC（曲线下面积）分数来评估常见邻居方法的性能，并指出在高阶关系存在的情况下，CN方法的AUC分数高于理论模型所能达到的最高分数。基于上述观察，文章提出了一个调整因子，用于修正预测分数，使其更好地估计算法在不同网络结构中的泛化能力。 对于给定的顶点子集 f，如果存在潜在空间 Rd 中的球体，使得 f 中所有顶点的潜在向量都包含在球体内，则 f 可以成为一个潜在的超边。 Higher-Order Temporal Network Prediction 这篇文章提出了一个基于记忆的模型，用于预测未来一步的高阶时间网络（或事件），这种网络记录了随时间发生的高阶事件。与传统的时间网络预测方法相比，该模型能够更好地预测高阶交互，并且在八个真实世界网络中表现优于基线模型。这个模型利用了网络过去观察到的活动，将高阶时间网络预测问题视为一个监督学习问题。模型假设一个群组在下一个时间步的活动受到该目标群组及其子群组和超群组过去活动的影响，且近期事件的影响大于旧事件。通过考虑不同大小的超链接（hyperlinks）及其活动状态，模型能够预测未来的高阶交互活动。此外，文章还提出了一个基线模型，将过去观察到的高阶时间网络视为成对时间网络，并从预测的成对交互中推断出高阶交互。实验结果显示，该模型在多个真实世界的网络数据集中均优于基线模型。 t + 1是预测的时间步长，L是用于预测的过去观测的长度，τ是指数衰减因子，xj(k)是时间k时链接j的激活状态：如果链接j在时间k处于活跃状态，则xj(k) = 1，否则xj(k) = 0。 其中L是过去用于预测的网络观察的时间长度，τ是指数衰减因子，Sj是超链接j的子超链接或超超链接的集合，xi(k)是时间k时超链接i的激活状态。cdidj是交叉阶影响系数，其中di是超链接i的大小，dj是超链接j的大小。例如，c32是与激活一个3超链接对其大小为2的子超链接的激活影响相关的系数。我们对任意大小d的超链接，都将cdd设为1。通过变化交叉阶系数cd1d2（对于d1 ≠ d2）的值，我们可以得到我们一般模型的不同子模型。 Tackling higher-order relations and heterogeneity: Dynamic heterogeneous hypergraph network for spatiotemporal activity prediction 这篇文章提出了一个动态异构超图网络模型，用于时空活动预测。这个模型使用超图来更好地建模高阶关系，并通过一个灵感来自集合表示学习的异构超边学习模块来处理时空活动预测中的高阶关系和异质性。此外，还引入了一个知识表示正则化损失来改进异质时空活动超边的编码，并提出了一个超图结构学习模块来动态更新超图结构。该模型在四个真实世界数据集上的测试表明，其性能超过了当时的最先进方法。 结构学习 : 对每种模态的节点嵌入应用结构学习算法，得到更新的结构矩阵Au、Al、At、Aa。 结构更新 : 结合初始超图结构AH和学习到的结构矩阵A^(i)来更新超图结构A~H。 迭代节点嵌入 : 对于i从1到L（L层的深度），更新节点嵌入E^(i) = A~H * E^(i-1)。 聚合节点嵌入 : 通过计算所有层次的节点嵌入的均值来聚合节点嵌入，得到E。 生成嵌入向量 : 对于每个活动记录（u, l, t, a），从嵌入矩阵E中提取相应的用户、地点、时间和活动的嵌入向量。 嵌入表示转换 : 将用户、地点、时间和活动的嵌入向量合并成一个嵌入矩阵X ∈ R^4xd。 编码嵌入矩阵 : 使用Hyperedge Attention Block（HAB）对嵌入矩阵X进行两次处理，得到Y_enc。 池化操作 : 对编码后的嵌入矩阵Y_enc应用池化操作，得到向量表示z。 原论文对HCN定义 用于计算节点嵌入之间的加权余弦相似性。 描述了邻接矩阵的稀疏化过程，通过设置一个阈值 ϵ 来删除小于该阈值的相似性分数，从而减少连接。 Incorporating higher order network structures to improve miRNA–disease association prediction based on functional modularity 这篇文章旨在通过整合更高阶的网络结构来提升miRNA-疾病关联（MDAs）的预测性能。该模型首先整合了miRNA相似性网络、疾病相似性网络和MDA网络，然后识别出重叠的功能模块，并设计了一种基于路径的评分函数来推断潜在的MDAs。HiSCMDA在跨验证和独立验证实验中表现优异，特别是在对结肠肿瘤和肺肿瘤的预测中，获得了数据库验证的高准确率。 该网络定义了五种不同的高阶模式（motifs），用于预测新的miRNA-疾病关联（MDAs）。 （1） 定义了疾病在DAG中的语义贡献度。如果两种疾病相同，其贡献度为1；如果不同，则取决于它们的关系，通过其子节点的最大语义贡献度与一个衰减因子的乘积来计算。 （2） 计算了一个疾病的所有祖先节点的语义贡献度之和，从而得出该疾病的语义值（DSV1）。 （3） 使用疾病的DAG中共有的祖先节点的语义贡献度，来计算两种疾病间的第一种语义相似性（DS1）。 （4） 提供了另一种方法来计算疾病在DAG中的语义贡献（DSC2），这次是通过考虑疾病在多少个DAG中出现。 （5） 计算了疾病所有祖先节点的第二种语义贡献度之和，从而得出该疾病的第二种语义值（DSV2）。 （6） 利用第二种语义贡献度来计算两种疾病间的第二种语义相似性（DS2）。 （7） 最后，通过取两种语义相似性度量（DS1和DS2）的平均值，来计算两种疾病间的综合语义相似性（DS）。 （8） 定义了两个miRNAs之间的高斯核相似度，它基于它们的交互作用轮廓（例如，与疾病的关联）。这个相似度通过计算两个miRNAs交互作用轮廓之间的欧氏距离的指数负值来得到，其中 γm 是核宽度的调节参数。 （9） 给出了如何计算 γm，即通过所有miRNAs交互作用轮廓的平均欧式距离的倒数。 （12） 定义了miRNAs之间的集成相似性（SM）。如果两个miRNA之间的功能相似性（FS）不为零，就使用FS值；如果FS为零，则使用高斯交互轮廓核相似性（KM）。 （13） 引入了一个相似性矩阵 F，用于表示miRNA相似性网络。每个元素 Fij 只有在 SM(mi,mj) 大于或等于给定阈值 β 时，否则为0 SD逻辑相同 高阶网络不同motif定义 这部分内容在网络模型中引入了复杂的转移概率计算，以及如何利用这些信息来检测可能在miRNA和疾病之间的关联模式。 STHGCN: A spatiotemporal prediction framework based on higher-order graph convolution networks 这篇文章提出了一个名为STHGCN的新的时空预测框架，核心思想是利用高阶依赖性来建模时空依赖性。具体来说，对于时空维度，提出并实现了一个高阶时间差分网络和一个高阶空间语义图卷积网络（GCN）。实验结果表明，STHGCN优于现有的最先进的时空预测模型。这与高阶（higher-order）关系密切相关，因为该模型通过高阶依赖性来精确捕获时空数据的复杂关联。 动态关系指的是那些随着样本X的变化而变化的空间依赖性。不同于静态关系，在模型学习完成后不再需要改变，动态关系会随样本X在STHGCN模型中的变化而变化。 初始化源节点嵌入E1和E2，并计算静态关系邻接矩阵As。 将动态关系邻接矩阵Ad附加到A。 根据公式计算动态关系邻接矩阵Ad、概率p(r|θ, X)、均值µ(X)和标准差σ(X)。 存在预定义的图邻接矩阵Ae，则A = [Ae, As, Ad]；否则A = [As, Ad]。 对于l=1到L（网络深度）， 根据公式计算X_T^(l)。 计算X^(l+1)。 根据公式计算最终输出Ŷ。 根据公式计算最终损失L。 Prompt learning 综述 Prompt learning通常是在预训练的语言模型（如BERT）的基础上，通过设计一个或一系列的提示语句，引导模型根据给定的上下文完成特定的任务，比如语句填空、分类、生成等。这种方法可以有效利用预训练模型的语言理解能力，通过少量的调整来适应新的任务或数据集。 Learning Transferable Visual Models From Natural Language Supervision 在Zero-Shot学习中，图像编码器没有直接学习特定任务的样本，但理解图像编码器和文本编码器在预训练阶段是如何一起学习的，编码器学习了如何将文本和图像映射到同一个嵌入空间，并确保相关的图像和文本对彼此接近。这种学习是在大量的图像和文本对上进行的，使得模型学会了理解各种各样的视觉和文本信息。 模型预测不是随机选择一个标签。相反，它利用预训练期间学到的图片转换为的文本特征表示来进行推理。模型理解了很多不同的图像特征和关联的文本描述，即使它没有直接学习过新的特定样本，也能使用这些通用的表示来推断新样本最可能关联的文本描述。 What Does a Platypus Look Like? Generating Customized Prompts for Zero-Shot Image Classification 这篇论文提出的基线方法是结合开放词汇模型和大型语言模型（LLM）来生成定制化提示（CuPL），用于图像分类。首先，LLM生成描述图像类别的详细描述，这些描述随后作为提示用于开放词汇模型进行图像分类。这一过程不需要额外的训练，在多个基准测试中提高了准确性。 图像分类模型通常是通过结合视觉模型和文本模型来处理的，例如使用多模态学习方法。在这种情况下，图像和生成的文本提示同时作为输入，模型学习如何结合这两种形式的信息来进行分类。 PLPMpro: Enhancing promoter sequence prediction with prompt-learning based pre-trained language model 研究引入了PLPMpro模型，该模型结合了prompt-learning和预训练语言模型，用于提高启动子序列（promoter sequences）的预测准确性。该模型不仅超越了典型的基于预训练模型的启动子预测方法，也超越了典型的深度学习方法。此外，通过各种实验详细考察了不同prompt learning设置和不同数量的软模块（soft modules）对模型性能的影响。更重要的是，解释实验揭示了预训练模型捕获了生物学语义。 DNA序列被转换成6-mer序列，并与prompt模板（包含soft modules和[MASK]）结合。然后，这些带有模板的DNA序列被输入到DNABERT模型中，DNABERT生成填充在[MASK]中的所有可能词汇的概率。接着，使用verbalizer将生成的词汇概率映射到不同标签的概率上 Universal Prompt Tuning for Graph Neural Network 这篇文章提出了一种通用的基于提示的调整方法，名为图提示特征（Graph Prompt Feature, GPF），适用于任何预训练策略下的图神经网络（GNN）模型。与传统的针对特定预训练任务设计的提示函数不同，GPF在输入图的特征空间上操作，理论上可以达到任何形式的提示函数的效果，从而避免了为每种预训练策略显式定义提示函数的需要。GPF通过适应性地获取针对下游任务的提示图，展示了其在多种预训练策略下的普适性和有效性，实验结果显示GPF在全量和少量标注场景下均优于传统的微调方法，为下游任务的适应提供了一个有力的替代方案。与Prompt learning的关系在于，GPF利用了提示学习的理念，通过引入图特征空间中的提示来改善预训练GNN模型在特定下游任务上的性能。 我们可以向分子图的特征空间引入提示，例如增加与特定化学功能相关的节点或边的特征权重，从而帮助预训练的GNN模型更好地识别和区分具有不同化学性质的分子。这种提示可以是基于已知化学规则的特征增强，或者是通过学习得到的针对特定化学任务的特征表示。 这些自定义的提示特征权重通常来源于对特定任务的先验知识或通过对数据集的探索性分析获得的洞察。在某些情况下，这些权重也可以通过自动化的搜索和优化过程获得，其中机器学习算法试图找到最佳的特征权重组合，以提高模型在下游任务上的性能。这个过程与模型的初始预训练状态无关，但旨在增强模型对特定任务的适应能力。 GPL-GNN: Graph prompt learning for graph neural network 这篇文章提出了一个名为GPL-GNN的新框架，用于解决在有限标注数据下，图表示学习性能瓶颈的问题。GPL-GNN通过将无监督预训练的结构表示作为提示信息引入下游任务，以缩小预训练目标与下游任务之间的差距。这种方法不仅提高了模型对特定任务的适应性，还增加了选择任务特定GNN模型的灵活性。此外，引入原型网络（prototype networks）作为分类头，实现了对下游任务的快速适应。 All in One: Multi-Task Prompting for Graph Neural Networks 这篇文章提出了一种新的多任务图提示方法，旨在缩小预训练模型与多种图任务之间的差距，通过设计一种特殊的图提示结构来统一图提示和语言提示，这种结构将NLP中的提示概念与图数据相结合。具体来说，它在图的节点或边特征中插入预定义或可学习的提示标记，类似于NLP中向文本序列中添加特定词汇或短语的做法。这些图提示模拟语言提示的作用，引导图神经网络模型更好地理解和执行特定的下游任务。 GNN数据集 Cora 每行（图的一个节点）的第一个字段是论文的唯一字符串标识，后跟 1433 个字段（取值为二进制值），表示1433个词汇中的每个单词在文章中是存在(由1表示)还是不存在(由0表示)。最后，该行的最后一个字段表示论文的类别标签（7个）。因此该数据的特征应该有 1433 个维度，另外加上第一个字段 idx，最后一个字段 label， 一共有 1433 + 2 个维度。 Citeseer 共包含3312篇论文，记录了论文之间引用或被引用信息。去除停用词和在文档中出现频率小于10次的词，整理得到3703个唯一词。CiteSeer数据集包含两个文件：.content文件和.cites文件：.content文件描述论文信息的格式为：&lt;paper_id&gt; &lt;word_attributes&gt;+&lt;class_label&gt;；每行的第一个条目（paper_id）是每篇论文的唯一编号ID，后续（word_attributes）包含3703个二进制码，表示词汇表中的每个单词在论文中是否存在（由1表示）或不存在（由0表示），最后一个条目（class_label）表示论文的类标签。.cites文件描述了论文之间的引用信息，格式为： 。每行数据包含了两篇论文的编码ID，第一个条目（ID of cited paper）表示被引用论文的编号，第二个条目（ID of citing paper）表示引用论文的编号。Citeseer数据集被广泛应用于节点分类、引文关系分析和文献推荐等任务。 PubMed PubMed数据集中的文献包含了丰富的特征信息，如标题、摘要、作者、关键词等。此外，数据集还提供了文献之间的引用关系，可以用于分析文献之间的相互引用和关联性。对于图神经网络（GNN）的研究，PubMed数据集被广泛应用于节点分类、文献关系分析和知识图谱构建等任务。通过使用GNN模型，可以根据文献的特征和引用关系来预测文献所属的类别（如疾病、基因或化学物质），探索文献之间的相似性和相关性，以及构建生物医学知识图谱。 Reddit Reddit数据集是一个用于社交网络分析和挖掘的常见数据集，包含了来自不同社区的用户以及他们之间的交互关系。这个数据集通常被用来进行社区发现、用户分类、推荐系统等任务。 PPI 这个数据集包含了不同蛋白质之间相互作用的信息，对研究蛋白质结构和功能具有重要意义，在PPI数据集中，通常会包含已知的蛋白质相互作用关系，这些关系可以描述为一个由节点和边组成的图。其中，图的节点代表不同的蛋白质，而图的边则表示蛋白质之间的相互作用关系。对于图神经网络（GNN）的研究，PPI数据集被广泛应用于预测新的蛋白质相互作用、研究蛋白质网络的拓扑结构、发现蛋白质功能模块等任务。通过使用GNN模型，可以利用蛋白质的结构特征和相互作用关系来预测未知的蛋白质相互作用，探索蛋白质网络的特性和功能，以及发现潜在的生物学规律。 Amazon Amazon Computers and Amazon Photo are segments of the Amazon co-purchase graph [McAuley et al., 2015], https://arxiv.org/pdf/1506.04757.pdf 论文作者主页提供的原始数据集 https://cseweb.ucsd.edu//~jmcauley/datasets.html 原始数据集是为推荐任务做的，几百万个结点。 分子数据集 BBBP 血脑屏障渗透（渗透性）的二进制标记 num：编号 name：化合物名称 p_np：渗透/非-渗透的二值表示 smiles：分子结构 clintox、HIV、muv等等 蛋白质数据集 HI-II-14 数据集：由二元管道获得的系统PPI网络。 HI-III 数据集：通过高通量实验筛选技术生成的PPI数据。 Lit-BM-13 数据集：文献整理的直接物理相互作用的PPI网络。 BioGRID 数据集：涵盖生物分子相互作用的数据库。 Bioplex 数据集：共复合物蛋白质组学数据集。 Hein et al 数据集：","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"深度学习","slug":"深度学习","permalink":"http://jxclbx.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"GNNs","slug":"GNNs","permalink":"http://jxclbx.github.io/tags/GNNs/"},{"name":"课题组","slug":"课题组","permalink":"http://jxclbx.github.io/tags/%E8%AF%BE%E9%A2%98%E7%BB%84/"}]},{"title":"GCLMTP","slug":"GCLMTP","date":"2023-10-14T14:20:52.000Z","updated":"2023-10-14T17:32:15.107Z","comments":true,"path":"2023/10/14/GCLMTP/","link":"","permalink":"http://jxclbx.github.io/2023/10/14/GCLMTP/","excerpt":"","text":"矩阵操作 123456789101112131415161718192021222324252627282930313233def read_file1(): # 加载 lncRNA 和 miRNA 之间的关联数据 lnc_mi = np.loadtxt(&quot;data/yuguoxian_lnc_mi.txt&quot;) # 将 lncRNA 和 miRNA 之间的关联数据转置，表示 miRNA 和 lncRNA 之间的关联数据 mi_lnc = lnc_mi.T # 加载 lncRNA 与疾病之间的关联数据 lnc_dis = np.loadtxt(&quot;data/lnc_dis_association.txt&quot;) # 加载 miRNA 与疾病之间的关联数据 mi_dis = np.loadtxt(&quot;data/mi_dis.txt&quot;) # 加载疾病之间的相似性数据 dis_sim = np.loadtxt(&quot;data/dis_fusion_sim.txt&quot;) # 加载 lncRNA 之间的相似性数据 lnc_sim = np.loadtxt(&quot;data/lnc_fusion_sim.txt&quot;) # 加载 miRNA 之间的相似性数据 mi_sim = np.loadtxt(&quot;data/mi_fusion_sim.txt&quot;) # 加载 lncRNA 与疾病关联数据的测试标识符 lnc_dis_test_id = np.loadtxt(&quot;data/lnc_dis_test_id1.txt&quot;) # 加载 miRNA 与疾病关联数据的测试标识符 mi_dis_test_id = np.loadtxt(&quot;data/mi_dis_test_id1.txt&quot;) # 加载 miRNA 和 lncRNA 之间关联数据的测试标识符 mi_lnc_test_id = np.loadtxt(&quot;data/mi_lnc_test_id1.txt&quot;) # 返回加载的数据作为函数的输出 return mi_lnc, lnc_dis, mi_dis, dis_sim, lnc_sim, mi_sim, lnc_dis_test_id, mi_dis_test_id, mi_lnc_test_id 以上代码形状为 (495, 240) (240, 405) (495, 405) (405, 405) (240, 240) (495, 495) (95051, 2) (189628, 2) (117999, 2)，test为在矩阵中为即将在copyA中置零的矩阵 12345def Preproces_Data(A, test_id): copy_A = A / 1 for i in range(test_id.shape[0]): copy_A[int(test_id[i][0])][int(test_id[i][1])] = 0 return copy_A 程序中对lnc疾病、mi疾病、lncmi做了如上处理，后续 matrix_A = construct_graph(lnc_dis, mi_dis, mi_lnc, lnc_sim, mi_sim, dis_sim)，把上面三个矩阵构造进去，同时也把三个变量自己之间相关性也包含在内。 然后依照这个先做hstack，再做vstack。我发现处理数据时，lncRNA与miRNA顺序是反过来的，所以我修改了代码。将其先做转置，再更改 12345678910def construct_graph(lncRNA_disease, miRNA_disease, lncRNA_miRNA, lncRNA_sim, miRNA_sim, disease_sim): lnc_dis_sim = np.hstack((lncRNA_sim, lncRNA_disease, lncRNA_miRNA)) print(lnc_dis_sim.shape) dis_lnc_sim = np.hstack((lncRNA_disease.T, disease_sim, miRNA_disease.T)) print(dis_lnc_sim.shape) mi_lnc_dis = np.hstack((lncRNA_miRNA.T, miRNA_disease, miRNA_sim)) print(mi_lnc_dis.shape) matrix_A = np.vstack((lnc_dis_sim, dis_lnc_sim, mi_lnc_dis)) return matrix_A 拉普拉斯归一化 12345678910111213def lalacians_norm(adj): # adj += np.eye(adj.shape[0]) degree = np.array(adj.sum(1)) D = [] for i in range(len(degree)): if degree[i] != 0: de = np.power(degree[i], -0.5) D.append(de) else: D.append(0) degree = np.diag(np.array(D)) norm_A = degree.dot(adj).dot(degree) return norm_A GCNConv GCNConv 是一个自定义的 PyTorch 模块类，继承了 nn.Module。这表示它是一个可训练的神经网络层，可以包含可学习的参数。 在初始化方法 __init__ 中，定义了 GCNConv 层的参数： in_size 表示输入特征的维度大小，即节点特征的数量。 out_size 表示输出特征的维度大小，即经过该层后节点特征的维度。 在 __init__ 中，创建了一个可训练的权重矩阵 self.weight 作为 GCNConv 层的参数。这个权重矩阵的大小是 (in_size, out_size)，初始化使用 Xavier 初始化方法，以确保参数的初始值是合适的，有助于网络的训练。 在 forward 方法中，定义了 GCNConv 层的前向传播操作： adj 是图的邻接矩阵（Adjacency Matrix），表示节点之间的连接关系。 features 是节点的特征矩阵，表示每个节点的特征向量。 在前向传播中，首先执行 torch.mm(adj, features) 操作，将邻接矩阵 adj 与特征矩阵 features 相乘。这个操作相当于对每个节点的特征与其邻居节点的特征进行聚合，得到了节点聚合后的特征表示。 然后，执行 torch.mm(out, self.weight) 操作，将上一步得到的聚合特征矩阵与 GCNConv 层的权重矩阵 self.weight 相乘。这个操作实现了将聚合后的特征进一步映射到输出特征空间，得到了最终的输出特征表示。 最后，将计算得到的输出特征 out 返回作为这个 GCNConv 层的输出。 图为encoder的一种结构 Encoder 123456789101112131415161718192021222324## input_dim是输入的维度，hidden_dim是隐藏层的维度，n_calss是输出的维度class Encoder(nn.Module): def __init__(self, input_dim, hidden_dim, n_calss): super(Encoder, self).__init__() self.gcn1 = GCNConv(input_dim, hidden_dim) self.prelu1 = nn.PReLU(hidden_dim) self.gcn2 = GCNConv(hidden_dim, n_calss) self.prelu2 = nn.PReLU(n_calss) self.last_linear = torch.nn.Linear(hidden_dim + n_calss, n_calss) def forward(self, x, adj, corrupt=True): if corrupt: perm = torch.randperm(x.shape[0]) x = x[perm] x1 = self.gcn1(adj, x) x1 = self.prelu1(x1) x2 = self.gcn2(adj, x1) x2 = self.prelu2(x2) return x2 不再赘述 模型本身 GCLMTP是一个基于图的模型，它利用编码器从输入数据生成正样本和负样本，然后使用判别器进行处理，并根据判别器的输出计算损失。这个模型的目的似乎是在图结构的数据上进行未监督的学习，可能是用于图嵌入或者相似的任务。 Corrupt 12345678910111213141516171819202122232425262728293031323334353637383940## hidden_dim是隐藏层的维度# discriminator是一个全连接层，输入是hidden_dim，输出是hidden_dimclass Discriminator(nn.Module): def __init__(self, hidden_dim): super(Discriminator, self).__init__() self.weight = nn.Parameter(torch.Tensor(hidden_dim, hidden_dim)) nn.init.xavier_uniform_(self.weight.data, gain=1.414) def forward(self, x, summary): x = torch.matmul(x, torch.matmul(self.weight, summary)) return x&#x27;&#x27;&#x27;Model&#x27;&#x27;&#x27;class GCLMTP(nn.Module): def __init__(self, input_dim, hidden_dim, output_dim): super(GCLMTP, self).__init__() self.encoder = Encoder(input_dim, hidden_dim, output_dim) self.discriminator = Discriminator(output_dim) self.loss = nn.BCEWithLogitsLoss() def forward(self, edge_index, x): positive = self.encoder(x, edge_index, corrupt=False) negative = self.encoder(x, edge_index, corrupt=True) summary = torch.sigmoid(positive.mean(dim=0)) # print(&quot;summary: &quot;,summary.shape) positive_D = self.discriminator(positive, summary) negative_D = self.discriminator(negative, summary) l1 = self.loss(positive_D, torch.ones_like(positive_D)) l2 = self.loss(negative_D, torch.zeros_like(negative_D)) L = l1 + l2 return L, positive 代码的核心在于 positive = self.encoder(x, edge_index, corrupt=False),corrupt代表是否生成错误特征，这也是对比学习的一个特点。 positive是通过编码器处理输入数据得到的“正”样本的输出，其形状应该是 [N, output_dim]，接下来的 positive.mean(dim=0)计算了 positive沿第0维度（即沿样本数方向）的平均值。这会得到一个长度为 output_dim的向量，其每个元素表示所有样本在该特定维度上的平均值。torch.sigmoid函数被应用于这个平均值向量。sigmoid函数将任何输入压缩到0和1之间。这意味着 summary是一个介于0和1之间的值的向量，表示所有正样本的平均特征。 Discriminator Discriminator接受两个输入：x和 summary。x是从编码器得到的输出，是正样本或负样本的表示，而 summary是前面提到的正样本的平均特征。torch.matmul(self.weight, summary)是一个矩阵与向量的乘法操作，它实际上是在为每个特征维度提供一个权重，这些权重来自 self.weight。然后得到的结果与输入 x再次进行矩阵乘法。这是将 x的每个样本与通过 summary加权的权重进行相乘。 我认为判别器实际上是在使用 summary 来影响或加权它如何处理输入的样本。 1234summary = torch.sigmoid(positive.mean(dim=0))&gt;&gt;&gt; positive: torch.Size([1140, 256])summary: torch.Size([256]) 可以看出，dim进行了降维度。 这样，判别器实际上是在使用 summary（即正样本的平均特征）来影响或加权它如何处理输入的样本。 从高级角度看，Discriminator的目的是判断一个给定的样本表示（x）与整体“正”样本分布（由 summary表示）有多接近。如果 x表示的样本接近于正样本分布，那么判别器的输出会更接近1（正类），否则它会更接近0（负类）。 训练 1234567891011121314151617181920212223242526def train(la_A, Epoch, in_features, N_HID, out_features, LR): G = GCLMTP(input_dim=in_features, hidden_dim=N_HID, output_dim=out_features) G_optimizer = torch.optim.Adam(G.parameters(), lr=LR) A_laplacians = torch.from_numpy(la_A).float() X = torch.from_numpy(la_A).float() # print(A_laplacians.shape,X.shape) ################################GPU############################# if torch.cuda.is_available(): G = G.cuda() A_laplacians = A_laplacians.cuda() X = X.cuda() ###########################model train########################### for epoch in range(Epoch): G_loss, embedding = G(A_laplacians, X) G_optimizer.zero_grad() G_loss.backward() G_optimizer.step() print(&#x27;Epoch: &#x27;, epoch, &#x27;| train G_loss: %.10f&#x27; % G_loss.item()) np.savetxt(&quot;dataset1_result/low_A_256.txt&quot;, embedding.detach().cpu().numpy()) 训练过程比较常规，无需单独记录 疑问 1234 A_laplacians = A_laplacians.cuda() X = X.cuda()G_loss, embedding = G(A_laplacians, X) 代码中 X矩阵即为经过拉普拉斯正则化的 matrix_A ，但我们发现作为 edge_index的矩阵仍是 matrix_A 我推测是因为这个矩阵中包含了足够多的特征","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"深度学习","slug":"深度学习","permalink":"http://jxclbx.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"GNNs","slug":"GNNs","permalink":"http://jxclbx.github.io/tags/GNNs/"},{"name":"课题组","slug":"课题组","permalink":"http://jxclbx.github.io/tags/%E8%AF%BE%E9%A2%98%E7%BB%84/"}]},{"title":"图学习之GCN","slug":"图学习之GCN","date":"2023-10-11T04:22:10.000Z","updated":"2023-10-15T01:39:28.836Z","comments":true,"path":"2023/10/11/图学习之GCN/","link":"","permalink":"http://jxclbx.github.io/2023/10/11/%E5%9B%BE%E5%AD%A6%E4%B9%A0%E4%B9%8BGCN/","excerpt":"","text":"其中： xi(k)x_i^{(k)}xi(k)​ 代表节点i在第k层的特征。 N(i)N(i)N(i) 是节点i的邻居集合。 deg(i)\\text{deg}(i)deg(i) 是节点i的度（或邻居的数量）。 WWW 是可学习的权重矩阵。 bbb 是偏置向量。 数学公式的含义 加入自循环：通过在求和符号中包含 j∈N(i)∪{i}j \\in N(i) \\cup \\{i\\}j∈N(i)∪{i}，我们考虑了每个节点自己的特征，即添加了自循环。 归一化系数：系数 1deg(i)⋅deg(j)\\frac{1}{\\sqrt{\\text{deg}(i) \\cdot \\text{deg}(j)}}deg(i)⋅deg(j)​1​ 是为了对节点的度进行归一化，这有助于模型的稳定性和训练效果。 线性特征转换：通过乘以权重矩阵 WTW^TWT 并添加偏置 bbb，每个节点的特征进行了线性变换。 特征聚合：通过对所有邻居的转换后的特征进行求和，我们实际上在每个节点上聚合了其所有邻居的信息。 使用“add”聚合 这是一个将所有邻接节点与自己特征先归一化再加和成为新节点的过程 添加自循环 123456789Examples: &gt;&gt;&gt; edge_index = torch.tensor([[0, 1, 0], ... [1, 0, 0]]) &gt;&gt;&gt; edge_weight = torch.tensor([0.5, 0.5, 0.5]) &gt;&gt;&gt; add_self_loops(edge_index) (tensor([[0, 1, 0, 0, 1], [1, 0, 0, 0, 1]]), None) 节点的度 在您之前提到的GCN的公式中，i 和 j 分别代表两个节点，其中节点 i 是中心节点，而节点 j 是它的一个邻居或它自己（当考虑自循环时）。 自循环产生的边缘特征如何计算 在图神经网络（GNN）中，自循环指的是节点到自身的边。当我们在图中添加自循环时，通常是为了确保节点在消息传递时可以考虑自己的特征。但这通常涉及到节点特征，而不是边的特征。 当涉及到具有边特征的图时，处理自循环的方式可能会有所不同： 没有边特征 ：在这种情况下，添加自循环只会影响节点特征的聚合，并不涉及边的特征。 有边特征 ：当图中存在边特征时，为自循环添加特定的边特征会更加复杂。在这种情况下，您有几种选择： 零向量 ：为自循环边分配一个零向量作为其特征。 特殊值 ：为自循环边分配一个固定的特殊值或标志。 节点特征衍生 ：从相关节点的特征衍生出自循环边的特征。 学习 ：如果网络结构允许，可以设计一个机制来学习自循环边的特征。需要注意的是，不是所有的GNN都会使用或需要边特征。在某些情况下，特别是当使 用基本的GNN架构如GCN时，只考虑节点特征可能就足够了。 计算 lin进行W矩阵的全连接，norm求出了所有ij节点的归一化系数 propagate包含了message方法 norm.view(-1, 1) * x_j讲norm转置，再与节点特征相乘 然后加上b求出了新xi 实现边缘卷积 边缘卷积相对于标准的GCN（Graph Convolutional Network）层更多地实现了以下方面的功能和考虑： 上图公式有错误，应该为(xi, xi-xj) 边缘卷积利用了&quot;max&quot;聚合方式，这意味着它在考虑一个节点的所有邻居节点时，会选择MLP计算后的最大值作为该节点的新特征。 具体来说： 对于节点i的每一个邻居j，计算特征差值 将这个差值通过MLP得到新的特征。 对于节点i的所有邻居，选择这些新特征中的最大值作为节点i的新特征。 因此，当我们说选择的是&quot;最大值&quot;时，我们是指对于节点i，我们选择其所有邻居经过MLP处理后的最大特征值来表示节点i的新特征。这种选择方式捕获了节点与其邻居之间的最显著差异，这可能在某些任务中是很有用的。 练习题 对于 GCNConv： row 和 col 分别保存了什么信息？ edge_index的形状是 [2, E]，其中E是边的数量。row和 col是 edge_index的两个维度。在这种情况下，col表示边的起始节点，而 row表示边的目标节点。 degree()函数的作用是什么？ degree()函数计算图中每个节点的度。在图论中，一个节点的度是指与它相连的边的数量。 为什么使用 degree(col, …) 而不是 degree(row, …)? 在GCN中，通常使用 degree(col, ...)来计算每个节点的出度，这与信息传播的方向有关。 deg_inv_sqrt[col] 和 deg_inv_sqrt[row] 的作用是什么？ 这两者都是GCN归一化步骤中用到的因子。使用节点的度的平方根的倒数作为归一化因子，这有助于训练的稳定性和模型的性能。 在 message() 函数中 x_j 保存了哪些信息？如果 self.lin 表示恒等函数，x_j 的确切内容是什么？ x_j保存了源节点的特征。如果 self.lin是恒等函数，那么 x_j就是原始的、未经修改的节点 j的特征。 为 GCNConv 添加一个 update() 函数，该函数将转换后的中心节点特征添加到聚合输出中。 12def update(self, aggr_out, x): return aggr_out + self.lin(x) 对于 EdgeConv： x_i 和 x_j - x_i 分别是什么？ x_i是目标节点的特征，而 x_j - x_i表示的是源节点与目标节点特征之间的差异。 torch.cat([x_i, x_j - x_i], dim=1) 的作用是什么？为什么选择 dim = 1？ torch.cat([x_i, x_j - x_i], dim=1)的作用是将 x_i和 x_j - x_i沿着特征维度进行拼接。选择 dim=1是因为我们希望在特征维度上进行拼接，这样每个节点的新特征长度会是原来的两倍。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"深度学习","slug":"深度学习","permalink":"http://jxclbx.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"GNNs","slug":"GNNs","permalink":"http://jxclbx.github.io/tags/GNNs/"},{"name":"课题组","slug":"课题组","permalink":"http://jxclbx.github.io/tags/%E8%AF%BE%E9%A2%98%E7%BB%84/"}]},{"title":"Hello，图学习","slug":"Hello，图学习","date":"2023-10-10T17:17:19.000Z","updated":"2023-10-10T17:22:33.237Z","comments":true,"path":"2023/10/11/Hello，图学习/","link":"","permalink":"http://jxclbx.github.io/2023/10/11/Hello%EF%BC%8C%E5%9B%BE%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"data封装了一个类似图的数据结构 123456789import torchfrom torch_geometric.data import Dataedge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)x = torch.tensor([[-1], [0], [1]], dtype=torch.float)data = Data(x=x, edge_index=edge_index)&gt;&gt;&gt; Data(edge_index=[2, 4], x=[3, 1]) 1234567dataset = TUDataset(root=&#x27;/tmp/ENZYMES&#x27;, name=&#x27;ENZYMES&#x27;)print(&quot;打印数据集的图表数量，类别数量，节点特征数量&quot;)print(len(dataset), dataset.num_classes, dataset.num_node_features)data = dataset[0] # Get the first graph object.print(data.num_nodes)&gt;&gt;&gt; 600 6 3&gt;&gt;&gt; 37 加入dataloader 123456dataset = TUDataset(root=&#x27;/tmp/ENZYMES&#x27;, name=&#x27;ENZYMES&#x27;, use_node_attr=True)loader = DataLoader(dataset, batch_size=32, shuffle=True)# 每个batch 32个图表for batch in loader: print(batch) 代表这个节点在哪张图里 12345678910for data in loader: data &gt;&gt;&gt; DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32]) data.num_graphs &gt;&gt;&gt; 32 x = scatter(data.x, data.batch, dim=0, reduce=&#x27;mean&#x27;) x.size() &gt;&gt;&gt; torch.Size([32, 21]) 分析scatter函数的汇总过程 输入数据: data.x: 这是节点特征矩阵，其形状为[1082, 21]。这意味着在这个批处理中，总共有1082个节点，每个节点有21个特征。 data.batch: 这是一个批次向量，其长度为1082（与 data.x中的节点数相同）。它指定了每个节点属于哪个图。 data.num_graphs: 这表示在批处理中有32个图。 使用scatter进行汇总: 你使用 scatter函数并指定 reduce='mean'，这意味着你想要计算每个图中的节点特征的平均值。 所以，对于每个图，它会考虑所有属于该图的节点（基于 data.batch），然后计算这些节点特征的平均值。结果是每个图都有一个平均的特征向量。 输出: x: 经过 scatter函数处理后，你得到一个新的张量 x，其形状为[32, 21]。这意味着现在你有32个平均特征向量，每个向量有21个特征（与输入 data.x中的特征数相同）。 每个平均特征向量对应于批处理中的一个图。这样，你从批处理中的1082个节点减少到了32个平均特征向量，每个都代表一个图。 结论: scatter的汇总工作是将这批处理中的每个图中的所有节点特征取平均，从而为每个图得到一个代表性的特征向量。这对于那些需要从整个图中提取特征的任务（例如，整图分类）非常有用。 数据转换 12345678import torch_geometric.transforms as Tfrom torch_geometric.datasets import ShapeNetdataset = ShapeNet(root=&#x27;/tmp/ShapeNet&#x27;, categories=[&#x27;Airplane&#x27;], pre_transform=T.KNNGraph(k=6))dataset[0]&gt;&gt;&gt; Data(edge_index=[2, 15108], pos=[2518, 3], y=[2518]) 该代码把点云图，找到每个点最邻近的6个点，加上边连接，所以15108 = 2518 * 6，数据集专注于飞机类别。而y属性中的值将表示飞机的各个部分（如机翼、尾翼、机身等） pre_transform vs transform pre_transform: 定义: pre_transform 是在保存数据集到磁盘之前应用的变换。 应用时机: 它只会执行一次，即在第一次下载和处理原始数据时。之后，即使你多次加载数据集，这个变换也不会再被应用。 示例解释: 在你的例子中，pre_transform=T.KNNGraph(k=6) 的意思是在数据被保存之前，对每个图形数据计算其k-最近邻图。具体来说，它会为每个点找到其6个最近的邻居，并创建一个边连接索引，表示这些近邻关系。 transform: 定义: transform 是每次从数据集中获取数据时都会应用的变换。 应用时机: 它是动态的，意味着每次你从数据集中提取一个数据项时，都会实时地应用这个变换。 示例解释: 在你的例子中，transform=T.RandomJitter(0.01) 的意思是每次提取数据时，都会对每个点的位置随机添加一个在 [-0.01, 0.01]范围内的扰动。这种随机扰动有助于数据增强，使模型更加鲁棒。 结论: pre_transform 是一个预处理步骤，只应用一次，而 transform 是一个每次都会应用的数据增强步骤。 图的学习方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051from torch_geometric.datasets import Planetoiddataset = Planetoid(root=&#x27;/tmp/Cora&#x27;, name=&#x27;Cora&#x27;)print(&quot;打印数据集的图表数量，类别数量，节点特征数量&quot;)print(len(dataset), dataset.num_classes, dataset.num_node_features)print(&quot;打印节点标签&quot;)print(dataset[0].keys)data = dataset[0] # Get the first graph object.print(data.num_nodes)import torchimport torch.nn.functional as Ffrom torch_geometric.nn import GCNConvclass GCN(torch.nn.Module): def __init__(self): super().__init__() self.conv1 = GCNConv(dataset.num_node_features, 16) self.conv2 = GCNConv(16, dataset.num_classes) def forward(self, data): x, edge_index = data.x, data.edge_index x = self.conv1(x, edge_index) x = F.relu(x) x = F.dropout(x, training=self.training) x = self.conv2(x, edge_index) return F.log_softmax(x, dim=1)device = torch.device(&#x27;cuda&#x27; if torch.cuda.is_available() else &#x27;cpu&#x27;)model = GCN().to(device)data = dataset[0].to(device)optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)model.train()for epoch in range(200): optimizer.zero_grad() out = model(data) loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask]) loss.backward() optimizer.step()model.eval()pred = model(data)print(pred.shape)pred = pred.argmax(dim=1)print (pred)correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()acc = int(correct) / int(data.test_mask.sum())print(f&#x27;Accuracy: &#123;acc:.4f&#125;&#x27;) 可以看到，图学习方法将边的信息融合了进去 现在让我们注意dim参数，dim的意思是，在某个维度上处理数据，argmax在7的概率分布中选择最大的那个 我们可以观察输出 12345678打印数据集的图表数量，类别数量，节点特征数量1 7 1433打印节点标签[&#x27;y&#x27;, &#x27;x&#x27;, &#x27;train_mask&#x27;, &#x27;val_mask&#x27;, &#x27;test_mask&#x27;, &#x27;edge_index&#x27;]2708torch.Size([2708, 7])tensor([3, 4, 4, ..., 5, 3, 3], device=&#x27;cuda:0&#x27;)Accuracy: 0.7880 关于这个mask是什么 1tensor([ True, True, True, ..., False, False, False]) 可以看出，就是为了区别是否加入训练 Exercises What does edge_index.t().contiguous() do? Load the &quot;IMDB-BINARY&quot; dataset from the TUDataset benchmark suite and randomly split it into 80%/10%/10% training, validation and test graphs. What does each number of the following output mean? 12print(batch)&gt;&gt;&gt; DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32]) edge_index.t().contiguous() 将 edge_index 张量转置并确保其在内存中连续存储。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"深度学习","slug":"深度学习","permalink":"http://jxclbx.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"GNNs","slug":"GNNs","permalink":"http://jxclbx.github.io/tags/GNNs/"},{"name":"课题组","slug":"课题组","permalink":"http://jxclbx.github.io/tags/%E8%AF%BE%E9%A2%98%E7%BB%84/"}]},{"title":"Ubuntu系统中如何快速安装和配置Clash代理","slug":"Ubuntu系统中如何快速安装和配置Clash代理","date":"2023-08-31T16:06:55.000Z","updated":"2023-09-01T03:13:31.361Z","comments":true,"path":"2023/09/01/Ubuntu系统中如何快速安装和配置Clash代理/","link":"","permalink":"http://jxclbx.github.io/2023/09/01/Ubuntu%E7%B3%BB%E7%BB%9F%E4%B8%AD%E5%A6%82%E4%BD%95%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AEClash%E4%BB%A3%E7%90%86/","excerpt":"","text":"前言 Clash 是一款免费的代理软件，可以帮助我们实现科学上网。在 Ubuntu 系统中安装和配置 Clash 代理非常简单，只需要按照以下步骤操作即可。 首先解决虚拟机剪切板问题 然而不行 然而还不行，提示安装增强功能时提示 未能加载虚拟光盘到虚拟电脑 删除这个光盘盘片 有了，然后在终端中打开盘片，再输入 ./autorun.sh 搞定 下载clash 打开 github，搜索 clash for Windows 1wget https://github.com/Fndroid/clash_for_windows_pkg/releases/download/0.20.32/Clash.for.Windows-0.20.32-x64-linux.tar.gz mkdir ~/.app mkdir 是 “make directory” 的缩写，用于创建新的目录。 ~/.app 指的是在用户主目录下创建一个名为 .app 的隐藏目录（因为它以 .开始）。 tar -zxvf Clash.for.Windows-0.19.12-x64-linux.tar.gz -C ~/.app tar 是一个用于归档文件的工具。 -zxvf 是选项的集合：-z 表示解压缩，-x 表示提取文件，-v 表示详细模式，-f 后面是要操作的文件。 Clash.for.Windows-0.19.12-x64-linux.tar.gz 是你要解压的文件。 -C ~/.app 表示解压后的文件将放置在 ~/.app 目录下。 cd ~/.app cd 是 “change directory” 的缩写，用于改变当前工作目录。 ~/.app 是你要切换到的目录。 mv Clash\\ for\\ Windows-0.19.12-x64-linux/ clash mv 是 “move” 的缩写，用于移动或重命名文件和目录。 Clash\\ for\\ Windows-0.19.12-x64-linux/ 是原始目录名，因为目录名包含空格，所以用反斜杠 \\ 进行转义。 clash 是新的目录名。 cd clash 同第3条命令，这条命令将你的当前工作目录切换到 clash。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"ubuntu","slug":"ubuntu","permalink":"http://jxclbx.github.io/tags/ubuntu/"},{"name":"linux","slug":"linux","permalink":"http://jxclbx.github.io/tags/linux/"},{"name":"clash","slug":"clash","permalink":"http://jxclbx.github.io/tags/clash/"},{"name":"科学上网","slug":"科学上网","permalink":"http://jxclbx.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"}]},{"title":"借助stackedit撰写远程日记","slug":"借助stackedit撰写远程日记","date":"2023-08-30T11:26:13.000Z","updated":"2023-08-31T04:15:25.538Z","comments":true,"path":"2023/08/30/借助stackedit撰写远程日记/","link":"","permalink":"http://jxclbx.github.io/2023/08/30/%E5%80%9F%E5%8A%A9stackedit%E6%92%B0%E5%86%99%E8%BF%9C%E7%A8%8B%E6%97%A5%E8%AE%B0/","excerpt":"","text":"欢迎来到 StackEdit 中文版！ 你好！我是你在 StackEdit中文版 中的第一个 Markdown 文件。如果你想了解 StackEdit中文版，可以阅读此文章。如果你想玩 Markdown，你也可以编辑此文章。另外，您可以通过打开导航栏左边的文件资源管理器来创建新文件。 文件 StackEdit中文版 将您的文件存储在您的浏览器中，这意味着您的所有文件都会自动保存在本地并且可以离线访问！ 创建文件和文件夹 使用导航栏左边的文件夹图标可以访问文件资源管理器。您可以通过单击文件资源管理器中的 创建文件 图标来创建新文件。您还可以通过单击 创建文件夹 图标来创建文件夹。 切换到另一个文件 您的所有文件和文件夹在文件资源管理器中都显示为树。您可以通过单击树中的文件从一个文件切换到另一个文件。 重命名文件 您可以通过单击导航栏中的文件名或单击文件资源管理器中的重命名图标来重命名当前文件。 搜索文件 您可以通过单击文件资源管理器中的搜索文件图标来通过关键字在整个文档空间中搜索文件。 删除一个文件 您可以通过单击文件资源管理器中的 删除 图标来删除当前文件。该文件将被移至 回收站 文件夹并在 7 天不活动后自动删除。 导出文件 您可以通过单击菜单中的 导入/导出 来导出当前文件。您可以选择将文件导出为纯 Markdown、使用 Handlebars 模板的 HTML 或 PDF。 同步 同步是 StackEdit中文版 的最大特点之一。它使您可以将文档空间中的任何文件与存储在Gitee 和 GitHub 账号中的其他文件同步。这使您可以继续在其他设备上写作，与您共享文件的人协作，轻松集成到您的工作流程中…同步机制在后台每分钟触发一次，下载、合并和上传文件修改。 有两种类型的同步，它们可以相互补充： 文档空间同步将自动同步您的所有文件、文件夹和设置。这将允许您在任何其他设备上获取您的文档空间。 要开始同步您的文档空间，只需在菜单中使用 Gitee 登录。 文件同步将保持文档空间的一个文件与Gitee或GitHub中的一个或多个文件同步。 在开始同步文件之前，您必须在同步子菜单中链接一个账号。 打开一个文件 您可以通过打开 同步 子菜单并单击 从…打开 从Gitee 或 GitHub 打开文件。在文档空间中打开后，文件中的任何修改都将自动同步。 保存文件 您可以通过打开 同步 子菜单并单击 在…保存 将文档空间的任何文件保存到Gitee 或 GitHub。即使文档空间中的文件已经同步，您也可以将其保存到另一个位置。 StackEdit中文版 可以将一个文件与多个位置和账号同步。 同步文件 一旦您的文件链接到同步位置，StackEdit中文版 将通过下载/上传任何修改来定期同步它。如有必要，将执行合并并解决冲突。 如果您刚刚修改了文件并且想要强制同步，请单击导航栏中的 立即同步 按钮。 注意： 如果您没有要同步的文件，立即同步按钮将被禁用。 管理文件同步 由于一个文件可以与多个位置同步，您可以通过单击同步子菜单中的文件同步列出和管理同步位置。这允许您列出和删除链接到您的文件的同步位置。 发布 在 StackEdit中文版 中发布使您可以轻松地在线发布文件。对文件感到满意后，您可以将其发布到不同的托管平台，例如 Blogger、Gitee、Gist、GitHub、WordPress 和 Zendesk。使用 Handlebars 模板，您可以完全控制导出的内容。 在开始发布之前，您必须在发布子菜单中链接一个账号。 发布文件 您可以通过打开 发布 子菜单并单击 发布到 来发布您的文件。对于某些位置，您可以选择以下格式： Markdown：在可以解释的网站上发布 Markdown 文本（例如GitHub）， HTML：通过 Handlebars 模板发布转换为 HTML 的文件（例如在博客上）。 更新发布 发布后，StackEdit中文版 会将您的文件链接到该发布，这使您可以轻松地重新发布它。一旦您修改了文件并想要更新您的发布，请单击导航栏中的立即发布按钮。 注意： 如果您没有要同步的文件，立即同步按钮将被禁用。 管理文件同步 由于一个文件可以与多个位置同步，您可以通过单击同步子菜单中的文件同步列出和管理同步位置。这允许您列出和删除链接到您的文件的同步位置。 Markdown扩展 StackEdit中文版 通过添加额外的 Markdown扩展 扩展了标准 Markdown 语法，为您提供了一些不错的功能。 提示： 您可以在 文件属性 对话框中禁用任何 Markdown 扩展名。 SmartyPants SmartyPants 将 ASCII 标点字符转换为“智能”印刷标点 HTML 实体。例如： ASCII HTML 单反引号 '这不好玩吗？' ‘这不好玩吗？’ 引用 “这不好玩吗？” “这不好玩吗？” 破折号 -- 是破折号，--- 是破折号 – 是破折号，— 是破折号 KaTeX 您可以使用 KaTeX 渲染 LaTeX 数学表达式： 满足 Γ(n)=(n−1)!∀n∈N\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb NΓ(n)=(n−1)!∀n∈N 的 Gamma 函数 是通过欧拉积分 Γ(z)=∫0∞tz−1e−tdt .\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt\\,. Γ(z)=∫0∞​tz−1e−tdt. 您可以在 这里 找到有关 LaTeX 数学表达式的更多信息。 UML 图 您可以使用 Mermaid 渲染 UML 图。例如，这将产生一个序列图： 123456789sequenceDiagram爱丽丝 -&gt;&gt; 鲍勃: 你好鲍勃，你好吗？鲍勃--&gt;&gt;约翰: 约翰，你呢？鲍勃--x 爱丽丝: 我很好，谢谢！鲍勃-x 约翰: 我很好，谢谢！Note right of 约翰: 鲍勃想了很长&lt;br/&gt;很长的时间，太长了&lt;br/&gt;文本确实&lt;br/&gt;不能放在一行中。鲍勃--&gt;爱丽丝: 正在和 John 核对...爱丽丝-&gt;约翰: 是的……约翰，你好吗？ 这将产生一个流程图： 12345graph LRA[长方形] -- 链接文本 --&gt; B((圆形))A --&gt; C(圆角矩形)B --&gt; D&#123;菱形&#125;C --&gt; D 图片 （将昨天功能改为把所有image以及新仓库里边的图片都复制到图床git里）将仓库克隆到本地，然后首先将其中所有图片移动到图床文件夹；将post中目前不存在的md文件复制进去，打开当前正在复制进去的文件，添加hexo的参数段；再遍历所有文件","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"测试自动图床","slug":"测试自动图床","date":"2023-08-27T17:40:04.000Z","updated":"2023-08-31T04:15:25.540Z","comments":true,"path":"2023/08/28/测试自动图床/","link":"","permalink":"http://jxclbx.github.io/2023/08/28/%E6%B5%8B%E8%AF%95%E8%87%AA%E5%8A%A8%E5%9B%BE%E5%BA%8A/","excerpt":"","text":"操，怎么就失败了呢，再试试 我好像要成功了","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"}]},{"title":"我回来了","slug":"我回来了","date":"2023-08-27T16:22:19.000Z","updated":"2023-08-31T04:15:25.540Z","comments":true,"path":"2023/08/28/我回来了/","link":"","permalink":"http://jxclbx.github.io/2023/08/28/%E6%88%91%E5%9B%9E%E6%9D%A5%E4%BA%86/","excerpt":"","text":"是的没错，很久没有更新之后，是时候来审视这个网站的作用。首先它部署在云端，让我回忆起来往昔更加容易一些……其实也并不容易，没有配图的文字确实是十分干燥，五月的事情没有配图，确实已经忘记的一干二净。其次呢，框架式的布局省去了一些排版上的麻烦，这是废话。为了把这些特性发扬出去，就需要一个提交网站的脚本……实现起来有一些技术难度，但我相信是可以攻克的，这样每时每刻想写的内容就可以及时地被记录下来，上传到图床。 明天开学，下学期能不能做的好一点呢？","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"使用Katex公式","slug":"使用Katex公式","date":"2023-06-05T03:27:41.000Z","updated":"2023-08-31T04:18:30.949Z","comments":true,"path":"2023/06/05/使用Katex公式/","link":"","permalink":"http://jxclbx.github.io/2023/06/05/%E4%BD%BF%E7%94%A8Katex%E5%85%AC%E5%BC%8F/","excerpt":"","text":"首先切换渲染器,在hexo目录下控制台执行以下代码 12npm uninstall hexo-renderer-marked --savenpm install hexo-renderer-markdown-it-plus --save front-matter中写入 1katex volantis自己的_config中 1234katex: js: https://unpkg.com/katex@0.16.4/dist/katex.min.js # https://unpkg.com/katex@0.15.2/dist/katex.min.js css: https://unpkg.com/katex@0.16.4/dist/katex.min.css # https://unpkg.com/katex@0.15.2/dist/katex.min.css render: https://unpkg.com/katex@0.16.4/dist/contrib/auto-render.min.js # https://unpkg.com/katex@0.15.2/dist/contrib/auto-render.min.js","categories":[],"tags":[]},{"title":"Pytorch的奇妙体验","slug":"pytorch的奇妙体验","date":"2023-05-09T13:11:25.000Z","updated":"2023-08-31T04:18:30.949Z","comments":true,"path":"2023/05/09/pytorch的奇妙体验/","link":"","permalink":"http://jxclbx.github.io/2023/05/09/pytorch%E7%9A%84%E5%A5%87%E5%A6%99%E4%BD%93%E9%AA%8C/","excerpt":"","text":"Dataset PyTorch中的Dataset类是一个抽象基类，用于表示数据集。它定义了两个必须实现的方法：__len__() 和 __getitem__()。这个基类是通用的，但它本身无法处理特定类型的数据。因此，当您需要处理特定类型的数据（例如图像、文本等）时，您需要创建一个继承自Dataset类的自定义类，并实现这两个方法，以便根据您的数据加载和处理需求来处理数据。 在您提供的代码示例中，您创建了一个名为ImageDataset的自定义数据集类，它继承自PyTorch的Dataset类。这个类实现了 __len__() 和 __getitem__() 方法，用于处理存储为NumPy格式的图像数据。通过这种方式，您可以使用自定义的数据集类来适应您的特定数据类型和数据处理需求。 总结一下，原因在于PyTorch的Dataset类是一个通用的抽象基类，无法直接处理特n定类型的数据。因此，需要创建自定义数据集类来实现针对特定数据类型的加载和处理。 网络1 12345678910111213141516class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 32, 5, stride=1) self.pool = nn.MaxPool2d(2, 2) self.conv2 = nn.Conv2d(32, 64, 5, stride=1) self.fc1 = nn.Linear(64 * 29 * 29, 128) self.fc2 = nn.Linear(128, 7) def forward(self, x): x = self.pool(F.relu(self.conv1(x))) x = self.pool(F.relu(self.conv2(x))) x = x.view(-1, 64 * 29 * 29) x = F.relu(self.fc1(x)) x = self.fc2(x) return x 效果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647Epoch 1 loss: 1.622, train acc: 0.522, test acc: 0.522Epoch 2 loss: 1.012, train acc: 0.740, test acc: 0.736Epoch 3 loss: 0.707, train acc: 0.811, test acc: 0.814Epoch 4 loss: 0.581, train acc: 0.852, test acc: 0.854Epoch 5 loss: 0.501, train acc: 0.840, test acc: 0.845Epoch 6 loss: 0.416, train acc: 0.886, test acc: 0.884Epoch 7 loss: 0.385, train acc: 0.863, test acc: 0.852Epoch 8 loss: 0.334, train acc: 0.902, test acc: 0.884Epoch 9 loss: 0.315, train acc: 0.922, test acc: 0.902Epoch 10 loss: 0.255, train acc: 0.907, test acc: 0.868Epoch 11 loss: 0.247, train acc: 0.937, test acc: 0.916Epoch 12 loss: 0.193, train acc: 0.956, test acc: 0.924Epoch 13 loss: 0.158, train acc: 0.959, test acc: 0.921Epoch 14 loss: 0.149, train acc: 0.967, test acc: 0.931Epoch 15 loss: 0.132, train acc: 0.961, test acc: 0.914Epoch 16 loss: 0.117, train acc: 0.976, test acc: 0.935Epoch 17 loss: 0.091, train acc: 0.968, test acc: 0.927Epoch 18 loss: 0.084, train acc: 0.980, test acc: 0.933Epoch 19 loss: 0.073, train acc: 0.975, test acc: 0.925Epoch 20 loss: 0.060, train acc: 0.990, test acc: 0.938Epoch 21 loss: 0.060, train acc: 0.978, test acc: 0.922Epoch 22 loss: 0.063, train acc: 0.989, test acc: 0.938Epoch 23 loss: 0.048, train acc: 0.991, test acc: 0.938Epoch 24 loss: 0.042, train acc: 0.990, test acc: 0.935Epoch 25 loss: 0.035, train acc: 0.994, test acc: 0.941Epoch 26 loss: 0.036, train acc: 0.991, test acc: 0.941Epoch 27 loss: 0.029, train acc: 0.993, test acc: 0.938Epoch 28 loss: 0.033, train acc: 0.998, test acc: 0.943Epoch 29 loss: 0.038, train acc: 0.993, test acc: 0.942Epoch 30 loss: 0.026, train acc: 0.998, test acc: 0.945Epoch 31 loss: 0.017, train acc: 0.997, test acc: 0.944Epoch 34 loss: 0.021, train acc: 0.996, test acc: 0.939Epoch 35 loss: 0.017, train acc: 0.990, test acc: 0.936Epoch 36 loss: 0.020, train acc: 0.997, test acc: 0.950Epoch 37 loss: 0.014, train acc: 0.997, test acc: 0.951Epoch 38 loss: 0.011, train acc: 0.998, test acc: 0.945Epoch 39 loss: 0.007, train acc: 1.000, test acc: 0.938Epoch 40 loss: 0.011, train acc: 1.000, test acc: 0.944Epoch 41 loss: 0.007, train acc: 0.995, test acc: 0.940Epoch 42 loss: 0.012, train acc: 1.000, test acc: 0.940Epoch 43 loss: 0.008, train acc: 0.999, test acc: 0.945Epoch 44 loss: 0.009, train acc: 1.000, test acc: 0.946Epoch 45 loss: 0.007, train acc: 0.997, test acc: 0.943Epoch 46 loss: 0.007, train acc: 0.999, test acc: 0.948Epoch 49 loss: 0.009, train acc: 1.000, test acc: 0.948Epoch 50 loss: 0.004, train acc: 1.000, test acc: 0.948Finished Training 这种比较简单的网络结构可能存在一些缺陷： 模型表达能力有限：该网络的深度相对较浅，层数较少，可能无法充分提取输入数据的特征，从而导致模型表达能力不足。 容易出现过拟合：该网络没有使用正则化技术，如dropout等，容易在训练过程中出现过拟合问题，导致模型在测试集上表现不佳。 卷积核尺寸较大：该网络使用的卷积核尺寸为5，可能会导致卷积后的特征图失去一些细节信息，从而降低模型性能。 没有使用预训练模型：该网络是从头开始训练的，没有使用任何预训练模型，可能会导致训练时间较长，模型性能不佳。 以上是该网络可能存在的一些缺陷，可以通过调整网络结构、添加正则化技术、使用更小的卷积核等方式来提高模型性能。 简单提升CNN网络性能 增加了更多卷积层，批量标准化层和 Dropout 层来提高性能： 123456789101112131415161718192021222324252627282930313233343536373839class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = nn.Conv2d(3, 32, 3, padding=1) self.bn1 = nn.BatchNorm2d(32) self.conv2 = nn.Conv2d(32, 64, 3, padding=1) self.bn2 = nn.BatchNorm2d(64) self.pool = nn.MaxPool2d(2, 2) self.conv3 = nn.Conv2d(64, 128, 3, padding=1) self.bn3 = nn.BatchNorm2d(128) self.conv4 = nn.Conv2d(128, 128, 3, padding=1) self.bn4 = nn.BatchNorm2d(128) self.conv5 = nn.Conv2d(128, 256, 3, padding=1) self.bn5 = nn.BatchNorm2d(256) self.conv6 = nn.Conv2d(256, 256, 3, padding=1) self.bn6 = nn.BatchNorm2d(256) self.fc1 = nn.Linear(256 * 8 * 8, 512) self.fc2 = nn.Linear(512, 256) self.fc3 = nn.Linear(256, 7) self.dropout = nn.Dropout(p=0.5) def forward(self, x): x = self.pool(F.relu(self.bn1(self.conv1(x)))) x = self.pool(F.relu(self.bn2(self.conv2(x)))) x = F.relu(self.bn3(self.conv3(x))) x = self.pool(F.relu(self.bn4(self.conv4(x)))) x = F.relu(self.bn5(self.conv5(x))) x = self.pool(F.relu(self.bn6(self.conv6(x)))) x = x.view(-1, 256 * 8 * 8) x = self.dropout(F.relu(self.fc1(x))) x = self.dropout(F.relu(self.fc2(x))) x = self.fc3(x) return x 效果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041Epoch 1 loss: 1.625, train acc: 0.466, test acc: 0.465Epoch 2 loss: 1.146, train acc: 0.707, test acc: 0.712Epoch 3 loss: 0.603, train acc: 0.895, test acc: 0.883Epoch 4 loss: 0.313, train acc: 0.938, test acc: 0.937Epoch 5 loss: 0.175, train acc: 0.963, test acc: 0.951Epoch 6 loss: 0.135, train acc: 0.970, test acc: 0.956Epoch 7 loss: 0.092, train acc: 0.982, test acc: 0.967Epoch 8 loss: 0.071, train acc: 0.986, test acc: 0.968Epoch 9 loss: 0.055, train acc: 0.988, test acc: 0.971Epoch 10 loss: 0.043, train acc: 0.990, test acc: 0.971Epoch 11 loss: 0.036, train acc: 0.995, test acc: 0.968Epoch 12 loss: 0.028, train acc: 0.994, test acc: 0.979Epoch 13 loss: 0.024, train acc: 0.996, test acc: 0.977Epoch 14 loss: 0.016, train acc: 0.998, test acc: 0.977Epoch 15 loss: 0.017, train acc: 0.997, test acc: 0.978Epoch 16 loss: 0.017, train acc: 0.997, test acc: 0.978Epoch 17 loss: 0.015, train acc: 0.998, test acc: 0.981Epoch 18 loss: 0.013, train acc: 0.998, test acc: 0.979Epoch 19 loss: 0.010, train acc: 0.998, test acc: 0.976Epoch 20 loss: 0.008, train acc: 0.999, test acc: 0.978Epoch 21 loss: 0.008, train acc: 0.999, test acc: 0.980Epoch 22 loss: 0.007, train acc: 0.998, test acc: 0.980Epoch 23 loss: 0.006, train acc: 1.000, test acc: 0.979Epoch 24 loss: 0.005, train acc: 0.999, test acc: 0.978Epoch 25 loss: 0.006, train acc: 0.999, test acc: 0.977Epoch 26 loss: 0.005, train acc: 1.000, test acc: 0.979Epoch 27 loss: 0.005, train acc: 1.000, test acc: 0.977Epoch 28 loss: 0.004, train acc: 0.999, test acc: 0.978Epoch 29 loss: 0.005, train acc: 0.999, test acc: 0.976Epoch 30 loss: 0.004, train acc: 0.999, test acc: 0.982Epoch 31 loss: 0.004, train acc: 1.000, test acc: 0.977Epoch 32 loss: 0.006, train acc: 0.999, test acc: 0.979Epoch 33 loss: 0.005, train acc: 1.000, test acc: 0.978Epoch 34 loss: 0.004, train acc: 0.999, test acc: 0.976Epoch 35 loss: 0.003, train acc: 1.000, test acc: 0.982Epoch 36 loss: 0.003, train acc: 1.000, test acc: 0.977Epoch 37 loss: 0.003, train acc: 1.000, test acc: 0.979Epoch 38 loss: 0.003, train acc: 1.000, test acc: 0.976Epoch 39 loss: 0.003, train acc: 1.000, test acc: 0.979Epoch 40 loss: 0.002, train acc: 1.000, test acc: 0.982Epoch 41 loss: 0.002, train acc: 1.000, test acc: 0.980 网络2（Resnet） 拟合速度更快，准确率更高的网络是残差网络（ResNet）。 ResNet是由微软提出的深度残差网络，其主要思想是通过引入残差连接来解决网络退化问题，从而允许网络更深更广，并提高了模型准确率和泛化能力。ResNet常用的版本包括ResNet-18、ResNet-34、ResNet-50、ResNet-101和ResNet-152等。 相比于其他深度神经网络，ResNet的优点有： 更快的训练速度：ResNet通过残差连接解决了梯度消失问题，使得网络可以更深更宽，从而能够更好地拟合数据，提高了训练速度。 更好的泛化能力：残差连接允许网络跨层直接传递信息，避免了信息的损失，使得网络可以更好地学习到数据的特征，提高了模型的泛化能力。 更高的准确率：ResNet通过引入残差连接，使得网络可以更深更宽，提高了模型的表达能力，从而能够更好地拟合数据，提高了模型的准确率。 但是，相比于其他深度神经网络，ResNet占用更多的显存，需要更多的计算资源来训练。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566class BasicBlock(nn.Module): def __init__(self, in_channels, out_channels, stride=1, downsample=None): super(BasicBlock, self).__init__() self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False) self.bn1 = nn.BatchNorm2d(out_channels) self.relu = nn.ReLU(inplace=True) self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False) self.bn2 = nn.BatchNorm2d(out_channels) self.downsample = downsample def forward(self, x): residual = x out = self.conv1(x) out = self.bn1(out) out = self.relu(out) out = self.conv2(out) out = self.bn2(out) if self.downsample: residual = self.downsample(x) out += residual out = self.relu(out) return outclass ResNet(nn.Module): def __init__(self, block, layers, num_classes=7): super(ResNet, self).__init__() self.in_channels = 64 self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(64) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) self.layer1 = self.make_layer(block, 64, layers[0]) self.layer2 = self.make_layer(block, 128, layers[1], 2) self.layer3 = self.make_layer(block, 256, layers[2], 2) self.layer4 = self.make_layer(block, 512, layers[3], 2) self.avgpool = nn.AdaptiveAvgPool2d((1, 1)) self.fc = nn.Linear(512, num_classes) def make_layer(self, block, out_channels, blocks, stride=1): downsample = None if stride != 1 or self.in_channels != out_channels: downsample = nn.Sequential( nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False), nn.BatchNorm2d(out_channels) ) layers = [] layers.append(block(self.in_channels, out_channels, stride, downsample)) self.in_channels = out_channels for _ in range(1, blocks): layers.append(block(out_channels, out_channels)) return nn.Sequential(*layers) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.avgpool(x) x = x.view(x.size(0), -1) x = self.fc(x) return x Resnet存在着如下几个问题 网络的深度限制：尽管ResNet的提出解决了深度神经网络的梯度消失问题，但是当网络的深度增加时，ResNet仍然会出现梯度消失和梯度爆炸的问题。这限制了ResNet的深度。 特征重复利用不充分：在ResNet中，残差块中的特征并没有充分地被重复利用。相对于DenseNet，ResNet的特征传递方式是逐级传递，即特征只在当前和下一个块之间传递，而不是在所有块之间传递。 训练时间较长：由于ResNet是一个非常深的网络，所以它的训练时间会比较长，特别是当训练数据集很大时。 1234567891011121314151617181920212223242526272829Epoch 1 loss: 1.333, train acc: 0.757, test acc: 0.734Epoch 2 loss: 0.492, train acc: 0.938, test acc: 0.904Epoch 3 loss: 0.171, train acc: 0.982, test acc: 0.951Epoch 4 loss: 0.061, train acc: 0.996, test acc: 0.956Epoch 5 loss: 0.026, train acc: 0.999, test acc: 0.960Epoch 6 loss: 0.012, train acc: 1.000, test acc: 0.960Epoch 7 loss: 0.006, train acc: 1.000, test acc: 0.962Epoch 8 loss: 0.005, train acc: 1.000, test acc: 0.964Epoch 9 loss: 0.004, train acc: 1.000, test acc: 0.963Epoch 10 loss: 0.003, train acc: 1.000, test acc: 0.964Epoch 11 loss: 0.003, train acc: 1.000, test acc: 0.964Epoch 12 loss: 0.002, train acc: 1.000, test acc: 0.964Epoch 13 loss: 0.002, train acc: 1.000, test acc: 0.964Epoch 14 loss: 0.002, train acc: 1.000, test acc: 0.963Epoch 15 loss: 0.002, train acc: 1.000, test acc: 0.964Epoch 16 loss: 0.002, train acc: 1.000, test acc: 0.963Epoch 17 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 18 loss: 0.001, train acc: 1.000, test acc: 0.962Epoch 19 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 20 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 21 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 22 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 23 loss: 0.001, train acc: 1.000, test acc: 0.964Epoch 24 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 25 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 26 loss: 0.001, train acc: 1.000, test acc: 0.964Epoch 27 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 28 loss: 0.001, train acc: 1.000, test acc: 0.963Epoch 29 loss: 0.001, train acc: 1.000, test acc: 0.963 网络3（DenseNet） 在DenseNet中，每个层的输出都会被连接到后续所有层的输入中，这使得每个层都可以直接获取到之前所有层的特征图，从而增加了特征重用的程度，避免了特征的浪费。在DenseNet中，特征图之间的连接可以使用张量拼接（concatenate）来实现。 具体地，DenseNet可以由多个密集块（Dense Block）和一个全局池化层（Global Pooling Layer）组成。每个密集块由多个卷积层和一个批量归一化层（Batch Normalization Layer）组成，卷积层的输出将被拼接到后续所有卷积层的输入中。全局池化层的输出将被送入一个全连接层和一个Softmax层中进行分类。 DenseNet的优点包括： 特征重用程度高：在DenseNet中，每个层都可以直接获取到之前所有层的特征图，从而增加了特征重用的程度，避免了特征的浪费。 模型参数较少：在DenseNet中，由于特征图之间的连接可以使用张量拼接来实现，所以模型参数较少。 准确率高：DenseNet在图像分类等任务上表现出色，达到了当时最好的性能。 然而，DenseNet也有一些缺点，如模型计算量较大、模型结构复杂等。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182class DenseLayer(nn.Module): def __init__(self, in_channels, growth_rate): super(DenseLayer, self).__init__() self.bn1 = nn.BatchNorm2d(in_channels) self.conv1 = nn.Conv2d(in_channels, growth_rate * 4, kernel_size=1, stride=1, bias=False) self.bn2 = nn.BatchNorm2d(growth_rate * 4) self.conv2 = nn.Conv2d(growth_rate * 4, growth_rate, kernel_size=3, stride=1, padding=1, bias=False) def forward(self, x): out = self.bn1(x) out = F.relu(out) out = self.conv1(out) out = self.bn2(out) out = F.relu(out) out = self.conv2(out) out = torch.cat((x, out), 1) return outclass DenseBlock(nn.Module): def __init__(self, in_channels, growth_rate, num_layers): super(DenseBlock, self).__init__() self.layers = nn.ModuleList([DenseLayer(in_channels + i * growth_rate, growth_rate) for i in range(num_layers)]) def forward(self, x): for layer in self.layers: x = layer(x) return xclass TransitionLayer(nn.Module): def __init__(self, in_channels, out_channels): super(TransitionLayer, self).__init__() self.bn = nn.BatchNorm2d(in_channels) self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False) def forward(self, x): out = self.bn(x) out = F.relu(out) out = self.conv(out) out = F.avg_pool2d(out, 2) return outclass DenseNet(nn.Module): def __init__(self, growth_rate, block_config, num_classes=7): super(DenseNet, self).__init__() self.conv1 = nn.Conv2d(3, growth_rate * 2, kernel_size=7, stride=2, padding=3, bias=False) self.bn1 = nn.BatchNorm2d(growth_rate * 2) self.relu = nn.ReLU(inplace=True) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) in_channels = growth_rate * 2 self.dense_blocks = nn.ModuleList() self.transition_layers = nn.ModuleList() for i, num_layers in enumerate(block_config): dense_block = DenseBlock(in_channels, growth_rate, num_layers) self.dense_blocks.append(dense_block) in_channels += num_layers * growth_rate if i != len(block_config) - 1: transition_layer = TransitionLayer(in_channels, in_channels // 2) self.transition_layers.append(transition_layer) in_channels = in_channels // 2 self.bn2 = nn.BatchNorm2d(in_channels) self.fc = nn.Linear(in_channels, num_classes) def forward(self, x): x = self.conv1(x) x = self.bn1(x) x = self.relu(x) x = self.maxpool(x) for i, dense_block in enumerate(self.dense_blocks): x = dense_block(x) if i != len(self.dense_blocks) - 1: x = self.transition_layers[i](x) x = self.bn2(x) x = F.relu(x) x = F.adaptive_avg_pool2 效果如下； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748Epoch 1 loss: 1.401, train acc: 0.684, test acc: 0.669Epoch 2 loss: 0.556, train acc: 0.945, test acc: 0.921Epoch 3 loss: 0.188, train acc: 0.984, test acc: 0.951Epoch 4 loss: 0.074, train acc: 0.997, test acc: 0.956Epoch 5 loss: 0.024, train acc: 1.000, test acc: 0.965Epoch 6 loss: 0.012, train acc: 1.000, test acc: 0.966Epoch 7 loss: 0.007, train acc: 1.000, test acc: 0.964Epoch 8 loss: 0.005, train acc: 1.000, test acc: 0.965Epoch 9 loss: 0.004, train acc: 1.000, test acc: 0.967Epoch 10 loss: 0.003, train acc: 1.000, test acc: 0.966Epoch 11 loss: 0.003, train acc: 1.000, test acc: 0.965Epoch 12 loss: 0.003, train acc: 1.000, test acc: 0.966Epoch 13 loss: 0.002, train acc: 1.000, test acc: 0.967Epoch 14 loss: 0.002, train acc: 1.000, test acc: 0.967Epoch 15 loss: 0.002, train acc: 1.000, test acc: 0.966Epoch 16 loss: 0.002, train acc: 1.000, test acc: 0.967Epoch 17 loss: 0.002, train acc: 1.000, test acc: 0.966Epoch 18 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 19 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 20 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 21 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 22 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 23 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 24 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 25 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 26 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 27 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 28 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 29 loss: 0.001, train acc: 1.000, test acc: 0.966Epoch 30 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 31 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 34 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 36 loss: 0.001, train acc: 1.000, test acc: 0.968Epoch 37 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 38 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 39 loss: 0.001, train acc: 1.000, test acc: 0.967Epoch 40 loss: 0.001, train acc: 1.000, test acc: 0.968Epoch 41 loss: 0.001, train acc: 1.000, test acc: 0.968Epoch 42 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 43 loss: 0.000, train acc: 1.000, test acc: 0.967Epoch 44 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 45 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 46 loss: 0.000, train acc: 1.000, test acc: 0.967Epoch 47 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 48 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 49 loss: 0.000, train acc: 1.000, test acc: 0.968Epoch 50 loss: 0.000, train acc: 1.000, test acc: 0.968Finished Training 提高准确度方法： 调整超参数：尝试不同的学习率、批量大小、优化器和权重衰减。可以使用网格搜索或随机搜索找到最佳超参数组合。同时，可以考虑使用学习率调度器逐渐降低学习率。 更深或更宽的模型：尝试使用更复杂的模型，如更深或更宽的 ResNet、DenseNet 或其他现代架构。通常，更复杂的模型具有更大的表示能力，可以提高性能。 数据增强：使用数据增强技术，如随机旋转、翻转、缩放、剪裁和亮度调整等，可以扩展训练数据集并提高模型泛化能力。 正则化：使用正则化技术，如 L1 或 L2 正则化、Dropout 或 Batch Normalization，可以减轻过拟合并提高模型泛化能力。 更多数据：如果可能，尝试收集更多的训练数据。更多的数据有助于模型学习更多的特征，从而提高准确性。 早停法：在验证集上监控模型性能，当性能不再提高时，提前停止训练。这有助于防止过拟合。 预训练模型：使用预训练的模型作为初始模型，然后在您的数据集上进行微调。这样可以利用在大型数据集上学到的特征，加速收敛并提高性能。 集成方法：训练多个模型并将它们的输出结合起来。这可以是简单的平均，或者可以使用更复杂的技术，如投票或模型堆叠。这有助于提高模型的稳定性和准确性。 数据增强 与上文不同，我在加入高斯噪声的基础上加入了图像旋转变换来提高模型的泛化能力 损失函数 要改善模型的训练效果，您可以尝试使用其他损失函数。这里我使用Label Smoothing Cross Entropy损失。可以提高模型的泛化能力，因为它在训练过程中为模型提供了额外的正则化。 12345678910111213141516class LabelSmoothingCrossEntropy(nn.Module): def __init__(self, eps=0.1, reduction=&#x27;mean&#x27;): super(LabelSmoothingCrossEntropy, self).__init__() self.eps = eps self.reduction = reduction def forward(self, output, target): c = output.size(1) log_preds = F.log_softmax(output, dim=1) loss = F.nll_loss(log_preds, target, reduction=self.reduction) smooth_loss = -log_preds.mean(dim=1) if self.reduction == &#x27;mean&#x27;: smooth_loss = smooth_loss.mean() elif self.reduction == &#x27;sum&#x27;: smooth_loss = smooth_loss.sum() return loss * (1 - self.eps) + smooth_loss * self.eps BATCH_SIZE Batch size的选择对模型的训练效果和收敛速度有很大影响。然而，并没有一个固定的答案来确定最佳的batch size。 训练稳定性和收敛速度 ：较大的batch size可以让梯度下降过程更稳定，因为每个batch的平均梯度对噪声更不敏感。然而，大的batch size可能会导致训练过程收敛速度变慢，因为每次迭代更新权重的次数减少了。相反，较小的batch size可以提高训练速度，因为每个epoch内权重更新的次数增加，但可能会导致训练过程不稳定，这是由于小batch size中噪声较多。 泛化能力 ：有研究表明，较小的batch size可能有助于提高模型的泛化能力。这可能是因为较小的batch size在训练过程中引入了随机性和正则化，从而防止模型过拟合。 训练时间 ：较大的batch size可以减少每个epoch所需的迭代次数，从而减少同步和数据传输的开销，提高计算资源的利用率。但是，如果batch size过大，可能会导致GPU内存不足，进而影响训练速度。","categories":[{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/categories/CV/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/tags/CV/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://jxclbx.github.io/tags/Pytorch/"}]},{"title":"网页设计与制作作业2","slug":"网页设计与制作作业2","date":"2023-05-09T05:55:09.000Z","updated":"2023-08-31T10:15:20.546Z","comments":true,"path":"2023/05/09/网页设计与制作作业2/","link":"","permalink":"http://jxclbx.github.io/2023/05/09/%E7%BD%91%E9%A1%B5%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%88%B6%E4%BD%9C%E4%BD%9C%E4%B8%9A2/","excerpt":"","text":"阐述 CSS 盒模型原理 CSS盒模型是CSS中最基础的概念之一，它描述了一个元素在网页中的呈现方式。盒模型将一个元素看做是一个矩形盒子，由四个部分组成：内容区域（content）、内边距区域（padding）、边框区域（border）和外边距区域（margin）。 内容区域，也就是元素内部实际显示内容的区域。比如div元素，它的内容区域就是它所包含的文字、图片、列表等内容。 内边距区域，它是在内容区域和边框之间的空白区域，它为元素的内容提供空间。可以设置背景颜色、背景图片等样式属性。可以通过设置padding属性来调整内边距的大小。 边框区域，它包围着内边距和内容区域，并为元素提供了可见的边界。可以通过设置border属性来调整边框的大小、样式和颜色。 外边距区域，它是元素边框与相邻元素边框之间的空白区域。可以通过设置margin属性来调整外边距的大小。 举例阐述 CSS 中几种常用的选择器 通配符选择器（Wildcard Selector）：使用 * 选择器可以匹配页面上的所有元素。 标签选择器（Tag Selector）：使用标签名称作为选择器，例如 div、p、h1，可以选择指定类型的元素。 ID 选择器（ID Selector）：使用 # 加上元素的唯一标识符，例如 #myId，可以选择具有指定 ID 的元素。ID 应在页面中是唯一的。 类选择器（Class Selector）：使用 . 加上类名，例如 .myClass，可以选择具有指定类名的元素。多个元素可以共享相同的类。 伪类选择器（Pseudo-Class Selector）：使用 : 加上伪类名，例如 :hover、:first-child，可以选择特定状态或位置的元素。伪类可以根据用户交互或元素的位置进行选择。 具体效果剪文件夹内代码 举例阐述 CSS 几种定位方式 绝对定位（Absolute Positioning）：使用 position: absolute; 将元素的位置相对于其最近的已定位祖先元素进行定位，如果没有已定位的祖先元素，则相对于文档的窗口进行定位。通过使用 top、bottom、left 和 right 属性，可以精确控制元素在页面上的位置。 相对定位（Relative Positioning）：使用 position: relative; 将元素相对于其正常位置进行定位。相对定位不会改变其他元素的布局，仍会占据原来的空间。通过使用 top、bottom、left 和 right 属性，可以相对于元素的正常位置调整其位置。 固定定位（Fixed Positioning）：使用 position: fixed; 将元素的位置相对于视口（浏览器窗口）进行定位，无论页面滚动与否，元素都会保持在固定的位置。通过使用 top、bottom、left 和 right 属性，可以确定元素在视口中的具体位置。 浮动定位（Float Positioning）：使用 float 属性将元素从正常的文档流中浮动到指定的位置。浮动元素可以向左或向右浮动，并使其周围的元素环绕在其周围。浮动通常用于创建多列布局。 做一个 CSS 3动画 使用了 CSS 的样式和关键帧动画来实现了一个动画效果，通过定义样式和应用动画属性创建了一个渐变放大和旋转的圆形元素，并在动画结束后以渐变放大的方式显示了一段文字。 linear-gradient()：渐变函数用于创建线性渐变背景。在 .circle 类的样式中，使用了 linear-gradient(45deg, #ff8a00, #e52e71, #4c4c4c) 来创建一个从斜角 45 度开始的线性渐变背景。 border-radius：用于设置元素的边框圆角。在 .circle 类的样式中，使用了 border-radius: 50% 来将元素设置为一个圆形。 transform：用于对元素进行变换，例如旋转、缩放、平移等。在 .circle 和 .text 类的样式中，使用了 transform: translate(-50%, -50%) scale(0) 来设置元素的初始位置和大小。 animation 和 @keyframes：这是 CSS3 中用于创建动画的特性。在 .circle 和 .text 类的样式中，使用了 animation 属性来指定动画名称、持续时间、缓动函数和循环次数等。而 @keyframes 则定义了关键帧动画的不同阶段和样式","categories":[{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/categories/HTML/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"},{"name":"网页","slug":"网页","permalink":"http://jxclbx.github.io/tags/%E7%BD%91%E9%A1%B5/"}]},{"title":"快速使用VSCode编写HTML文件","slug":"快速使用VSCode编写HTML文件","date":"2023-05-09T05:33:11.000Z","updated":"2023-09-01T03:12:03.659Z","comments":true,"path":"2023/05/09/快速使用VSCode编写HTML文件/","link":"","permalink":"http://jxclbx.github.io/2023/05/09/%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8VSCode%E7%BC%96%E5%86%99HTML%E6%96%87%E4%BB%B6/","excerpt":"","text":"安装 安装相关插件——搜索html,安装如下插件 再次打开插件商店，搜索open in browser 回到你的html文件，ctrl+s保存文件，然后shift+alt+b，在弹出的窗口中输入open in ,选择open in Other Browsers,如图(或者右键文件空白处，如图二红箭头所指向的两个，一个是用默认浏览器，一个是用其他浏览器。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"http://jxclbx.github.io/tags/vscode/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"}]},{"title":"Hexo博客自定义页面跳过渲染","slug":"Hexo博客自定义页面跳过渲染","date":"2023-05-08T07:39:01.000Z","updated":"2023-08-31T04:18:30.947Z","comments":true,"path":"2023/05/08/Hexo博客自定义页面跳过渲染/","link":"","permalink":"http://jxclbx.github.io/2023/05/08/Hexo%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2%E8%B7%B3%E8%BF%87%E6%B8%B2%E6%9F%93/","excerpt":"","text":"Hexo自定义原理 Hexo 系列的博客中的文章都是经Hexo的主题渲染的静态网页。所以Hexo博客大部分都呈现出一种高度的统一化与规范化。不过 Hexo 提供了跳过渲染功能，使得我们可以直接在博客中放入自定义网页。 比如在博客中放入图片、自定义404.html、自定义About页面、简历等 创建自定义网页 网页可以是自己编写的，也可以是别人现成的源码（下载喜欢的页面）。 网页编写完成后，在Hexo\\source目录下创建一个文件夹（文件夹名称任意，比如我创建的是about这个文件夹，部署完成后，访问http://mrlsm.github.io/about即可看到效果，依此类推） 将 html 文件放置于此文件夹，并重命名为 index.html 。 跳过渲染 跳过渲染有下述两种方法： 在自定义页面的开头添加如下： 123---layout: false--- 添加该指令后，执行 hexo g命令时便会跳过该 index.html文件，使得index.html不受当前 hexo 主题影响，完全是一个独立的网页，如果网页引用了 css 或 js，css 和 js 需使用外链或者将css js 文件放入index.html同目录下引用。 引用图片亦是如此 在_config.yml文件中设置skip_render 使用编辑器打开 Hexo 目录下的_config.yml文件，找到skip_render skip_render一般有以下四种常用参数： 跳过source目录下的 test.html: skip_render: test.html 跳过source目录下 test 文件夹内所有文件：skip_render: test/* 跳过source目录下 test 文件夹内所有文件包括子文件夹以及子文件夹内的文件：skip_render: test/** 跳过多个路径： 123skip_render:- curriculumVitae/**- DecrypeMusic/** 最后执行 1hexo g -d","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://jxclbx.github.io/tags/hexo/"},{"name":"音乐","slug":"音乐","permalink":"http://jxclbx.github.io/tags/%E9%9F%B3%E4%B9%90/"}]},{"title":"算法设计实验题目","slug":"算法设计实验题目","date":"2023-05-06T08:37:01.000Z","updated":"2023-08-31T04:15:25.541Z","comments":true,"path":"2023/05/06/算法设计实验题目/","link":"","permalink":"http://jxclbx.github.io/2023/05/06/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E5%AE%9E%E9%AA%8C%E9%A2%98%E7%9B%AE/","excerpt":"","text":"GS算法匹配小狗狗 忘了 BFS DFS树的层序遍历（3月29日） 4.5没上课","categories":[{"name":"算法设计课程","slug":"算法设计课程","permalink":"http://jxclbx.github.io/categories/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"算法","slug":"算法","permalink":"http://jxclbx.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Anaconda配置PyTorch环境","slug":"Anaconda配置PyTorch环境","date":"2023-05-05T14:36:39.000Z","updated":"2023-08-31T04:15:25.533Z","comments":true,"path":"2023/05/05/Anaconda配置PyTorch环境/","link":"","permalink":"http://jxclbx.github.io/2023/05/05/Anaconda%E9%85%8D%E7%BD%AEPyTorch%E7%8E%AF%E5%A2%83/","excerpt":"","text":"在Anaconda下安装Pytorch 安装pytorch，有两种办法，一是pip，二是conda。不管什么样的方法，首先，都要安装最新的anaconda。 安装Anaconda Anaconda指的是一个开源的Python发行版本，其包含了conda、Python等180多个科学包及其依赖项。里面所包含的Jupyter Notebook是数据挖掘领域中最热门的工具。(例如Kaggle网站) 没安装Anaconda的小伙伴可以参考以下安装链接： https://blog.csdn.net/qq_4521807/article/details/112442577 安装Pytorch 打开Anaconda Prompt 在命令行格式下，输入代码，完成调用清华镜像、建立pytorch环境、安装pytorch、测试pytorch过程 调用清华镜像 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ 1conda config --set show_channel_urls yes 1conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ 这个配置好以后，以后再安装其他的软件如果要用到清华镜像源网站就不用了重新配置了。 注意！如果切换镜像后当出现下载不了的情况，就先切换默认源，然后再修改另一个可以使用的conda源（一定要先恢复默认，再换另一个！！！） 切回默认源： 1conda config --remove-key channels 创建Pytorch环境 说真的，别在命令行里费那劲了，给你个GUI为嘛不用呢 1conda create -n pytorch python=3.7 查看环境是否安装成功 1conda info --envs 下载Pytorch 根据自己的安装版本，在Pytorch官网寻找安装命令代码：Pytorch官网：https://pytorch.org/ 查看CUDA版本 nvidia-smi solve environment需要比较长的时间，换了清华源之后就基本不需要挂梯子了 等待安装完成出现done 此时在vscode中可以在python解释器选择里看到pytorch环境的解释器： 按下F1键选择解释器，结束。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"anaconda","slug":"anaconda","permalink":"http://jxclbx.github.io/tags/anaconda/"},{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"}]},{"title":"Anaconda常用操作","slug":"Anaconda常用配置","date":"2023-05-04T09:30:21.000Z","updated":"2023-08-31T04:18:30.946Z","comments":true,"path":"2023/05/04/Anaconda常用配置/","link":"","permalink":"http://jxclbx.github.io/2023/05/04/Anaconda%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/","excerpt":"","text":"在使用 python anaconda时，经常会用到很多常用操作，记录下来，方便以后更好地使用： Conda Conda既是一个包管理器又是一个环境管理器。你肯定知道包管理器，它可以帮你发现和查看包。但是如果当我们想要安装一个包，但是这个包只支持跟我们目前使用的python不同的版本时。你只需要几行命令，就可以搭建起一个可以运行另外python版本的环境。这就是conda环境管理器的强大功能。 Conda常用命令 1conda update conda # 升级conda 12conda create -n pytorch1 python=3 Astroid Babel#创建基于python3 ，包含Astroid 和 Babel 包，称为pytorch1的新环境，在/envs/bunnies文件夹里 123# 查看当前可用环境conda env list conda info --envs 123# 切换工作环境conda activate baseconda deactivate 123456# 复制一个环境conda create -n flowers --clone snowflakes # 重新命名：先 clone 一份 new name 的环境；删除 old name 的环境；conda create -n tf --clone rcnn # 克隆conda remove -n rcnn --all # 删除conda info -e # 重新查看环境 123# 删除一个环境conda remove -n flowers --allconda info -e # 查看是否环境已经成功被移除 12345678# 管理Python环境# 检查python版本conda search --full --name python conda search python # 使用模糊匹配 # 安装一个新的版本 conda create -n snakes python=3# 查看已经安装的环境 conda info -e 123456789101112# 管理包# 查看当前环境中包含的包和其版本列表 conda list # 查找一个包conda search beautifulsoup4 # 安装一个包conda install --name bunnies beautifulsoup4 # 你必须告诉conda你要安装环境的名字（-n bunies）否则它将会被安装到当前环境中 # 使用 pip 安装一个包，并可使用 conda list 进行查看；pip install see conda list 123# 删除整个anaconda rm -rf ~/miniconda OR rm -rf ~/anaconda # 直接删除整个文件夹，并去除.bashrc 中的配置文件即可，对环境影响较少；","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"anaconda","slug":"anaconda","permalink":"http://jxclbx.github.io/tags/anaconda/"},{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"}]},{"title":"站内搜索","slug":"站内搜索","date":"2023-05-03T05:46:39.000Z","updated":"2023-08-31T04:18:30.951Z","comments":true,"path":"2023/05/03/站内搜索/","link":"","permalink":"http://jxclbx.github.io/2023/05/03/%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2/","excerpt":"","text":"站内搜索 配置代码 1234567891011121314# To use hexo search, you need to install the following plugins:# npm i hexo-generator-json-contentsearch: enable: true service: hexo # hexo, algolia, meilisearch algolia: searchAsYouType: true # If false, triggers the search only on submit. hitsPerPage: 5 # Set the number of hits per page. placeholder: &#x27;Search...&#x27; # The placeholder text of the input. meilisearch: placeholder: &#x27;Search...&#x27; searchKey: &#x27;&#x27; indexName: &#x27;&#x27; hostUrl: &#x27;&#x27; 显然这段没啥用，因为我们不需要使用algolia搜索等等 你需要安装 hexo-generator-json-content，并根据它的文档去做相应配置。 修改 主题配置文件 。 123search: enable: true service: hexo","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://jxclbx.github.io/tags/hexo/"},{"name":"站内搜索","slug":"站内搜索","permalink":"http://jxclbx.github.io/tags/%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2/"}]},{"title":"Github+jsDelivr搭建个人图床","slug":"Github-jsDelivr搭建个人图床","date":"2023-05-02T16:13:51.000Z","updated":"2023-08-31T04:15:25.534Z","comments":true,"path":"2023/05/03/Github-jsDelivr搭建个人图床/","link":"","permalink":"http://jxclbx.github.io/2023/05/03/Github-jsDelivr%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%9B%BE%E5%BA%8A/","excerpt":"","text":"Github+jsDelivr图床 经常写博文的朋友对床图肯定不陌生。使用markdown撰写博客，将图片放在床图网站生成外链统一管理，这样一份博文就可以发布在不同的平台，也避免了不同网页对同一张图片引用的。不过免费的床图网站有时不稳定，付费价格又都不便宜。 最近了解到了Github+jsDelivr的方式搭建个人床图，稳定快速免费。 搭建方法也比较简单，本文默认已经： 有Github账号 通过SSH与本地Git绑定 掌握基本的Git操作 那么，搭建床图仅需三步。 在GIthub建立一个仓库 在创建GitHub仓库并与本地Git绑定中已经完成 将本地图片push到仓库 先将建好的仓库clone到本地 将需要上传的图片添加到对应文件夹 git push 图片就是保存在github仓库，每个仓库有1个G的容量限制。1个G？不叫事，那能存很多图片。如果你图片存满，那再建个新仓库就是了。 Github的资源在国内加载速度比较慢，所以需要用到CDN技术来加速。 CDN的全称是Content Delivery Network，即内容分发网络。CDN是构建在网络之上的内容分发网络，依靠部署在各地的边缘服务器，通过中心平台的负载均衡、内容分发、调度等功能模块，使用户就近获取所需内容，降低网络拥塞，提高用户访问响应速度和命中率。CDN的关键技术主要有内容存储和分发技术。 jsDelivr(https://cdn.jsdelivr.net)就是一种免费且快速的CDN，通过jsDelivr引用资源GIthub图片资源，即可实现图片加速。所以接下来的第三步，改写一下链接就搞定了。主题内部也是用了这种方法。 通过jsDelivr引用资源 使用方法： 1https://cdn.jsdelivr.net/gh/你的用户名/你的仓库名@发布的版本号/文件路径 此处 1https://cdn.jsdelivr.net/gh/jxclbx/blogImages/文件路径 例如访问https://cdn.jsdelivr.net/gh/jxclbx/blogImages/imageSource/bg.jpg 得到如下效果： 图床接入 markdown的图片URL可以填入网络地址，并且paste image插件所输出的格式就是标准的markdown格式，而不是hexo的引用图片格式，我们只需在写完一篇blog后，多加入一步上传图片到github的步骤即可。 在merge后，直接将md文件中的url做替换，加入 1https://cdn.jsdelivr.net/gh/jxclbx/blogImages/imagePost/ 即可完成。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"图床","slug":"图床","permalink":"http://jxclbx.github.io/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"jsDelivr","slug":"jsDelivr","permalink":"http://jxclbx.github.io/tags/jsDelivr/"},{"name":"git","slug":"git","permalink":"http://jxclbx.github.io/tags/git/"}]},{"title":"创建GitHub仓库并与本地Git绑定","slug":"创建GitHub仓库并与本地Git绑定","date":"2023-05-02T13:40:34.000Z","updated":"2023-08-31T04:15:25.539Z","comments":true,"path":"2023/05/02/创建GitHub仓库并与本地Git绑定/","link":"","permalink":"http://jxclbx.github.io/2023/05/02/%E5%88%9B%E5%BB%BAGitHub%E4%BB%93%E5%BA%93%E5%B9%B6%E4%B8%8E%E6%9C%AC%E5%9C%B0Git%E7%BB%91%E5%AE%9A/","excerpt":"","text":"为了创建一个图床 有Github账号 通过SSH与本地Git绑定 掌握基本的Git操作 这三步是缺一不可的，现在先来将SSH绑定git 创建一个新的仓库 我们点击“New repository”创建一个新的仓库： 得到SSH地址 绑定SSH 双击git-bash.exe，在本地创建ssh key： 1ssh-keygen -t rsa -C &quot;your_email@youremail.com&quot; 然后成功后会在User文件夹对应的用户下创建.ssh文件夹，其中有一个id_rsa.pub文件，我们复制其中的key: 之后返回github，进入 Account Settings（账户配置），左边选择SSH and GPG Keys选项 其中的title随便填，下面的粘贴在你电脑上生成的key。点击添加之后，则添加成功： 验证是否绑定本地成功，在git-bash中验证，输入指令： 1ssh -T git@github.com 如果第一次执行该指令，则会提示是否continue继续，如果我们输入yes就会看到成功信息： 1ssh -T git@github.com github不支持shell这个可以忽略。 1Hi jxclbx! You&#x27;ve successfully authenticated, but GitHub does not provide shell access. Git操作 由于GitHub每次执行commit操作时，都会记录username和email，所以要设置它们： 12git config --global user.name &quot;jxclbx&quot;git config --global user.email &quot;13001392777@163.com&quot; Clone到本地 1git clone git@github.com:jxclbx/blogImages.git 此时在目录下会到一个隐藏的.git文件夹，该文件夹是Git用来跟踪管理版本库的，然后将所有文件添加到仓库，并提交文件： 1git add . 1git commit -m &quot; &quot; Add &amp; Commit git commit 是 Git 版本控制系统中用于保存本地仓库更改的命令。当你在本地 Git 仓库中更改文件时，可以使用 git commit 创建一个新的快照并将其添加到 Git 历史记录中。这有助于跟踪你随着时间推移所做的更改并与其他人共同开发同一项目。 要使用 git commit，你首先需要使用 git add 将要提交的更改加入到暂存区中。这告诉 Git 你想要包含在提交中的更改内容。一旦你将更改加入到暂存区中，就可以使用以下命令将其提交： -m 标志用于添加提交信息，描述你所做的更改。编写清晰和描述性的提交信息非常重要，这样其他开发人员可以轻松地理解你所做的更改。 如果你想在提交中包含工作目录中的所有更改，可以使用以下命令： 1git commit -a -m &quot;提交信息&quot; -a 标志告诉 Git 自动将仓库中所有已修改或已删除的更改加入到暂存区中。 提交完成后，可以将其推送到远程仓库以与他人共享更改或保留更改的备份。 暂存区 暂存区是 Git 版本控制系统中的一个概念，它是介于工作目录和 Git 仓库之间的一个中间状态，也被称为 Git 的“索引”（index）。它是用于临时存储已修改或已删除文件的地方，以便在下一次提交时包含这些更改。 暂存区在本地 Git 仓库的 .git 目录中的 index 文件中。每次使用 git add 命令将文件添加到暂存区时，Git 会将这些更改写入 index 文件中。在执行 git commit 命令之前，你可以使用 git status 命令来查看哪些文件已经被添加到暂存区，哪些文件还未被添加。 需要注意的是，暂存区只是一个中间状态，只有执行 git commit 命令将暂存区中的更改提交到 Git 仓库后，这些更改才会被永久保存下来。如果你在暂存区中添加了一个文件，但之后又对该文件进行了修改，那么只有重新使用 git add 命令将该文件添加到暂存区，之后再使用 git commit 命令才能将最新的更改提交到 Git 仓库中。 关于远程仓库：remote 在 Git 中，remote 表示远程仓库的别名或名称。当你从远程仓库中获取代码或将代码推送到远程仓库时，需要使用远程仓库的名称。为了方便起见，Git 允许为每个远程仓库分配一个别名，这个别名就是 remote。 在 git remote add 命令中，remote 参数指定了新远程仓库的名称或别名，origin 就是一个常用的远程仓库别名。在这个命令中，origin 将被用作指向远程仓库的别名，而 git@github.com:jxclbx/blogImages.git 则是该远程仓库的 URL。这个命令将把远程仓库 git@github.com:jxclbx/blogImages.git 添加到本地 Git 仓库中，并将其命名为 origin。 在添加远程仓库后，你可以使用 git remote -v 命令查看所有已添加的远程仓库，包括它们的别名和 URL。 这个错误意味着在尝试将本地 Git 仓库连接到远程仓库时，Git 发现已经存在一个名为 origin 的远程仓库。这通常发生在你尝试在已经存在 origin 的情况下再次运行 git remote add origin 命令，或者在克隆仓库时指定了一个与 origin 名称相同的远程仓库。 要解决这个错误，可以尝试以下方法： 1git remote rm origin 本地仓库建立完成 此时我们的本地仓库就建立好了。 然后我们的本地仓库要关联GitHub的仓库，直接将本地仓库关联远程GitHub仓库地址即可 1git remote add origin git@github.com:jxclbx/blogImages.git 上传本地代码至GitHub 下面要上传本地代码至GitHub，但是前提是远程仓库不能使空的，所以我们在远程仓库中创建一个README.md的文件： 本地仓库也创建一个一模一样的README.md文件即可，然后使用git pull origin master远程更新一下。 然后我们在原来的git bash中提交本地仓库中的web工程源代码： 1git push -u origin master error: src refspec master does not match any 确认本地 Git 仓库中是否存在名为 master 的分支。使用以下命令查看本地分支： 1git branch 如果 master 分支不存在，则可以使用以下命令创建该分支： 1git checkout -b master Pull request 出现 There isn’t anything to compare. 请移步另一篇文章。至此，已经绑定以及创建仓库。","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"git","slug":"git","permalink":"http://jxclbx.github.io/tags/git/"},{"name":"ssh","slug":"ssh","permalink":"http://jxclbx.github.io/tags/ssh/"}]},{"title":"你好，五月！","slug":"你好，五月！","date":"2023-04-28T06:11:48.000Z","updated":"2023-08-31T10:15:20.521Z","comments":true,"path":"2023/04/28/你好，五月！/","link":"","permalink":"http://jxclbx.github.io/2023/04/28/%E4%BD%A0%E5%A5%BD%EF%BC%8C%E4%BA%94%E6%9C%88%EF%BC%81/","excerpt":"","text":"五月 一个寻常的五月，往往以一个寻常的错误开篇。 寻常的不能再寻常 寻常到……front-matter的Headimg千万不要忘了打后缀名，本地路径打上了后缀名也会因为外部链接没法引用这个路径下的image而无法显示。。最后投奔了图床…… 开始 真正的五月在北京开启，爬展花花卡丁车 好在五月是这样的一个轻松充实的基调 （富士真好玩.jpg 让我们和四月说一声再见吧，希望五月的风带来我想见的你，愿你想要的明天，都会如约而至。","categories":[{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"}],"tags":[{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"}]},{"title":"VS_Code配置Python解释器","slug":"VS-Code配置Python解释器","date":"2023-04-26T13:21:53.000Z","updated":"2023-08-31T04:15:25.536Z","comments":true,"path":"2023/04/26/VS-Code配置Python解释器/","link":"","permalink":"http://jxclbx.github.io/2023/04/26/VS-Code%E9%85%8D%E7%BD%AEPython%E8%A7%A3%E9%87%8A%E5%99%A8/","excerpt":"","text":"我们熟悉的老朋友VS Code今天cv2莫名其妙报错，经过一番排查，得到是Python自身出了问题，故记录一下VSC与anaconda配置其的过程 VSCode 首先，我们需要在环境变量中添加 12C:\\Users\\13001\\AppData\\Local\\Programs\\Python\\Python37C:\\Users\\13001\\AppData\\Local\\Programs\\Python\\Python37\\Scripts 再在VSCode中，Ctrl+Shift+P 或者 View &gt; Command Palette，打开命令面板 输入 Python: Select Interpreter 选择Python的安装路径 可以使用上方的刷新符号来更新已经卸载的python版本的状态使其消失 选择好解释器后，就可以愉快的开始使用了","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"},{"name":"垃圾py","slug":"垃圾py","permalink":"http://jxclbx.github.io/tags/%E5%9E%83%E5%9C%BEpy/"},{"name":"vscode","slug":"vscode","permalink":"http://jxclbx.github.io/tags/vscode/"}]},{"title":"公开前：配置主题","slug":"公开前：配置主题","date":"2023-04-23T15:35:32.000Z","updated":"2023-08-31T04:15:25.538Z","comments":true,"path":"2023/04/23/公开前：配置主题/","link":"","permalink":"http://jxclbx.github.io/2023/04/23/%E5%85%AC%E5%BC%80%E5%89%8D%EF%BC%9A%E9%85%8D%E7%BD%AE%E4%B8%BB%E9%A2%98/","excerpt":"","text":"首先，非常激动，非常开心，我打开了撰写blog的大门。 配置主题 首先是更改主题 1npm i hexo-theme-volantis 这步是为了将主题安置到 blog\\node_modules\\hexo-theme-volantis 关于背景图片的替换 将图片放置在 node_modules\\hexo-theme-volantis\\source\\images 中，再将 12345678cover: height_scheme: full # full, half layout_scheme: dock # blank (留白), search (搜索), dock (坞), featured (精选), focus (焦点) display: home: true archive: true others: false # can be written in front-matter &#x27;cover: true&#x27; background: /images/bg.jpg # background image 的background字段更改为相对路径即可 关于引用图片 hexo-renderer-marked 3.1.0 引入了一个新的选项，其允许你无需使用 asset_img 标签插件就可以在 markdown 中嵌入图片 然后再在 _config.yml中更改代码块 1234post_asset_folder: truemarked: prependRoot: true postAsset: true 后在 _posts 文件夹中新建与post名相同的文件夹即可","categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"自言自语","slug":"自言自语","permalink":"http://jxclbx.github.io/tags/%E8%87%AA%E8%A8%80%E8%87%AA%E8%AF%AD/"}]},{"title":"Hello World","slug":"hello-world","date":"2023-04-22T15:54:53.000Z","updated":"2023-05-02T15:55:08.000Z","comments":true,"path":"2023/04/22/hello-world/","link":"","permalink":"http://jxclbx.github.io/2023/04/22/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"技术","slug":"技术","permalink":"http://jxclbx.github.io/categories/%E6%8A%80%E6%9C%AF/"},{"name":"浮生","slug":"浮生","permalink":"http://jxclbx.github.io/categories/%E6%B5%AE%E7%94%9F/"},{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/categories/CV/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/categories/HTML/"},{"name":"算法设计课程","slug":"算法设计课程","permalink":"http://jxclbx.github.io/categories/%E7%AE%97%E6%B3%95%E8%AE%BE%E8%AE%A1%E8%AF%BE%E7%A8%8B/"}],"tags":[{"name":"专业课","slug":"专业课","permalink":"http://jxclbx.github.io/tags/%E4%B8%93%E4%B8%9A%E8%AF%BE/"},{"name":"深度学习","slug":"深度学习","permalink":"http://jxclbx.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"GNNs","slug":"GNNs","permalink":"http://jxclbx.github.io/tags/GNNs/"},{"name":"课题组","slug":"课题组","permalink":"http://jxclbx.github.io/tags/%E8%AF%BE%E9%A2%98%E7%BB%84/"},{"name":"ubuntu","slug":"ubuntu","permalink":"http://jxclbx.github.io/tags/ubuntu/"},{"name":"linux","slug":"linux","permalink":"http://jxclbx.github.io/tags/linux/"},{"name":"clash","slug":"clash","permalink":"http://jxclbx.github.io/tags/clash/"},{"name":"科学上网","slug":"科学上网","permalink":"http://jxclbx.github.io/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"},{"name":"日记","slug":"日记","permalink":"http://jxclbx.github.io/tags/%E6%97%A5%E8%AE%B0/"},{"name":"python","slug":"python","permalink":"http://jxclbx.github.io/tags/python/"},{"name":"HTML","slug":"HTML","permalink":"http://jxclbx.github.io/tags/HTML/"},{"name":"CV","slug":"CV","permalink":"http://jxclbx.github.io/tags/CV/"},{"name":"Pytorch","slug":"Pytorch","permalink":"http://jxclbx.github.io/tags/Pytorch/"},{"name":"网页","slug":"网页","permalink":"http://jxclbx.github.io/tags/%E7%BD%91%E9%A1%B5/"},{"name":"vscode","slug":"vscode","permalink":"http://jxclbx.github.io/tags/vscode/"},{"name":"hexo","slug":"hexo","permalink":"http://jxclbx.github.io/tags/hexo/"},{"name":"音乐","slug":"音乐","permalink":"http://jxclbx.github.io/tags/%E9%9F%B3%E4%B9%90/"},{"name":"算法","slug":"算法","permalink":"http://jxclbx.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"anaconda","slug":"anaconda","permalink":"http://jxclbx.github.io/tags/anaconda/"},{"name":"站内搜索","slug":"站内搜索","permalink":"http://jxclbx.github.io/tags/%E7%AB%99%E5%86%85%E6%90%9C%E7%B4%A2/"},{"name":"图床","slug":"图床","permalink":"http://jxclbx.github.io/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"jsDelivr","slug":"jsDelivr","permalink":"http://jxclbx.github.io/tags/jsDelivr/"},{"name":"git","slug":"git","permalink":"http://jxclbx.github.io/tags/git/"},{"name":"ssh","slug":"ssh","permalink":"http://jxclbx.github.io/tags/ssh/"},{"name":"垃圾py","slug":"垃圾py","permalink":"http://jxclbx.github.io/tags/%E5%9E%83%E5%9C%BEpy/"},{"name":"自言自语","slug":"自言自语","permalink":"http://jxclbx.github.io/tags/%E8%87%AA%E8%A8%80%E8%87%AA%E8%AF%AD/"}]}